[{"target_population": "Targets recipients of SNAP (Supplemental Nutrition Assistance Program, formerly known as the Food Stamp Program). Low-income, low-skilled adults are eligible to enrol in FasTRAC programmes regardless of SNAP receipt.  Participants can also be referred by country SNAP E&T programmes - they will be enrolled into the FasTRAC programme if an evaluation finds that their individualised plan would benefit from Career Navigator services. To participate in SNAP E&T, an individual must be a recipient of SNAP benefits and not Temporary Assistance for Needy Families (TANF). Working-age SNAP recipients who are not employed and do not qualify for an exemption must meet certain requirements. (pp. 2-3)", "source": ["While the program is fairly new, Minnesota's SNAP E&T pay-for-performance pilot, which includes three career pathway programs, is already sparking interest as an innovative strategy.", "Career pathways combine integrated basic-skills education and career-specific training in high-demand occupations with wrap-around services designed to help participants succeed.", "The pilot involves employer outreach and engagement; soft skills training and career navigation; and a form of intensive student-centered support that includes: individual assessment, service coordination, early intervention, navigation of financial and academic resources, job search assistance, and retention and advancement services.", "These programs are designed to help low-income students with low job skills find well-paying jobs with advancement potential while also meeting the needs of businesses.", "SNAP E&T funding allows these programs to provide more intensive services to SNAP recipients than would otherwise be possible while also expanding services to more participants.", "Although Minnesota's SNAP E&T pilot does not currently reimburse participants for tuition costs, child care, transportation, and other direct costs of education and training, the pilot intends to pursue reimbursement for some or all of these opportunities moving forward, with the approval of the submitted federal fiscal year 2015 state plan."], "paper_id": "#8415", "title": "Minnesota's Pay-for-performance Pilot Program", "pdf_txt": "SNAP Employment and Training July 2014 Minnesota\u2019s Pay-for-Performance Pilot Program Lavanya Mohan and Helly Lee SNAP Employment & Training (E&T) is an important component of SNAP (Supplemental Nutrition Assistance Program, formerly known as the Food Stamp Program) that supports a variety of education, training, employment, and related services for SNAP recipients. It gives recipients opportunities to gain skills, training, or experience that will improve their employment prospects and reduce their reliance on SNAP benefits. Moreover, it may help SNAP recipients who are subject to work requirements meet those program stipulations.1 The U.S. Department of Agriculture's Food and Nutrition Service (FNS) provides state agencies grant money (commonly called \u201c100 percent money\u201d) to cover the program costs of SNAP E&T. States may also claim 50 percent reimbursements on additional spending, including covering participants\u2019 tuition, support services such as dependent care, and transportation expenses. Through a partnership with the Greater Twin Cities United Way (GTCUW), Minnesota is using SNAP E&T funds to provide career navigation and other support services for SNAP recipients who participate in select career pathways programs under the Minnesota FastTRAC (Training, Resources, and Credentialing) Adult Career Pathways initiative.2 While the program is fairly new, Minnesota\u2019s SNAP E&T pay-for-performance pilot, which includes three career pathway programs, is already sparking interest as an innovative strategy. Career pathways combine integrated basic-skills education and career-specific training in high-demand occupations with wrap-around services designed to help participants succeed. The pilot involves employer outreach and engagement; soft skills training and career navigation; and a form of intensive student-centered support that includes: individual assessment, service coordination, early intervention, navigation of financial and academic resources, job search assistance, and retention and advancement services. These programs are designed to help low-income students with low job skills find well-paying jobs with advancement potential while also meeting the needs of businesses.3 SNAP E&T funding allows these programs to provide more intensive services to SNAP recipients than would otherwise be possible while also expanding services to more participants. Although Minnesota\u2019s SNAP E&T pilot does not currently reimburse participants for tuition costs, child care, transportation, and other direct costs of education and training, the pilot intends to pursue reimbursement for some or all of these opportunities moving forward, with the approval of the submitted federal fiscal year 2015 state plan.4 1 Helly Lee, SNAP Works: http://www.clasp.org/resources-and- publications/files/SNAP-Work-Requirements-and-Time-Limits-ABAWD.pdf. 2 Andrea Ferstan and Rachel Speck. Phone Interview by . For more information on Minnesota\u2019s FastTRAC programs, please see: \"Minnesota FastTRAC,\" accessed June 23, 2014, http://www.mnfasttrac.org. 3 For more information on career pathways, please see: Shared Vision, Strong Systems: The Alliance for Quality Career Pathways Framework Version 1.0, Alliance for http://www.clasp.org/resources-and-publications/files/aqcp-framework-version-1- 0/AQCP-Framework.pdf. 4 Ferstan and Speck, phone interview, and \"Minnesota FastTRAC,\" http://www.mnfasttrac.org. 1200 18th Street NW \u2022 Suite 200 \u2022 Washington, DC 20036 \u2022 p (202) 906.8000 \u2022 f (202) 842.2885 \u2022 www.clasp.org SNAP E&T: Minnesota\u2019s Pay-for-Performance Pilot Program July 2014 2 In the \u201cPay-for-Performance\u201d model, the community-based organizations (CBOs) providing services are paid by the state based on outcomes achieved, as opposed to activity hours. For instance, CBOs are reimbursed for their navigation services when participants achieve specified milestones, including credential attainment, job placement, and 90-day job retention.5 In order to prevent \u201ccreaming\u201d (serving only more job-ready participants), GTCUW issues service providers bonus payments when the specified milestones are achieved by participants identified as members of harder-to-employ groups, such as ex-offenders. These bonuses are not claimed for SNAP E&T reimbursement but rather are funded with philanthropic dollars. The Pay for Performance initiative, like the state\u2019s SNAP E&T coordination, is administered through Minnesota\u2019s Department of Employment and Economic Development, as opposed to the state\u2019s Department of Human Services.6 Enrollment Process Low-income, low-skilled adults are eligible to enroll in FastTRAC programs regardless of SNAP receipt. Participants may be referred to FastTRAC programs by county SNAP E&T programs (which are funded with 100 percent federal SNAP E&T funds). Participants may also learn about career pathways programs through referrals from Workforce Centers,7 nonprofit service providers, adult basic education programs, or simply word of mouth. In such cases, interested participants are screened for SNAP receipt and can receive application assistance if they appear to be eligible for SNAP or are currently enrolled. Students enrolled in SNAP E&T are evaluated to see if their individualized plan would benefit from Career Navigator services. If so, these students can enroll in the FastTRAC program.8 Data Management Participating nonprofit FastTRAC partners that provide skills training and navigation services, record and track participant activities and wrap-around services through Minnesota\u2019s WorkForce One (WF1) database. The metrics tracked include demographic information of participants, job placement and retention, and graduation milestones. Support services are also documented in WF1 for reimbursement purposes. On a regular basis, participating nonprofit partners provide participant data to the state agency for verification of SNAP E&T enrollment. The state agency cross-references the Minnesota Department of Human Service (DHS) data warehouse to confirm that participants are currently enrolled in SNAP and notifies the nonprofit provider. 5 Suzanne Perry, \u201cMinnesota Explores \u2018Pay for Performance\u2019 Bonds,\u201d The Chronicle of http://philanthropy.com/blogs/state-watch/minnesota-explores-pay-for-performance-bonds/397. The Minnesota Pay-for-Performance model is similar to a Social Impact Bond model, leveraging private funds to support pilot programs through an intermediary wherein the state pays back investors based on a program\u2019s performance. To raise funds for the initiative, GTCUW issues bonds purchased by private and philanthropic investors. As the initiative produces results based on specified metrics, the state pays the non-profit provider which in turn pays back investors at an agreed upon rate of return. For more information on Pay-for-Performance and Social Impact Bonds, please see: Social Impact Bonds: http://www.clasp.org/resources-and-publications/publication-1/CLASP-Social-Impact-Bonds-SIBs- March-2014.pdf. 6 \u201cMinnesota Department of Employment and Economic Development,\u201d accessed June 23, 2014, http://mn.gov/deed and Minnesota Adult Career Pathway Navigator Wraparound Services: SNAP Employment and Training 50% Reimbursement Funding Proposal, Minnesota Department of Employment and Economic Development, October 30, 2012. 7 Established under the 1998 Workforce Investment Act, One-Stop Workforce Centers provide a range of services for job seekers which includes training referrals, career counseling, job listings, and similar employment-related services. 8 Ferstan and Speck, phone interview, and Minnesota Adult Career Pathway Navigator Wraparound Services: SNAP Employment and Training 50% Reimbursement Funding Proposal. 1200 18th Street NW \u2022 Suite 200 \u2022 Washington, DC 20036 \u2022 p (202) 906.8000 \u2022 f (202) 842.2885 \u2022 www.clasp.org SNAP E&T: Minnesota\u2019s Pay-for-Performance Pilot Program July 2014 3 On a quarterly basis, nonprofit providers submit documentation to the state to facilitate reimbursement from GTCUW. After receiving verification, GTCUW pays out reimbursements to participating providers for all student outcomes achieved, and then submits documentation to the state for SNAP E&T reimbursements.9 By The Numbers Overview of SNAP E&T \uf0b7 Year started: Program design began in 2012 and enrollment began in the third quarter of 2013.10 \uf0b7 Approximate number of active participants: As of December 2013, between 70 to 80 total participants have participated each quarter; approximately 15 to 25 of these have been SNAP-enrolled during each quarter. \uf0b7 Performance Measures: o Industry-recognized credentials earned (all participants): 55 o Number of jobs obtained (all participants): 69 o Number of jobs retained for 90 days (all participants): 48.11 Supplemental Nutrition Assistance Program Employment and Training (SNAP E&T) funds can be used to support education, training, employment, and related services for SNAP recipients. To participate in SNAP E&T, an individual must be a recipient of SNAP benefits and not Temporary Assistance for Needy Families (TANF). The majority of SNAP recipients are either working\u2014but earning so little that they still qualify for benefits\u2014or are not expected to be employed, mostly due to age or disability. Working-age SNAP recipients who are not employed and do not qualify for an exemption must meet certain requirements. States may operate voluntary or mandatory SNAP E&T programs (or a combination of both) and may limit eligibility to certain types of SNAP recipients or to those who live in certain areas. SNAP E&T funds can support operating costs of job search services, work experience, education and training programs, support services for participants, and job retention services for up to 90 days. Additional activities may be allowed under new pilot projects authorized under the Farm Bill. For more information, see SNAP E&T. Crucial Innovations Career navigation and career pathways are cutting-edge workforce services. The hypothesis is that in combination, services will be more effective than they would be as a stand-alone activities, opening doors for low-income, low-skilled students who could not otherwise access or complete postsecondary learning opportunities. Integrating services that assist participants in determining a career path, understanding the requirements for the jobs they seek, and accessing the education and training needed can help them achieve their goals. The SNAP E&T pilot is one of the first of its kind to leverage the Pay-for-Performance model. With tight budgets and increased skepticism about the effectiveness of government-funded programs, the idea of paying only for proven results has broad appeal. This model eases the burden on states in providing up-front 9 Ferstan and Speck, phone interview, and Minnesota Adult Career Pathway Navigator Wraparound Services: SNAP Employment and Training 50% Reimbursement Funding Proposal. 10 Ferstan and Speck, phone interview. 11 Minnesota Adult Career Pathway Navigator Wraparound Services: SNAP Employment and Training 50% Reimbursement Funding Proposal. 1200 18th Street NW \u2022 Suite 200 \u2022 Washington, DC 20036 \u2022 p (202) 906.8000 \u2022 f (202) 842.2885 \u2022 www.clasp.org SNAP E&T: Minnesota\u2019s Pay-for-Performance Pilot Program July 2014 4 funds, as payments are made only when specific milestones are achieved. It also alleviates the burden on service providers by eliminating tracking of activity hours. While not required, an intermediary or service provider that is willing and able to provide the initial funding and absorb the risk of non-performance, can be instrumental in facilitating this type of innovation. Challenges A pay-for-performance schedule increases the risk of non-payment for nonprofit providers and/or intermediaries. The program requires significant up-front investment by the intermediary to reduce the risk to nonprofits of non-payment. GTCUW covers quarterly costs for career navigation administered by nonprofit providers, but requires state authentication of outcomes achieved by students, including SNAP recipients, in order for payments to qualify for federal reimbursement.12 As programs begin to access reimbursements and are better able to assess future reimbursement levels, GTCUW anticipate that the need for up-front investment will begin to diminish. The process of enrolling in SNAP can create barriers for potential participants due to administrative lag and the burden of providing documentation for Able-Bodied Adults Without Dependents. The application to enroll in SNAP is lengthy and includes significant documentation requirements. Further, submitted applications may have longer-than-expected wait times to process through county agencies. Some participants find this process cumbersome. As Minnesota recently reverted to a mandatory SNAP E&T participation for Able-Bodied Adults Without Dependents (ABAWDs), more participants are required to submit information on a monthly basis to continue receipt of SNAP benefits, a burden for busy adults engaged in full-time postsecondary education or employment. This requires increased coordination between County staff and Navigators to share and document required student hours. Participants who obtain jobs\u2014and thus receive reduced SNAP benefits\u2014may also allow their SNAP enrollment to lapse, making them ineligible for SNAP E&T retention services.13 For More Information Visit http://www.mnfasttrac.org Contact Andrea Ferstan Director of Education and Jobs Greater Twin Cities United Way (612) 340-7483 or (612) 298-9153 Andrea.Ferstan@gtcuw.org 12 Ferstan and Speck, phone interview. 13 Ibid. Steven Erbes SNAP Employment and Training Coordinator Minnesota Department of Employment and Economic Development (651) 259-7539 or (952) 393-4342 steve.erbes@state.mn.us 1200 18th Street NW \u2022 Suite 200 \u2022 Washington, DC 20036 \u2022 p (202) 906.8000 \u2022 f (202) 842.2885 \u2022 www.clasp.org "}, {"target_population": "3- and 4-year-old children and their families", "source": ["The Child-Parent Center (CPC) model, one of the longest running early childhoodintervention models in the United States, has produced some of the most robust longtermacademic and social outcomes for children (Reynolds, 2000; Reynolds &Temple, 2008).", "Beginning in January 2012, as part of a U.S. Department ofEducation Investing in Innovation (i3) grant to the University of Minnesota, the city ofChicago and Chicago Public Schools (CPS) received funding to (1) increase thenumber of children who could attend existing CPC sites and (2) increase theavailability of CPC programs by adding 16 new sites.Pay for Success (PFS), previously referred to in this evaluation as a Social ImpactBond (SIB), is a funding mechanism whereby private business and philanthropicpartners purchase Social Impact Bonds (SIBs) to support public programs.Government entities, such as a state\u2019s Department of Education, pay investors onlywhen a program meets its pre-determined outcomes.", "The investors bear the full riskof the investment and if a program fails to meet its goals, taxpayers owe nothing.", "Tothis end, PFS initiatives typically have an independent evaluator to help determinewhether the outcomes have been realized and outcome payments to the privateinvestor need to be made.", "Beginning in 2014\u201315, the IFF Pay for Success projectfunded additional CPC preschool slots at six CPS schools.", "In 2015\u201316, three sites(identified by CPS and approved by the city of Chicago) were added to the PFSproject.", "SRI International (SRI) was contracted to conduct the evaluation of the childoutcomes for this project, referred to as the \u201cPFS-CPC project.\u201d The project isexpected to serve four cohorts of preschool children across the nine sites over fourschool years\u2014Cohort 1: 2014\u201315, Cohort 2: 2015\u201316, Cohort 3: 2016\u201317, andCohort 4: 2017\u201318.This third SRI project evaluation report describes first grade special educationplacement outcomes of Cohort 1 children, kindergarten special education placementoutcomes of Cohort 2, and kindergarten readiness outcomes for Cohort 3.", "The reportbegins with a description of the CPC program and its expansion efforts using PFSfunding, including evidence about the impacts of the CPC program model onchildren\u2019s school readiness and school achievement at the beginning of the project.Next, we describe the approach to the PFS-CPC program evaluation.", "The last sectionpresents the results of the evaluation for Cohorts 1, 2, and 3.", "We then conclude thisreport with a discussion of how the results fit in the larger context of research."], "paper_id": "#17194", "title": "Evaluation Of Child Outcomes In Nine Child-Parent Centers: Report For 201617", "pdf_txt": " Evaluation of Child Outcomes in Nine Child-Parent Centers: Report for 2016\u201317 March 2018 Prepared for: IFF Pay For Success I, LLC 333 S. Wabash Avenue, Suite 2800 Chicago, Illinois 60604 Attention: Dana Lieberman, Sr. Vice President, Capital Solutions E-mail: dlieberman@iff.org Copy to: IFF 333 S. Wabash Ave., Suite 2800. Chicago, Illinois 60604 Attention: Charles M. Biggam III, Chief Legal Counsel E-mail: cbiggam@iff.org Prepared by: SRI International Erika Gaylor Kate Ferguson Mary McCracken Xin Wei Donna Spiker Revised June 2019 to correct an error on p. 9 Suggested citation: Gaylor, E., Ferguson, K., McCracken, M., Wei, X., & Spiker, D. (2018). Evaluation of child outcomes in nine Child-Parent Centers: Report for 2016-17. Prepared for IFF Pay for Success I, LLC. Menlo Park, CA: SRI International. PFS-CPC: Report for 2016\u201317 March 2018 ii Contents Background ................................................................................................................................... 1 CPC Program Model ..................................................................................................................... 2 CPC Model Description ............................................................................................................. 2 Expected Outcomes from the CPC Program Model .................................................................. 4 School Readiness .................................................................................................................. 4 Third-Grade Reading and Literacy ........................................................................................ 4 Reduced Special Education Use ........................................................................................... 5 Chicago PFS Project (PFS-CPC Project) .................................................................................. 6 Evaluation Design ......................................................................................................................... 7 Analysis Approach ..................................................................................................................... 9 CPC Intervention Sample Included in Analysis ..................................................................... 9 Analyzing Impact on Kindergarten Readiness ..................................................................... 13 Analyzing Impact on Special Education Placement ............................................................. 14 Selecting a Comparison Group ............................................................................................ 16 Results ........................................................................................................................................ 19 Kindergarten Readiness .......................................................................................................... 19 Cohort 3 Kindergarten Readiness ....................................................................................... 19 Special Education Placement .................................................................................................. 21 Cohort 2 Kindergarten Special Education Placement .......................................................... 21 Cohort 1 First grade Special Education Placement ............................................................. 21 Discussion ................................................................................................................................... 22 Kindergarten Readiness Findings ........................................................................................... 23 Special Education Placement Findings ................................................................................... 29 Limitations ............................................................................................................................... 34 Conclusion ............................................................................................................................... 35 Next Steps ............................................................................................................................... 36 References .................................................................................................................................. 37 Appendices ................................................................................................................................. 43 Appendix A: Chicago Child-Parent Center Social Impact Bond Evaluation Plan ................... A-1 Appendix B: Timing of Cohorts .............................................................................................. B-1 Appendix C: Propensity Score Approach ............................................................................... C-1 PFS-CPC: Report for 2016\u201317 March 2018 iii List of Exhibits Exhibit 1. CPC Program Model Components ................................................................................ 3 Exhibit 1. CPC Program Model Components (concluded) ............................................................ 4 Exhibit 2. Description of Participating CPC Sites, by Project Year ............................................... 6 Exhibit 3. Enrollment at PFS-funded CPC sites, by year ............................................................ 11 Exhibit 4. Children Attending PFS-funded CPC Sites, by Cohort and Exclusion Criteria ........... 12 Exhibit 5. Intervention Sample Characteristics During their Preschool Year, by Cohort ............. 13 Exhibit 6. Annual attrition, by Cohort and comparison group ...................................................... 19 Exhibit 7. Percent of Children Meeting Kindergarten Readiness Criteria, Across Domains, by Cohort ......................................................................................................................................... 20 Exhibit 8. Percent of Children Meeting Kindergarten Readiness Criteria, by Cohort and Domain .................................................................................................................................................... 21 PFS-CPC: Report for 2016\u201317 March 2018 iv Background The Child-Parent Center (CPC) model, one of the longest running early childhood intervention models in the United States, has produced some of the most robust long- term academic and social outcomes for children (; ). Beginning in January 2012, as part of a U.S. Department of Education Investing in Innovation (i3) grant to the University of Minnesota, the city of Chicago and Chicago Public Schools (CPS) received funding to (1) increase the number of children who could attend existing CPC sites and (2) increase the availability of CPC programs by adding 16 new sites. Pay for Success (PFS), previously referred to in this evaluation as a Social Impact Bond (SIB), is a funding mechanism whereby private business and philanthropic partners purchase Social Impact Bonds (SIBs) to support public programs. Government entities, such as a state\u2019s Department of Education, pay investors only when a program meets its pre-determined outcomes. The investors bear the full risk of the investment and if a program fails to meet its goals, taxpayers owe nothing. To this end, PFS initiatives typically have an independent evaluator to help determine whether the outcomes have been realized and outcome payments to the private investor need to be made. Beginning in 2014\u201315, the IFF Pay for Success project funded additional CPC preschool slots at six CPS schools. In 2015\u201316, three sites (identified by CPS and approved by the city of Chicago) were added to the PFS project. SRI International (SRI) was contracted to conduct the evaluation of the child outcomes for this project, referred to as the \u201cPFS-CPC project.\u201d The project is expected to serve four cohorts of preschool children across the nine sites over four school years\u2014Cohort 1: 2014\u201315, Cohort 2: 2015\u201316, Cohort 3: 2016\u201317, and Cohort 4: 2017\u201318. This third SRI project evaluation report describes first grade special education placement outcomes of Cohort 1 children, kindergarten special education placement outcomes of Cohort 2, and kindergarten readiness outcomes for Cohort 3. The report begins with a description of the CPC program and its expansion efforts using PFS funding, including evidence about the impacts of the CPC program model on children\u2019s school readiness and school achievement at the beginning of the project. Next, we describe the approach to the PFS-CPC program evaluation. The last section PFS-CPC: Report for 2016\u201317 March 2018 1 presents the results of the evaluation for Cohorts 1, 2, and 3. We then conclude this report with a discussion of how the results fit in the larger context of research. CPC Program Model CPC Model Description The CPC program model is designed to promote school readiness, parent involvement, and early learning that, in turn, will translate into long-term academic achievement, higher graduation rates, and career success for CPC students. The CPC model is unique in that it is designed to (1) provide full- or part-time high-quality preschool experiences for 3- and 4-year-old children and (2) combine those educational experiences with family support services and parent engagement activities. CPC programs deliver synergized services for children and their families from preschool through third grade. Indeed, the CPCs emphasize the provision of comprehensive services and parental involvement\u2014program features that are considered to be strongly associated with program quality (; ). A typical CPC site has the components listed in Exhibit 1. The CPC program model components are explained fully at https://humancapitalrc.org/midwest-cpc/cpc-resources (). For this report, the components listed in Exhibit 1 were taken from the draft evaluation plan in the PFS-CPC expansion agreement (see Appendix A, pp. 9\u201311). Note that the CPC model as conceptualized in the current PFS expansion project focuses primarily on providing high-quality preschool education, engaging parents in their child\u2019s education through a parent resource teacher (PRT) at the child\u2019s preschool, and promoting continuity and stability from pre-K through the primary grades. Because the focus for the PFS-CPC project is on preschool programming, SRI\u2019s evaluation is designed to measure the impact of the preschool components on children\u2019s short- and long-term outcomes. PFS-CPC: Report for 2016\u201317 March 2018 2 Exhibit 1. CPC Program Model Components Effective Learning Experiences \uf0b7 Offer pre-K classes that are limited to 34 children for half-day classrooms (two sessions of 17 children each) and have a minimum of two teaching staff. Full-day classrooms, if available, will be limited to 20 children per session. \uf0b7 Provide highly qualified educational staff who will deliver the classroom instruction and parent engagement activities. For example, classroom teachers are certified with a bachelor\u2019s degree (or higher). Overall, program staff must adhere to the requirements set forth by the CPS Talent office, in accordance with collective bargaining unit agreements, and state regulations. Any changes in CPS education and certification requirements will be complied with. \uf0b7 Use data to drive instruction by effectively documenting the organization and implementation of instructional practices to monitor quality and adherence to the program, which is completed by all program staff where appropriate. \uf0b7 Program staff meet with parents over the course of each school year to review their child\u2019s progress and discuss parent program opportunities with the Parent Resource Teacher (PRT). Aligned Curriculum \uf0b7 Implement a CPS District curriculum and formative assessment that are aligned to standards, domains of learning, assessments, and learning activities. \uf0b7 Collaborate with the PRT and classroom teachers to ensure that opportunities to engage families in student learning are available, appropriate, and aligned to the program and parents\u2019 needs. \uf0b7 CPS and, most specifically, the Office of Early Childhood Education provide meaningful professional development and ongoing coaching and feedback for teachers, aides, and other staff members that facilitates high-quality instructional practices. Parent Involvement and Engagement \uf0b7 Engage a PRT and School-Community Representative to work closely with the head teacher and liaisons to maintain a consistently supportive parent program. \uf0b7 Encourage parents to sign a CPC school-home agreement at the start of the school year outlining a plan for fostering learning at home and participating in CPC activities. \uf0b7 Offer and engage families in monthly activities. PRTs create and distribute a monthly parent involvement calendar and conduct parent/teacher conferences over the year to review progress in the parent program. \uf0b7 Provide a resource room dedicated to parent and family activities through kindergarten when possible. \uf0b7 Provide culturally responsive learning opportunities for families that provide flexibility for families\u2019 needs and schedules. Collaborative Leadership Team \uf0b7 Engage a program leadership team that includes the head teacher, PRT, and school-community representative. \uf0b7 Meet regularly, under the direction of the principal, to discuss operations and best practices within the CPC. \uf0b7 Meet regularly, under the direction of the Office of Early Childhood Education (OECE) management team, with staff from across sites to share challenges, experiences, and best practices and make frequent on-site visits to monitor the quality and effectiveness of the program. \uf0b7 Establish meaningful partnerships with community providers to strengthen service delivery and enlist local universities in training opportunities. PFS-CPC: Report for 2016\u201317 March 2018 3 Exhibit 1. CPC Program Model Components (concluded) Continuity and Stability \uf0b7 CPC pre-K classrooms are collocated in the same building as kindergarten classrooms, when possible, to promote familiarity and integration for students as they transition to kindergarten. \uf0b7 Provide a structure of communication, planning, and joint activities under the direction of the principal, leadership team, and OECE management team from pre- K through the primary grades. \uf0b7 Provide a part-time kindergarten aide when funding is available to support the transition into kindergarten. Professional Development System \uf0b7 Offer ongoing professional development opportunities on current trends and needs in early childhood education classrooms, through the OECE and the CPC leadership teams, including topics such as quality curriculum and instruction, data- driven instruction, learning environment, social and emotional needs, and parent engagement. \uf0b7 Meet regularly and create professional learning communities to review ways to support instruction in the classroom and with other teachers. Source: Adapted from Chicago Child-Parent Center Social Impact Bond Evaluation Plan, dated December 2, 2014 (in Appendix A). Expected Outcomes from the CPC Program Model SCHOOL READINESS Previous research on the CPC program showed significant positive effects on children\u2019s kindergarten readiness (; ). Examination of a more recent cohort of CPC participants indicated that they had significantly higher scores on a measure of language proficiency at the end of the program than children enrolled in other publicly funded preschool programs (). More recently, Reynolds and colleagues reported that CPC participants are more likely to meet kindergarten readiness standards in four of six educational focus areas, or \u2018domains\u2019 on a teacher-rated measure (70%) compared with preschool children in the school district who did not attend CPC preschool classrooms (52%) (). THIRD-GRADE READING AND LITERACY The Chicago Longitudinal Study (CLS) followed children over time using administrative records to examine attendance, achievement, and graduation rates in CPC participants compared with children who did not attend CPC preschool. One study found a significant positive impact on third-grade reading achievement for pre-K to third-grade participants (.53 standard deviation) compared with participants who attended CPC only for pre-K and kindergarten (). Smaller studies of PFS-CPC: Report for 2016\u201317 March 2018 4 high-quality preschool interventions have found similar impacts on later school achievement compared with a no-preschool Comparison group (e.g., the Abecedarian study: ; Perry preschool project: ). REDUCED SPECIAL EDUCATION USE The long-term CLS study showed that extended CPC participation (defined as 4 to 6 years) resulted in reductions in the use of special education. Among children 6 to 18 years old, CPC participants had an average rate of special education placement of 14.4% compared with 24.6% for children in the comparison group (who did not attend CPC preschool), indicating that CPC participants had a 41% lower rate of special education placement (). This finding is consistent with another analysis using the CLS sample that compared the average rates of special education placement over time for children who had attended a CPC preschool with those of children who attended a full-day non-CPC kindergarten classroom: special education placement rates of 12.5% and 18.4%, respectively (). It is noteworthy that these estimates average special education placement rates over a wide age range extending beyond the early school years. A more recent study of North Carolina\u2019s state-funded preschool program used statewide population data from 1995 to 2010 to show that third-grade special education rates were reduced by as much as 39% for children who participated in the preschool program, even after taking into account a variety of child and family risk factors, types of special education categories, and funding levels that varied by year (). Other reviews of a variety of preschool program models also reported reductions in special education placement as one of the many cost savings results from participation in high-quality preschool programs like the CPC model (; ). In summary, positive impacts on kindergarten readiness, third-grade reading achievement, and special education placements have been cited extensively to demonstrate the short- and long-term benefits for the individual child and savings for society that come from investing in early childhood education. These studies were used as the basis for identifying the selected outcomes in the current evaluation and for calculating the repayments that will be made in the Chicago PFS-CPC project. PFS-CPC: Report for 2016\u201317 March 2018 5 Chicago PFS Project (PFS-CPC Project) During 2016\u201317, the PFS expansion of the CPC model involved funding for part-day or full-day CPC preschool at nine sites. Exhibit 2 indicates the year each site began receiving PFS funding and whether the site expanded an existing CPC program or began implementing the CPC program for the first time (i.e., a \u201cnew\u201d CPC site).1 In 2016\u201317, the PFS funding provided preschool to an additional 798 3- and 4-year-olds across the nine sites (see Exhibit 3). The funding paid for the expansion of classroom programming at each site as well as enhanced resources and instructional materials to implement the CPC model. The CPC program typically serves both 3- and 4-year- olds, sometimes in mixed-age classrooms. Thus, the investor funding was used to provide CPC preschool and enhanced services to both 3- and 4-year-olds. Exhibit 2. Description of Participating CPC Sites, by Project Year De Diego Expanded Continued Site Peck Melody Fiske Edwards Tonti Davis Year 1 2014\u201315 Year 2 2015\u201316 Expanded Continued Expanded Continued Expanded Continued Continued Expanded New New Year 3 2016\u201317 Continued Continued Continued Continued Continued Continued Continued Continued Continued Thomas Expanded Continued Hanson Park New2 Note: \u201cExpanded\u201d indicates that a site used PFS funding in that year to expand an existing CPC program, \u201cNew\u201d indicates a program received PFS funding to begin implementing a CPC program for the first time, and \u201cContinued\u201d indicates that a site continued to receive PFS funding for an additional year. The project administrators anticipated that four cohorts of children will be served across the nine sites, identified by the school year in which children begin preschool 1 Three of the six sites in Year 1 had been providing CPC services since 2012, at the start of the i3 federal grant, and two had been providing CPC services since 2013, when the original sites from the 1970s were merged with the current site. For the three additional sites in year 2, two were new to providing CPC services and one had been providing CPC services since 2012. 2 This site only operated for half of the year due to delays in hiring. Thus, the first full year of implementing CPC was 2015\u201316. PFS-CPC: Report for 2016\u201317 March 2018 6 (Cohort 1: 2014\u201315, Cohort 2: 2015\u201316, Cohort 3: 2016\u201317, Cohort 4: 2017-18) (see Appendix B for grade levels of children in the four cohorts across years.) Evaluation Design Because government pays investors only when outcomes are achieved, PFS initiatives typically have an independent evaluator to help determine whether the outcomes have been realized. SRI is conducting the independent evaluation of the outcomes of the PFS-CPC expansion project. The SRI evaluation team developed the evaluation methodology building on a draft evaluation design written by a team that included the Harvard Social Impact Bonds Technical Assistance Lab. The project also has an oversight committee of early education and research experts. The evaluation team has been charged with independently documenting the outcomes- based performance measures of the initiative. This kind of evaluation is not intended to test the impact of the CPC model against other preschool models; rather it is tracking the outcomes of the participating children against specific outcome metrics. The evaluation is addressing three performance questions: 1. What is the rate of kindergarten readiness in children participating in the PFS- CPC sites as defined by performance on the Teaching Strategies (TS) GOLD\u2122 instrument (completed by teachers in the spring of the preschool before a child enters kindergarten)? 2. What is the rate of third-grade literacy as defined by performance in meeting or exceeding grade-level performance on the state- or district-administered third- grade assessment in reading? 3. What is the rate at which students are identified with special education needs and placed in special education services (starting in kindergarten) compared with a matched comparison group of children? Kindergarten readiness is being measured in the spring of preschool for CPC participants (as described below), and third-grade literacy will be measured in the spring of third grade after the administration of required state achievement tests. SRI will begin measuring special education placement in kindergarten and repeat its evaluation annually until spring 2020 (in spring 2020, Cohort 1 will have reached the PFS-CPC: Report for 2016\u201317 March 2018 7 first grade).3 fourth grade; Cohort 2, the third grade; Cohort 3, the second grade; and Cohort 4, the For the evaluation of the PFS-CPC project, SRI is using two designs to track the primary outcomes: a descriptive study for the kindergarten readiness and third-grade literacy outcomes4 and a quasi-experimental design for the special education outcomes from first to fourth grades (see analysis approach for further information). Specifically, for the kindergarten readiness and third-grade literacy outcomes, there will be no comparison group for evaluating the outcomes and calculating the subsequent repayment. Evaluation of these two primary outcomes will be based on the intervention group only, and payments will be calculated using outcomes relative to national standards. In the planning phase, it was determined that both the kindergarten readiness and literacy outcomes had normative information so that children\u2019s performance on these measures could be used to identify whether they were performing at or above normative trends for comparable age their peers. The decision was to use this kind of standard rather than compare performance with that of a comparison group of children. In addition, the kindergarten readiness data are not available for children with no preschool experience, given that the kindergarten readiness measure is collected during the spring of pre-K in Chicago Public Schools and only for children who attended preschool. For special education outcomes (first to fourth grades), children are identified as receiving the intervention (i.e., attending a CPC preschool classroom) in the year they are in preschool and then are matched to children with similar demographic characteristics but who did not attend any preschool (CPC or otherwise) in CPS. This no pre-K comparison group is identified when the children are in kindergarten for each of the four cohorts. That is, SRI will create a no pre-K comparison group for each cohort of intervention children using propensity score weighting processes. 3 Further evaluation will be required after 2020. 4 The approach used here is sometimes referred to as the \u201crate card\u201d approach where success payments are made on a per-student basis. PFS-CPC: Report for 2016\u201317 March 2018 8 Analysis Approach CPC INTERVENTION SAMPLE INCLUDED IN ANALYSIS Children were included in the intervention cohorts if they attended one of the PFS- CPC sites that was fully implementing the CPC program during their preschool year,5 were enrolled in either a full- or half-day pre-K classroom, were not identified as having a severe disability, were income eligible (i.e., eligible to receive free or reduced-price lunch), and were at least 4 years old in September of their preschool year. Additionally, a child needed to have attended a CPC pre-K classroom for at least 66% of the days (not consecutively) in a given school year\u2014a percentage considered a sufficient amount or dose of the intervention to affect child outcomes. The project is based on the hypothesis that high-quality early childhood education will prevent or reduce a future need for special education services for children considered at-risk for developing delays or mild disabilities. As such, children diagnosed with severe disabilities were excluded from the project. Early childhood education and intervention also may reduce the need for children with mild delays or speech and language impairments in preschool from needing additional special education services in kindergarten and beyond. The project does not expect to prevent children with severe disabilities or needs from receiving special education services. Children were categorized as having no disability, a mild disability, or severe disability based on a priori decisions of the evaluation team in the planning and evaluation design phase. A severe disability could include autism, specific learning disability, deaf- blindness, deafness, hearing impairment, orthopedic impairment, other health impairment, traumatic brain injury, visual impairment, and multiple disabilities. A mild disability could include developmental delay, speech and language impairment, specific learning disability, and educational support accommodations or modifications for children with no other disability (mild or severe).6 Additionally, children were excluded from the intervention cohort if they were in a separate classroom for students with special education needs. Finally, children were excluded if they were identified with special needs and already had an Individualized Education Plan (IEP) prior to starting their preschool year at age 4 and were specifically assigned to one of the CPC sites because the site had blended classrooms (i.e., based on a CPS district 5 There were five sites for Cohort 1 and nine sites for Cohort 2. 6 In an earlier version of this report, the \u201cmild\u201d disability category was incorrectly described as including SPL, DD, and ED. This description has been corrected; the results of analyses have not changed. PFS-CPC: Report for 2016\u201317 March 2018 9 policy, some school sites had general education classrooms with additional supports to better serve children with IEPs, which are referred to as \u201cblended classrooms\u201d). Each cohort includes children from all PFS-funded sites that were providing the CPC model to 3- and 4-year-olds during that cohort\u2019s 4-year-old preschool year. Inclusion of all eligible 4-year-olds in this group increases the sample size for the study to provide a more reliable and valid assessment of kindergarten readiness at the CPC sites. All the children across all classrooms received the full CPC model. That is, the experience of all 4-year-olds enrolled in these CPCs is similar, with a common curriculum, professional development, and parent engagement aligned through monthly Collaborative Leadership Training by all CPCs, including high-quality preschool and family support services and parent engagement activities. Thus, the evaluation does not distinguish between preschool slots funded by PFS versus other CPC funding sources. Each PFS-CPC cohort is defined as meeting the eligibility criteria above and will become the cohort to be tracked for outcomes in kindergarten and in later grades. Each cohort also will be used to identify a matched comparison group of children in kindergarten for comparing special education outcomes at the end of kindergarten and in later grades. Exhibit 3 shows the enrollment information for CPC preschool slots at PFS-funded sites, by year. At the end of Year 3 (the 2016\u201317 school year), administrative enrollment data showed that 1,309 3- and 4-year-old children were attending preschool at these nine sites (502 3-year-olds; 807 4-year-olds). PFS expansion funding covered the costs of providing CPC preschool for 798 of these 1,309 children. PFS-CPC: Report for 2016\u201317 March 2018 10 Exhibit 3. Enrollment at PFS-funded CPC sites, by year Number of sites Total enrollment 3-year-olds 4-year-olds PFS-funded seats Year 1 Enrollment (2014\u201315) Year 2 Enrollment (2015\u201316) Year 3 Enrollment (2016\u201317) 6 653 267 386 374 9 1,378 537 841 782 9 1,309 502 807 798 For Cohort 3 intervention group, SRI requested a data export that included all students ever enrolled as grade PK (the CPS designation for 4-year-olds in preschool) in the PFS-funded CPC sites at any time in the 2016\u201317 school year. Overall, 818 PK students were ever enrolled at one of the nine CPC sites during 2016\u201317.7 Across the total sample of 818 PK children, 637 or 78% met all the eligibility criteria. Exhibit 4 indicates the exclusions from the original sample of PK children ever enrolled in one of the sites that resulted in the final sample of children included in the analysis for each cohort. 7 The number of children ever enrolled is different from enrollment estimates at any given point in the year. As children left a CPC site, new children were enrolled. The 818 includes all children ever enrolled during the 2016\u201317 year. Based on enrollment in May/June 2017, CPS reported that 807 4-year-old children were enrolled at the nine CPC sites at the end of the year. PFS-CPC: Report for 2016\u201317 March 2018 11 Exhibit 4. Children Attending PFS-funded CPC Sites, by Cohort and Exclusion Criteria Cohort 1 2014\u201315 (n or %) Cohort 2 2015\u201316 (n or %) Cohort 3 2016\u201317 (n or %) Number of sites included Number of four-year old children attending these sites (grade PK) Number of four-year old children meeting eligibility criteria Reason for exclusion Did not attend 66% of days Severe disability and/or enrolled in separate special education classroom Had an IEP prior to PK year Not eligible for free or reduced-price lunch or insufficient documentation Under 4 years old in September of PK year 5 449 3138 % 21% 3% 3% 2% <1% 9 1,004 6549 % 21% 2% 7% 1% 4% 9 818 63710 % 7% 3% 8% 4% 1% Cohort 1 (2014\u201315) included 313 children, Cohort 2 (2015\u201316) included 654 children, and Cohort 3 (2016\u201317) included 637 children. The demographic characteristics of Cohorts 1, 2, and 3 are described in Exhibit 5. Cohorts 1 and 2 are also described in previous reports (; ). The final samples of children who were included were similar in many ways to the children who did not meet the eligibility criteria with a few exceptions. The children who were included in each intervention cohort were more likely to be Hispanic and more likely to speak Spanish at home compared with the children who were excluded from that cohort. 8 Of the 313 children selected for Cohort 1 in their PK year (2014\u201315), 289 were enrolled in CPS on the 20th day of school during their kindergarten year, for a Cohort 1 kindergarten retention rate of 92.33%. 9 Of the 654 children selected for Cohort 2 in their PK year (2015\u201316), 619 were enrolled in CPS on the 20th day of school during their kindergarten year, for a Cohort 2 kindergarten retention rate of 94.65%. 10 Of the 637 children selected for Cohort 3 in their PK year (2016\u201317), 593 were enrolled in CPS on the 20th day of school during their kindergarten year, for a Cohort 3 kindergarten retention rate of 93.09%. PFS-CPC: Report for 2016\u201317 March 2018 12 Exhibit 5. Intervention Sample Characteristics During their Preschool Year, by Cohort Characteristic Cohort 1 2014\u201315 (n = 313) (percent) Cohort 2 2015\u201316 (n = 654) (percent) Cohort 3 2016\u201317 (n = 637) (percent) Male Hispanic African-American Caucasian Other ethnicity Designated as English Language Learner (ELL) Identified mild developmental delay or disability Enrolled in full-day Pre-K classrooms 50 67 30 1 1 44 4 37 48 79 17 2 <1 57 4 40 47 82 15 2 1 60 3 4211 ANALYZING IMPACT ON KINDERGARTEN READINESS SRI examined kindergarten readiness using Teaching Strategies (TS) GOLD\u2122 scores from the spring before the child entered kindergarten.12 TS GOLD is a teacher- reported measure of young children\u2019s skills across six developmental domains: literacy, language, mathematics, cognitive development, socio-emotional well-being, and physical health. We are using this measure because it was the only available child assessment that CPS routinely collects and was therefore selected as the measure of kindergarten readiness by the PFS planning team.13 It is used routinely in the CPS preschool programs, and there was no alternative CPS-wide measure of kindergarten readiness that is completed as children are entering kindergarten in the fall of the school year at the time of the PFS implementation design. 11 Half- or full-day status was unknown for 7% of the 637 students. 12 The TS GOLD assessment was developed to monitor the skills of children attending a child care or preschool program so teachers can adjust their instructional strategies depending on the children\u2019s progress on a variety of skills and behaviors. TS GOLD\u2122 was not developed as a measure of kindergarten readiness. 13 The methodology involved in most SIB projects relies on use of available administrative data rather than additional data collection to evaluate outcomes. PFS-CPC: Report for 2016\u201317 March 2018 13 Calculating Impact on Kindergarten Readiness As described, we calculated the impact of CPC on kindergarten readiness by comparing children\u2019s performance on the measure with national norms. We selected this approach for two reasons. First, adequate normative data enables us to identify whether children in the sample were performing at or above a widely accepted standard. Second, creating an appropriate comparison group within CPS was not possible; kindergarten readiness data are not available for children without preschool experience (our comparison group), given that the kindergarten readiness measure is collected during the spring of pre-K in Chicago Public Schools. The metric for kindergarten readiness is the percentage of children who are performing at or above national trends across at least five of these six domains.14 A child is determined to be ready for kindergarten if he or she is rated by the teacher as demonstrating levels of skill or knowledge that are expected for a child at a particular age; the reference point for such expectations come from the observed abilities of other children from a representative sample of same-aged peers in the United States. We categorized children as kindergarten ready on each domain by the criterion of meeting or exceeding the 50% percentile on the standard score for that domain using scores from the most recently published technical manual (a). Then, we calculated the percentage of children who met this criterion on five of six domains.15 ANALYZING IMPACT ON SPECIAL EDUCATION PLACEMENT Special education placement was determined using data on children\u2019s disability designation at any time during the child\u2019s kindergarten year. Children were classified into three categories: children receiving special education services for mild disability, 14 No data are available on which domains of the TS GOLD assessment to use to reliably and validly determine kindergarten readiness. The decision to define kindergarten readiness as performing at or above national trends on five of six domains (and not four of six) aligns with the National Research Council\u2019s definition of school readiness, which includes age-level skills across multiple domains (). The threshold of five of six domains also takes into account that a child may not meet a standard for all six domains, especially in the spring of preschool, as these skills are emerging during this time period. 15 Teacher-reported assessments have some unknown sources of variability, and the GOLD assessment is no different. Research on the GOLD assessment indicates that between 17% and 25% of the variance in scale scores is accounted for by unmeasured differences between classroom and teachers, including rater effects (). At this time, there is no consensus on how to calculate kindergarten readiness using GOLD assessment scores. Thus, we continue to use the a priori definition and benchmark. PFS-CPC: Report for 2016\u201317 March 2018 14 children receiving special education services for severe disability, and children not receiving special education services (no IEP). Recall that our hypothesis is that high- quality preschool via the CPC program will decrease the chances that children who are at risk will need special education services in the future. Because we are not trying to prevent children with severe disabilities from receiving the special education services they need, we restricted our definition of special education outcomes to children who needed special education for mild delays or disabilities defined as those children who had an IEP for the following: speech and language issue (S/L), developmental delay (DD), emotional disturbance (ED),16 which is the only information available in the administrative dataset describing the type and severity of disability. This helps avoid the perverse incentive of withholding special education services from children with severe disabilities. We report the special education placement outcomes during kindergarten for children who attended CPC preschool in 2014\u201315 versus their peers who did not attend any preschool administered by CPS. The effect size of the impact on special education placement for Cohort 1 was calculated using the risk difference approach. The equation is the following: \ud835\udc38\ud835\udc46(cid:3036),(cid:3047) (cid:3404) \ud835\udc46\ud835\udc43\ud835\udc38\ud835\udc37(cid:3004),(cid:3036),(cid:3047) (cid:3398) \ud835\udc46\ud835\udc43\ud835\udc38\ud835\udc37(cid:3021),(cid:3036),(cid:3047) where ESi,t is the effect size for cohort i in year t, SPEDC,i,t is equal to the average of a binary indicator of special education placement among the no pre-K comparison group for cohort i in year t, and SPEDT,i,t is the average of a binary indicator of special education placement among the intervention group for cohort i in year t. The same calculation will be used for each cohort for each year through sixth grade as described below. Based on conversations with special education experts and reviewing existing CPS data, the consensus by the planning committee is that the vast majority of children who have a disability will be identified by the end of sixth grade (). As a result, after the sixth-grade effect size has been calculated, IFF (or the district) will average the effect size over the last 3 years (fourth, fifth, and sixth grades) and lock in that average effect size for the purposes of calculating payments in grades 7 through 12. This lock-in rate will be calculated separately for each 16 Note that no children were identified as needing special education services for an Emotional Disability or Disturbance (ED) in the intervention cohort or the comparison group. PFS-CPC: Report for 2016\u201317 March 2018 15 intervention cohort. SRI may propose changes to this lock-in methodology in the event that the team determines that it produces skewed results. Any modifications must be approved by CPS, the city of Chicago, the project coordinator, and approved by the lender committee. SELECTING A COMPARISON GROUP For the special education placement outcome, we conducted propensity score analysis to identify an appropriate comparison group that had not received CPS preschool in either school- or community-based settings. Propensity score methods are quasi-experimental approaches that were developed to approximate findings obtained from randomized controlled trials (). They have been used increasingly in analysis of observational data to reduce selection bias in estimating treatment, policy, or intervention effects when randomized controlled trials are not feasible or ethical (1984, 1985). In essence, propensity score methods help to identify a comparison group that mimics what might have been obtained using random assignment. Initial selection To create the initial comparison group for each cohort, we first restricted our data set to all kindergarteners in CPS who were 5 years old or older on September 30, were eligible for free and reduced-price lunch, did not attend preschool in CPS (either in a CPC or other CPS preschool classroom),17 and who were not attending kindergarten at a school with a CPC program.18 For detail about the Cohort 1 comparison group selection, see the previous report for 2015\u201316. For the Cohort 2 comparison group, our potential sample was approximately 7,928 or about one-third of the total number of children enrolled in kindergarten in CPS in 2016\u201317 (approximately 23,000). The sample was further reduced to 7,126 who had no missing data on any baseline covariates and outcome. 17 The evaluation team only had data about whether children had received preschool in CPC or other CPS-sponsored classrooms. As such, it is possible that some children in this comparison group may have participated in a preschool program such as Head Start outside of the district in a community- based setting. 18 The initial planning team had suggested also excluding children who were enrolled in charter schools, magnet or selective enrollment schools, and schools that serve exclusively a special education population. However, there are no elementary schools that serve exclusively a special education population. The evaluation team did not think it necessary to exclude children who attended charter or magnet schools because we did not have adequate information showing these were higher-performing schools than the \u201cbusiness as usual\u201d elementary schools children could have attended. PFS-CPC: Report for 2016\u201317 March 2018 16 We then applied propensity score analysis to identify a propensity score for each of the 7,126 children eligible to be in the comparison group. The propensity score is the predicted probability of being in an intervention based on a set of potentially confounding covariates (e.g., child and neighborhood background characteristics; see below for more detail) using logistic regression. The key advantage of using a propensity score is the ability to balance intervention and comparison groups on a large number of covariates by using a linear combination of covariates for a single score. Simply, the propensity score is a measure of how similar children from the comparison group are to the children in the intervention group on a large number of covariates. We applied propensity score weighting (PSW) because this approach has the advantage of maximizing power by including all eligible children in the comparison group sample rather than only matched cases. It weights each comparison child by their propensity score, a measure of similarity between intervention and comparison on a large number of covariates; comparison children were weighted higher if they were more similar to intervention children and were weighted lower if they were to less similar to Intervention children. The way PSW works is that each child is given a weight derived from logistic regression which represents how closely the child matches the intervention group; in this case, how well-matched they were on the selected child and neighborhood characteristics. The weight is not related to the outcome (special education status). This propensity score weighting approach adjusts for confounds using inverse propensity score estimators, as recommended by , , and . From the logistic regression model, we calculated a probability that the comparison child would be in the intervention group. The weight for intervention students was 1.0, and the weight for comparison students was equal to their propensity score transformed to an odds scale (pi/1-pi) (; ). In the PSW approach, children in the comparison group who are more like the intervention group children are weighted more heavily, and comparison group children less like the intervention group children get smaller weights. Outcome data PFS-CPC: Report for 2016\u201317 March 2018 17 for each child is given a numerical weight based on the child\u2019s baseline demographic characteristics. For example, if the intervention group has a higher proportion of Hispanic children and a lower proportion of White children than the comparison group, the Hispanic children in the comparison group will be weighted more and the white children in the comparison group will be weighted less.19 The final comparison sample comprises all 7,126 children, weighted to closely match children in the intervention group. An important aspect of estimating the propensity score is the selection of covariates. Researchers suggest that covariates that affect both intervention participation and outcomes should be included in the estimation of the propensity score (; ; ; ). Covariates included in this study were selected based on findings from studies that have examined neighborhood effects associated with child outcomes (; ; ; ten ). Our covariates came from four data sources: school district data for the 2015-2016 school year, census tract data for 2013, community area public health data for 2009, and police district crime report data for 2010. The PSW did result in well-match intervention and comparison groups. Additional details about the PSW analysis for the Cohort 2 comparison group are contained in Appendix C. Adjusting for attrition (Cohort 1 First grade, 2016\u201317) The initial selection of the comparison group for Cohort 1 was described in the Year 2 report (April 2017). In Year 3, Cohort 1 and their comparison group moved into first grade, and our analyses of their first grade special education outcome were adjusted to account for attrition20 as students left the district after their kindergarten year. As shown in Exhibit 6, there were high rates of attrition between kindergarten and first grade in both Cohort 1 (14%) and their comparison group (25%). To make sure the groups were still similar after this attrition, we re-weighted the remaining 7,076 19 This is an oversimplification because the approach actually uses all of the demographic data available to create the weight for each comparison child. That is, instead of matching on each of the covariates; children are given a weight that is based on the combination of all of the covariates. 20 Attrition here is defined as students not attending CPS in the expected grade level in a particular school year. Children are included if they are no longer enrolled in the school district or are enrolled in another grade. PFS-CPC: Report for 2016\u201317 March 2018 18 comparison children to match the remaining 256 Cohort 1 children on the selected child and neighborhood background characteristics. Additional details about the re- weighting analysis for the Cohort 1 comparison group are contained in Appendix C. Exhibit 6. Annual attrition, by Cohort and comparison group Group School Year 2014\u201315 School Year 2015\u201316 School Year 2016\u201317 Cohort 1 and their comparison group Cohort 1 Preschool n = 313 original sample Comparison n/a Cohort 2 and their comparison group Cohort 2 n/a n/a Kindergarten n = 297 5% attrition Kindergarten n = 9,445 original sample Preschool n = 654 original sample First Grade n = 25621 14% attrition First Grade n = 7,076 25% attrition Kindergarten n = 595 9% attrition Kindergarten n = 7,126 original sample Comparison n/a Note: Attrition rates are calculated using the number of students enrolled in that grade at the end of the designated school year as the numerator and the number of students enrolled the previous year as the denominator. Results We first present the kindergarten readiness results for Cohort 3 and then the results for kindergarten special education placement outcomes for Cohort 2 children and first grade special education placement for Cohort 1 children. Kindergarten Readiness COHORT 3 KINDERGARTEN READINESS The TS GOLD\u2122 Spring 2017 data were not available for 90 of the 637 children in Cohort 3,22 resulting in a final analytic sample for this outcome of 547 children (86% of the 637 children), which we used to calculate kindergarten readiness. Of those 547 21 Of the 313 children selected for Cohort 1 in their PK year (2014\u201315), 256 were enrolled in CPS at the end of their first grade year, for a Cohort 1 first grade retention rate of 81.79%. 22 These children were missing data either because teachers rated their Literacy and Language domains in Spanish, for which scale scores are not available (n = 76), they could not be found in the GOLD\u2122 system (n = 1), or their GOLD\u2122 assessment was incomplete for unknown reasons (n = 13). PFS-CPC: Report for 2016\u201317 March 2018 19 children, 44% (44.24%) were considered ready for kindergarten, where \u201creadiness\u201d was defined as scoring at or above the 50th percentile on at least five of the following six domains: literacy, language, mathematics, cognitive development, socio-emotional well-being, and physical health. One-fifth (20%) of the 514 children did not score at or above the 50th percentile for any domain, with 8% meeting the criteria for only one domain, 9% for two domains, 7% for three domains, and 13% for four domains (Exhibits 7 and 8). Additionally, children who attended full-day CPC preschool had higher rates of kindergarten readiness (54%) compared to children who attended half- day CPC preschool (32%). Exhibit 7. Percent of Children Meeting Kindergarten Readiness Criteria, Across Domains, by Cohort Number of domains meeting or exceeding the 50th percentile Cohort 1 2014\u201315 (percent) Cohort 2 2015\u201316 (percent) Cohort 3 2016\u201317 (percent) 0 1 2 3 4 5 6 5 or 6 9% 3% 7% 12% 9% 10% 51% 61% 14% 11% 11% 11% 11% 19% 23% 42% 19% 7% 9% 7% 13% 15% 29% 44% PFS-CPC: Report for 2016\u201317 March 2018 20 Exhibit 8. Percent of Children Meeting Kindergarten Readiness Criteria, by Cohort and Domain Domain Cohort 1 2014\u201315 (percent) Cohort 2 2015\u201316 (percent) Cohort 3 2016\u201317 (percent) Cognitive Language Literacy Math Physical Social-emotional 82% 66% 75% 81% 60% 79% 65% 50% 62% 72% 30% 63% 65% 53% 60% 68% 42% 61% Special Education Placement COHORT 2 KINDERGARTEN SPECIAL EDUCATION PLACEMENT After ensuring the two groups were equivalent on child and neighborhood characteristics and weighting appropriately, we examined the kindergarten special education placement rates for mild and moderate developmental delay or disability for Cohort 2 and its comparison group.23 The special education rate was lower in the intervention group than the comparison group (3.36% for Cohort 2 in kindergarten and 5.09% for children in the comparison group in kindergarten). This is a difference of 1.73% percent. All of these children were either categorized as having developmental delay or speech and language impairment. COHORT 1 FIRST GRADE SPECIAL EDUCATION PLACEMENT After ensuring the two groups were equivalent on child and neighborhood characteristics and weighting appropriately, we examined the first grade special education placement rates for mild and moderate developmental delay or disability for Cohort 1 and its comparison group. The special education rate was lower in the intervention group than the comparison group (3.13% for Cohort 1 in first grade and 6.17% for children in the comparison group in first grade). This is a difference of 3.04 23 All students in the Cohort 1 and Cohort 2 comparison groups with an IEP were identified during their kindergarten year. PFS-CPC: Report for 2016\u201317 March 2018 21 percent. All of these children were either categorized as having developmental delay or speech and language impairment. Discussion Sociodemographic risk factors\u2014the most extensively studied of which is poverty\u2014are highly predictive of developmental trajectories. Children from low-socioeconomic- status (SES) households are less likely to enter kindergarten with the pre-academic and social skills needed to succeed and are more likely to require later special education services later (; ; ; ). Early childhood programs potentially mitigate the risks endemic to children from disadvantaged backgrounds, with studies showing that the strongest positive short- and long-term outcomes result from intensive and comprehensive programs targeting low-income children (; Institute for Research on ; ). Indeed, prior studies have highlighted early childhood as a critical and sensitive period for the development of brain architecture and neurochemistry (e.g., ) and subsequent academic and socio-emotional well-being (). First implemented in Chicago in 1967, the CPC model has a long history of offering innovative, targeted approaches to school reform including a comprehensive system of educational and family support services during the preschool through third grade years for young children in low-income neighborhoods. The intervention promoted young children\u2019s school success through language enrichment and intensive, mandatory parent involvement within a system of comprehensive support services for children and their families. The CPC model, integrated into the CPS system since its inception in 1967, has been systematically evaluated for its impact on child and family outcomes. A notable by-product of the CPC program\u2019s efforts is the Chicago Longitudinal Study (CLS), which has supported researchers\u2019 efforts to develop a deeper understanding of the \u201cactive\u201d ingredients of early dual-generation interventions and early childhood interventions more generally. The following are key relevant findings from analyses conducted on the CLS samples: PFS-CPC: Report for 2016\u201317 March 2018 22 \uf0b7 Nearly half of children (44%) attending a CPC for one year were considered ready for kindergarten compared with 28% of children who had no preschool (unpublished data, A. Reynolds, personal communication, February 25, 2015). \uf0b7 Children having one or two years of CPC preschool experience were less likely than those having no CPC preschool experience to have received special education throughout the elementary school years (). The expectation for the PFS-funded expansion of CPC to new sites in CPS and increasing the number of available CPC preschool slots at existing sites in CPS was based on previous research showing positive impacts on kindergarten readiness and school achievement, and reductions in special education placements over time. Other new CPC data also show positive impacts on kindergarten readiness (). In a meta-analysis of 9 high-quality experimental and quasi-experimental studies conducted in the last 50 years find on average, participation in ECE leads to reductions in special education placement, about 8% fewer children need special education services when averaged across studies (). Below we discuss the findings from the year 3 evaluation outcomes, including some of the limitations in interpreting the data. Kindergarten Readiness Findings To put the findings in context, we ask four questions of the kindergarten readiness data. First, is the assessment a reliable and valid measure of children\u2019s kindergarten measure and how much error might exist in measuring children\u2019s \u201ctrue\u201d kindergarten readiness? Second, to what extent are our findings similar to those of other CPC and CLS data? Third, to what extent are our findings similar to the ECLS-K data for the general population and for children from low-income families? Finally, what might explain the decrease in the percentage of children ready for kindergarten in the two cohorts of children from year 1 to year 2 and from year 1 to year 3? IS THE ASSESSMENT A RELIABLE AND VALID MEASURE OF CHILDREN\u2019S KINDERGARTEN READINESS? It is important to understand the current context of assessing young children\u2019s kindergarten readiness. Currently, there is no summative assessment tool that is considered a \u2018gold standard\u2019 for measuring kindergarten readiness. All assessments, whether they involve teacher ratings or direct assessments of young children\u2019s abilities and skills, are prone to some measurement error. Direct assessments are PFS-CPC: Report for 2016\u201317 March 2018 23 limited in that they only assess children at a single time point and often only assess a very small set of skills (e.g., counting, alphabet recognition) administered and scored based on performance on a highly defined set of items that do not reflect the full spectrum of foundational skills needed to be ready for kindergarten and succeed in school. Teacher ratings that are based on longer periods of observation across multiple settings can be a more accurate representation of children\u2019s skills and behaviors. The developers of the TS GOLD\u2122 recommend certain kinds of trainings to help teachers use the tool as well as procedures to ensure the accuracy of ratings (e.g., checking inter-rater reliability). Some aspects of the TS GOLD\u2122 measure show strong psychometrics. For example, the developers have published analyses showing strong internal reliability (Cronbach\u2019s alpha reliability coefficients = .94 - .97) which suggests that the items are correlated (i.e., a child who scores high on one item has a high probability of scoring high on another item (). There is limited evidence, however, for test-retest or inter-rater reliability on the TS GOLD\u2122. Understandably, high test-retest reliability may not be something you would expect from this measure as children develop and mature very rapidly in the first five years, especially children participating in a preschool program. However, we would want to have higher inter-rater reliability, meaning different raters (in this case, teachers) would tend to rate the children the same way given the same information and observation window for those two raters. There are limited data, however, on whether this measure has moderate to high interrater reliability. For example, correlations between the ratings of a master trainer and ratings of teachers who were current users of the system were high (between .80 and .90) suggesting that when teachers are adequately trained (in this case, received a full two days of training) they can demonstrate good reliability when making ratings of the same child (). There is some evidence that the measure has validity, meaning it measures what it is intended to measure. One way to assess the measure\u2019s validity is to examine whether children with a known delay or disability perform lower on the ratings when compared to children who do not have identified delays or disabilities. The developers have published data showing children with identified disabilities have lower TS GOLD\u2122 scores when compared with their typically developing peers and they develop at a slower rate (b). A different way to examine PFS-CPC: Report for 2016\u201317 March 2018 24 validity is to test whether teacher ratings are correlated to independent direct assessments of children\u2019s development. The correlations between TS GOLD\u2122 domain scores and independent direct assessment and other teacher rating measures are moderate (in the range of .3 to .5) suggesting they may be measuring different aspects of development (; ; ). In addition, to our knowledge, validation studies that examine predictive relationships have not been conducted (i.e., how well TS GOLD\u2122 assessment ratings predict later academic achievement and behavior in kindergarten and beyond). Given that our sample included many children who are ELLs, it is important to understand the validity of the use of the TS GOLD\u2122 with that population.  published data that provide some empirical evidence supporting the validity for the TS GOLD\u2122 domains and learning objectives for typically developing children, as well as English-language learners and for those children identified with special needs or disabilities. In other words, this observation- based teacher rating assessment tool measures the construct domains in the same way across various subgroups of children 3 to 5 years old. These studies were conducted with samples of teachers who had been trained to reliability. For the measure to be used with children who have very limited English abilities, the teacher must be bilingual in both English and the child\u2019s native language and/or be able to document children\u2019s skills and abilities using information from a bilingual teacher assistant or family members. If the teacher is not bilingual and/or has not gathered additional documentation and observation data from other staff, it is possible that language barriers could influence the accuracy of their assessment, raising the possibility that children\u2019s abilities could be either under- or over-estimated. TO WHAT EXTENT ARE THE PFS-CPC KINDERGARTEN READINESS FINDINGS SIMILAR TO THOSE OF OTHER CPC AND CLS DATA? More recently, Reynolds and colleagues (2014) published data in a peer-reviewed journal showing that 80.9% of children attending full-day CPC classrooms (n = 409) and 58.7% of children attending part-day CPC classrooms (n = 573) were considered kindergarten-ready when kindergarten-readiness was defined as meeting the national norm on four of the six TS GOLD\u2122 domains. Additionally, full-day participants demonstrated higher average levels of skill mastery in the domains of language, PFS-CPC: Report for 2016\u201317 March 2018 25 mathematics, socio-emotional development, and physical health (but not for literacy and cognitive development). Reynolds and colleagues (2014) report a higher proportion of children who are kindergarten ready than that reported here, but use a less stringent standard for \u201creadiness,\u201d i.e., a threshold of proficiency on four compared with five of the TS GOLD\u2122 domains; five was the standard used for the current evaluation. If we had used that less stringent standard of 4 of 6 domains, an additional 9% would meet the kindergarten readiness criteria in Cohort 1, for a total of 70%, an additional 11% in Cohort 2 for a total of 53%, and an additional 13% in Cohort 3 for a total 57% (see Exhibit 7). Kindergarten readiness rates in all three cohorts are similar or better than the previous CLS study findings for this outcome, but the percentage of children in Cohort 2 and 3 meeting kindergarten readiness benchmarks is lower than other contemporary studies of CPC and lower than the percentage found for Cohort 1. Potential explanations for these differences are discussed in more detail below. TO WHAT EXTENT ARE PFS-CPC FINDINGS SIMILAR TO NATIONALLY REPRESENTATIVE STUDIES OF KINDERGARTEN READINESS AND FOR CHILDREN FROM LOW-INCOME FAMILIES? Data from the contemporary, nationally representative sample of ECLS-K24 children and using a single measure of kindergarten readiness which is similar to that of this report indicate rates of school or kindergarten readiness that are typically less than 50% for children from economically disadvantaged households (). In comparison, the same report showed that 75% of children from more economically advantaged households (i.e., moderate to high income households) were considered ready for kindergarten. Other publicly available reports produced by states that are using a kindergarten readiness assessment show considerable variability given the different ways to measure kindergarten readiness. The state of Washington uses a modified version of the TS GOLD\u2122 assessment and recently published data from their kindergarten entry assessment study showing that 31% of entering kindergarteners from low-income households met the benchmarks25 on all six domains \u2013 what they refer to as \u201cfull\u201d readiness (State of Washington, n.d.). About 24 ECLS-K is a contemporary longitudinal dataset that draws from a nationally representative sample; includes direct assessments of children\u2019s skills at kindergarten entry (cf. ; ). 25 It is unclear what benchmarks on the TS GOLD\u2122 assessment the Washington study uses. PFS-CPC: Report for 2016\u201317 March 2018 26 half of Cohort 1 (51%), about one-fifth of Cohort 2 (23%) and nearly one-third of Cohort 3 children (29%) demonstrated readiness in all domains (see Exhibit 8). About 72% of children (across income levels) met the benchmarks for at least 4 domains in Washington state (State of Washington, n.d.). In this evaluation, 70% of children in Cohort 1, 53% of children in Cohort 2, and 57% of children in Cohort 3 (all low- income) met the benchmarks in at least 4 of the 6 domains. Thus, the rates of kindergarten readiness found for all three cohorts are similar to what has been found in national and state studies. WHAT EXPLAINS THE DECREASE IN KINDERGARTEN READINESS IN THE COHORTS OF CHILDREN FROM YEAR 1 TO YEAR 2 AND YEAR 3? There is much larger year-to-year variation than expected in the percentages of children identified as meeting the kindergarten readiness criterion in Cohort 1 versus in both Cohort 2 and Cohort 3. That is, one would expect the rates to be similar in the two cohorts if three factors were similar from year to year: schools were serving the same or very similar populations of children; all teachers in both cohorts received the same type and quality of training and reliability checks to reliably complete the TS GOLD\u2122 ratings (including new teachers who might need more training and practice in rating children reliably); and there were no major programmatic changes in how the CPC programs were implemented (e.g., instructional practices, curricula used, etc.) at each site from year 1 to year 2. If these were all similar from year 1 to year 2, then the only explanation for these differences would be that the assessment tool has a significant degree of unreliability. Finally, it is possible any combination of these four factors could explain the year-to-year variability, and different combinations of these factors might explain the year-to-year change at different sites.26 SRI conducted additional analyses in spring 2017 to examine if and to what degree these factors might explain the decrease in percentage of children who are deemed kindergarten ready in Cohort 2 compared with Cohort 1. The analyses also apply to differences in kindergarten readiness from Cohort 1 to Cohort 3. Are the sites serving a different population? There were some differences in the demographic characteristics served in Cohort 1 versus Cohorts 2 and 3. Most significantly, the number and percentage of children 26 CPS is exploring these factors related to teacher training and program implementation. PFS-CPC: Report for 2016\u201317 March 2018 27 who are designated as English Language Learners has increased across cohorts (Exhibit 5), from 44% in Cohort 1 to 57% in Cohort 2 and 60% in Cohort 3. There were a larger number of ELLs served in year 2 and year 3 and it could be harder to reliably assess these children with the TS GOLD\u2122. Some children who are ELLs could be rated on their English language and literacy abilities while other children could not. The TS GOLD\u2122 developers have provided guidance on whether or not children\u2019s language and literacy skills can be rated in English. We also found that across Cohorts 1 and 2, the percentage of children meeting the Kindergarten readiness benchmark differs significantly by ELL status: 54% of all non- ELLs meet the 5 or 6 criterion compared with 42% of all ELLs (p < .001). Since Cohort 2 has more ELLs than Cohort 1, that difference might partially explain the lower rate of kindergarten readiness in Cohort 2 compared with Cohort 1 as children who are learning two languages may take longer to demonstrate proficiency in any of these domains.27 This same phenomenon applies to Cohort 3; however, we did not test the differences. Did all teachers receive the same training and reliability checks? Although SRI does not collect information on teacher training and turnover, we did examine statistically the percentage of variance in children\u2019s scores that can be attributed to child, teacher, and school factors which helps us understand if the level of teacher effects or site effects is greater than what we would expect on a teacher rating. On the TS GOLD\u2122 assessment, children receive a score on each of six domains. The assumption is that these scores represents the child\u2019s ability in the area measured and that a child\u2019s ability would be measured the same no matter which teacher completed the assessment. To test if this assumption is true, we can estimate the degree to which any child\u2019s score can be predicted by the teacher who completed the TS GOLD\u2122. From other studies using TS GOLD\u2122, we expect the rater to predict about 29 to 35% of the variance in a group of children\u2019s scores (b). In the Year 2 data for the current study, the rater predicted 32 to 53% of the variance in children\u2019s scores depending on the domain. This amount of variation is more than the expected amount. This measurement error reduces the 27 We did not examine fall to spring gains for ELLs and non-ELLs, so we do not know whether ELLS are making good growth on the skills that are rated but just do not gain enough to meet the kindergarten readiness benchmark that we set. PFS-CPC: Report for 2016\u201317 March 2018 28 reliability of the scores. As scores become less reliable, it is more difficult to estimate the impact of an intervention on the ability being measured. There should be consistency in how different teachers rate the children. You would expect children with the same abilities to be rated similarly by different teachers. These analyses might reflect teacher training and turnover factors and these are addressed in greater detail by the CPS/city of Chicago program teams in an addendum. Did CPC implementation vary from year to year? There was a surprisingly large range in the percentage of children deemed ready for kindergarten across sites and across cohorts (24% to 79%). One factor that might influence these site differences in kindergarten readiness could be site-level difference in implementation of the CPC model. For example, unobserved site factors may influence training in the CPC model, the ways that the CPC program is implemented, and other program components that may influence teacher ratings and/or children\u2019s kindergarten readiness (e.g., changes instructional practices). While the evaluation did not collect any data on site implementation, these factors are being explored by the implementation partners, CPS and the city of Chicago, who are conducting additional analyses about the contextual site factors that may have impacted implementation. Special Education Placement Findings Based on the extensive CLS analyses as well as reviewing existing data for CPS in the years leading up to the PFS-CPC project, the PFS project was built on the hypothesis that high-quality preschool through the CPC program would help prevent or reduce the need for special education in the intervention group. We found that the special education placement rate in kindergarten for the Cohort 2 intervention group was lower than the rate for the comparison group (3.36% versus 5.09%). This is a difference of 1.73% in the rate of special education use between the two groups, and is an 51% decrease for the intervention group relative to the comparison group. This is a much larger decrease than found in the Cohort 1 kindergarten special education outcomes from last year. That is, we found that the special education placement rate in kindergarten for the Cohort 1 intervention group was slightly lower than the rate for the comparison group (4.38% versus 4.94%). This is a difference of 0.56% in the rate of special education use between the two groups, and is an 11% decrease for the intervention group relative to the comparison group. PFS-CPC: Report for 2016\u201317 March 2018 29 years. For the Cohort 1 special education placement outcomes at the end of first grade, we found that the special education placement rate for the Cohort 1 intervention group was lower than the rate for the comparison group (3.31% versus 6.17%). This is a difference of 3.04% in the rate of special education use between the two groups at the end of first grade, and is a 92% decrease for the intervention group relative to the comparison group. These results show that the difference in special education placements in favor of the intervention group is increasing over the early school We want to acknowledge a few data limitations. As described earlier, SRI was unable to identify with certainty children from the comparison group who may have received pre-K programming in non-CPS funded settings in order to exclude them from the comparison group sample. We did however exclude from the comparison group all children who had a CPS identification number when they entered kindergarten, which serves as an indication that they attended a CPS preschool program and/or were receiving services from the school district. In addition, with the propensity score weighting procedure, we used a large comparison sample to reduce the impact of possible preschool attendance on our estimation of comparison group outcomes. That is, there is likely some proportion of children in the comparison group samples who did attend some type of public preschool program (e.g., Head Start) or private child care program using child care subsidies and/or tuition. It is not clear how inclusion of some children with preschool experience in the comparison group is affecting the special education rate in that group. We also want to note that in the original design of this PFS project using the CPC model, the planning team decided that the targeted population was high risk children but not necessarily those with identified disabilities prior to participation in preschool. Therefore, children who were identified prior to enrollment in PreK were excluded from the sample that is tracked over time. Finally, the evaluation team used disability categories to define who had a mild versus a severe disability, based on the assumption that the intervention was only targeting prevention of the need for later special education services for children at- risk of a mild disability. Because the disability categories do not provide information on the severity of a child\u2019s disability or delay, the team used additional information about placement in special day classes and blended classrooms to identify children PFS-CPC: Report for 2016\u201317 March 2018 30 as having more \u201csevere\u201d delays or disabilities. While the information sources used are proxies for identifying those with \u201csevere\u201d delays or disabilities who were excluded from the analyses, rather than direct measurements of the severity of a child\u2019s disability, they were agreed upon with input from CPS as appropriate proxies to identify severity. We recognize that some children with developmental delay may eventually develop a more severe disorder and need services as could some of the children with speech and language delays and emotional disturbances. To put the findings about rates of special education placement for Cohort 1 and comparison group samples into context, we searched for comparable data and organized our search around three questions. First, to what extent are the findings similar to those reported in the Chicago Longitudinal Study of the earlier CPC cohort? Second, how do kindergarten special education placement rates for the intervention and comparison groups compare with kindergarten special education placement rates in the Chicago Public Schools? Third, to what extent are the findings similar to the national data about special education placement rates for children who attend preschool versus those who do not? TO WHAT EXTENT ARE THE FINDINGS SIMILAR TO THOSE REPORTED IN THE CHICAGO LONGITUDINAL STUDY OF THE EARLIER CPC COHORT? Studies of the Chicago Longitudinal Study (CLS) cohort of children who attended CPC preschool in 1984 showed that special education placement rates were lower for CPC recipients compared with children who did not participate in CPC preschool. In one CLS analysis that looked at children 6 to 18 years old, CPC participants had an average special education placement rate of 14.4% compared with 24.6% for children in the comparison group (). This rate was calculated by averaging rates across school years, and therefore is not directly comparable to the kindergarten special education rates described in this report. In another CLS analysis that compared average special education placement rates from school entry through eighth grade for children who had attended a CPC preschool with a comparison group, special education placement rates were 12.5% versus 18.4%, respectively (). Significant differences in special education placement rates between children in the CLS who did and did not attend CPC preschool programs emerged as early as first grade (0.5% versus 3.2%) (). We see difference in special education rates also emerging by the end of first grade, a 92% PFS-CPC: Report for 2016\u201317 March 2018 31 decrease for the intervention group relative to the comparison group. These earlier CLS findings suggest that special education rates may rise over the early elementary grades and we may continue detect a positive intervention effect for reduced special education placement from attendance in CPC preschool across all the early grades.28 Other changes in how children are identified and placed in special education have occurred since the 1990s when these latter analyses were completed making these comparisons less appropriate than more contemporary data. These changes include but are not limited to improvements in early screening and programming prior to entering kindergarten as well as during the early elementary school years. Such improvements may mean that contemporary children who would have needed special education in the past are being identified during preschool or the early elementary grades and given more intensive or focused supports that can prevent those early difficulties from becoming more severe delays and learning problems requiring special education services. The percentage of children needing special education for developmental delay or speech/language issues ranged from 4% in both groups in kindergarten for Cohort 1 to close to 6% for the comparison group in first grade. Interestingly, the majority of children in the intervention cohort were identified during the preschool year while enrolled in CPC preschool classrooms. Because of changes in how children are identified for services and how important assessment and early intervention are in early care and education settings, we believe as part of best practices in a high- quality preschool classroom, more children may be identified for services (and appropriately so) early in their school careers than may have occurred previously when the CLS was conducted. The hypothesized role of CPC in preventing or reducing the need for special education is still valid; however, in contemporary settings, there may be an initial increase in identification and placement before we see long-term reductions and/or average reductions in this outcome. HOW DO KINDERGARTEN SPECIAL EDUCATION PLACEMENT RATES FOR THE INTERVENTION AND COMPARISON GROUPS COMPARE WITH KINDERGARTEN SPECIAL EDUCATION PLACEMENT RATES IN CHICAGO PUBLIC SCHOOLS? 28 Support for this suggestion comes from earlier CPC studies that found that students with extended CPC program participation (through second or third grade) had lower rates of special education placements than CPC students having fewer years of intervention through middle () and high school (). PFS-CPC: Report for 2016\u201317 March 2018 32 In the previous 2015\u201316 school year, the kindergarten special education placement rate for CPS overall for what we are identifying as mild delays and disorders was 7.4%. Our findings show that both Cohort 1 and their comparison group have rates that are lower than the rate in CPS overall during the same year. We do not have a good explanation for this difference. Historical data from CPS demonstrate that special education placement rates during preschool have been relatively high for children attending CPS preschool (10\u201314% for the last 5 school years)29 and that the overall CPS rates decrease in kindergarten (7\u20138%) and steadily climb through elementary and middle school grades; by third grade, for example, overall special education rates in CPS have been 10\u201311% for the last 5 school years (). These special education rates in CPS suggest that we will see increases in special education rates as children move through the early elementary years, probably for both groups. But we hypothesize that the rate for the intervention group will increase at a slower rate and be lower than the rate in the comparison group in the later elementary years if the preschool CPC experiences have helped intervention group children have better developmental trajectories. Continued follow- up of the cohorts will address this question.30 TO WHAT EXTENT ARE THE FINDINGS SIMILAR TO THE NATIONAL DATA ABOUT SPECIAL EDUCATION PLACEMENT RATES FOR CHILDREN WHO ATTEND PRESCHOOL VERSUS THOSE WHO DO NOT? Data collected annually from every state as part of federal reporting required under the Individual with Disabilities Education Act by the Office of Special Education Programs give us another perspective on the special education rates. These national data indicate that 7% of children were receiving special education services at age 5, the kindergarten year for most students (National Center for ). Other data from the nationally representative Head Start Family and Child Experiences Survey (FACES) for children participating in Head Start preschool programs () and the nationally representative ECLS-B study ()31 found rates higher than those for our comparison 29 For the previous 2015-16 school year, we found that for low-income children who had attended any CPS preschool, the overall IEP special education rate in kindergarten was 13.7% (10.7% for mild and 3% for not mild delays and disorders). 30 The special education rates in CPS preschool may be higher than rates for kindergarten because children identified with a delay or disability prior to kindergarten would be likely to be referred to CPS and when determined to be eligible for an IEP, they would be served in a CPS preschool program. 31 ECLS-B children entered kindergarten in 2006 or 2007. PFS-CPC: Report for 2016\u201317 March 2018 33 sample (8% and 7%, respectively). However, findings from the FACES study also suggest that more children in Head Start without an Individual Education Plan (IEP) meet other criteria for disability or delay than are served (about 33% meet criteria indicative of delays such as very low assessment scores on standard measures, but only 8% had an IEP and were receiving special education services) (). These national data and other research suggest that children from low-SES families are at greater risk of developmental delay and low levels of kindergarten readiness but may be less likely than higher SES children to be receiving special education services in early childhood (). Taken together, these other data suggest that the rates we are seeing in both the intervention and comparison groups are lower that would be expected for our high risk samples. Limitations The evaluation is limited to data already collected in the district data and as such, must use for a kindergarten readiness measure, an assessment tool that was not developed for these purposes. The TS GOLD\u2122 assessment is vulnerable to large (and maybe small) changes in training protocols and teacher turnover and both reliability and validity may suffer. In addition, the use of the TS GOLD\u2122 measure with ELL populations is problematic because some ELL children can be assessed on all six domains in English while others cannot. Furthermore, there are not scale scores for children who have the TS GOLD\u2122 language and literacy assessment domains in Spanish and therefore we did not have complete data needed for making the kindergarten readiness determination for those children. Use of a teacher-report measure as the indicator of kindergarten readiness can be seen as a limitation of this study. As described above, teacher effects or bias is also a limitation in the evaluation. The accuracy of teacher ratings of young children\u2019s behavior has been questioned by some early childhood researchers (; ). Additionally, there is a need in the field for more research about the amount and types of teacher training and knowledge needed to assess young children reliably and accurately, even while it is widely acknowledged that teacher training and knowledge are critical (Institute of ; National Association Early Childhood Specialists in State Departments of Education & PFS-CPC: Report for 2016\u201317 March 2018 34 National Association for the Education of ; National Association for the Education of ). For the special education outcome at kindergarten, to the best of our ability we created a comparison group that was weighted to match closely the characteristics of children in the intervention cohort. However, both propensity score methods\u2013PSW and PSM\u2013have some disadvantages. One disadvantage is that these methods only account for observed (and observable) covariates. They cannot balance intervention and comparison groups on unobservable characteristics (for example, parent education levels or parent involvement in the children\u2019s early learning). Second, we can only identify those children who attended a CPS-funded preschool program prior to kindergarten. Many entering kindergarten children who meet the income and age criteria may have attended other preschool programs either public (e.g., state-funded preschool outside of the city of Chicago) or private (e.g., using child care subsidies for example). The evaluation team had no way of identifying which children attended these other settings because this information is not routinely collected at kindergarten entry in CPS. Conclusion Together, these findings show that early childhood education in the form of CPC is associated with rates of kindergarten readiness of 61% in Cohort 1, 42% in Cohort 2, and 44% in Cohort 3. The findings also show that there is a significant decrease in special education in kindergarten for the intervention group for Cohort 2. This is a difference of 1.73% in the rate of special education use, is an 51% decrease for the intervention group relative to the comparison group. This also is a much larger decrease than found in the Cohort 1 special education outcomes from last year (a decrease of 11%). While the overall special education rates in both the intervention and comparison group children are very low at the end of kindergarten for both Cohort 1 and Cohort 2, the rates are lower in the intervention group in both cohorts and the rate of the decrease is greater in Cohort 2 (11% versus 51% decrease). The findings also show that at the end of first grade the rate of special education placement for Cohort 1 was lower for the intervention group than for the comparison group (3.31% versus 6.17%), a 92% decrease for the intervention group relative to the comparison group. These first grade results show that the difference in special PFS-CPC: Report for 2016\u201317 March 2018 35 school years. Next Steps education placements in favor of the intervention group is increasing over the early The year 4 report will include kindergarten readiness outcomes for a new group of children in Cohort 4. It will also present data on special education placement rates at the end of kindergarten for Cohort 3 children compared with rates of special education placement in a matched comparison sample of children who did not attend any preschool in CPS. In addition, we will present the continued follow-up data on special education placement rates at the end of first grade for Cohort 2 and its comparison group and special education placement rates at the end of second grade for Cohort 1 and its comparison group. PFS-CPC: Report for 2016\u201317 March 2018 36 "}, {"target_population": "The project serves pre-school children (aged 3- and 4-years old) across 9 sites in the Chicago area. \"CPC INTERVENTION SAMPLE INCLUDED IN ANALYSIS Children were included in the intervention cohorts if they attended one of the PFSCPC [pay-for-success Child-Parent Center] sites that was fully implementing the CPC program during their preschool year, were enrolled in either a full- or half-day pre-K classroom, were not identified as having a severe disability, were income eligible (i.e., eligible to receive free or reduced-price lunch), and were at least 4 years old in September of their preschool year. Additionally, a child needed to have attended a CPC pre-K classroom for at least 66% of the days (not consecutively) in a given school year\u00e2\u20ac\u201da percentage considered a sufficient amount or dose of the intervention to affect child outcomes.\"", "source": ["The Child-Parent Center (CPC) model, one of the longest running early childhoodintervention models in the United States, has produced some of the most robust longtermacademic and social outcomes for children (Reynolds, 2000; Reynolds &Temple, 2008).", "Beginning in January 2012, as part of a U.S. Department ofEducation Investing in Innovation (i3) grant to the University of Minnesota, the city ofChicago and Chicago Public Schools (CPS) received funding to (1) increase thenumber of children who could attend existing CPC sites and (2) increase theavailability of CPC programs by adding 16 new sites.Pay for Success (PFS), previously referred to in this evaluation as a Social ImpactBond (SIB), is a funding mechanism whereby private business and philanthropicpartners purchase Social Impact Bonds (SIBs) to support public programs.Government entities, such as a state\u2019s Department of Education, pay investors onlywhen a program meets its pre-determined outcomes.", "The investors bear the full riskof the investment and if a program fails to meet its goals, taxpayers owe nothing.", "Tothis end, PFS initiatives typically have an independent evaluator to help determinewhether the outcomes have been realized and outcome payments to the privateinvestor need to be made.", "Beginning in 2014\u201315, the IFF Pay for Success projectfunded additional CPC preschool slots at six CPS schools.", "In 2015\u201316, three sites(identified by CPS and approved by the city of Chicago) were added to the PFSproject.", "Nine sites remained in 2016-17 and 2017-18.", "SRI International (SRI) wascontracted to conduct the evaluation of the child outcomes for this project, referred toas the \u201cPFS-CPC project.\u201d The project served four cohorts of preschool childrenacross the nine sites over four school years\u2014Cohort 1: 2014\u201315, Cohort 2: 2015\u201316,Cohort 3: 2016\u201317, and Cohort 4: 2017\u201318.This fourth SRI project evaluation report describes second grade special educationplacement outcomes of Cohort 1 children, first grade special education placementoutcomes of Cohort 2, and kindergarten special education outcomes for Cohort 3.Although this report was to include the kindergarten readiness outcomes for thefourth, and final cohort of preschool children, these data are not available due to achange in the administration and scoring of the early learning assessment used in thedistrict\u2019s preschool program \u2013 Teaching Strategies (TS) GOLD\u2122.", "This unanticipated change is described in greater detail below.", "The report begins with a description ofthe CPC program and its expansion efforts using PFS funding, including evidenceabout the impacts of the CPC program model on children\u2019s school readiness andschool achievement at the beginning of the project.", "Next, we describe the approachto the PFS-CPC program evaluation.", "The last section presents the results of theevaluation for Cohorts 1, 2, 3, and 4.", "We then conclude this report with a briefdiscussion of how the results fit in the larger context of research."], "paper_id": "#17195", "title": "Evaluation Of Child Outcomes In Nine Child-Parent Centers: Report For 201718", "pdf_txt": " Evaluation of Child Outcomes in Nine Child-Parent Centers: Report for 2017\u201318 May 2019 Prepared for: IFF Pay For Success I, LLC 333 S. Wabash Avenue, Suite 2800 Chicago, Illinois 60604 Attention: Dana Lieberman, Sr. Vice President, Capital Solutions E-mail: dlieberman@iff.org Copy to: IFF 333 S. Wabash Ave., Suite 2800. Chicago, Illinois 60604 Attention: Charles M. Biggam III, Chief Legal Counsel E-mail: cbiggam@iff.org Prepared by: SRI International Erika Gaylor Kate Ferguson Mary McCracken Xin Wei Donna Spiker Suggested citation: Gaylor, E., Ferguson, K., McCracken, M., Wei, X., & Spiker, D. (2019). Evaluation of child outcomes in nine Child-Parent Centers: Report for 2017-18. Prepared for IFF Pay for Success I, LLC. Menlo Park, CA: SRI International. PFS-CPC: Report for 2017\u201318 May 2019 ii Contents Background ................................................................................................................................... 1 CPC Program Model ..................................................................................................................... 2 CPC Model Description ............................................................................................................. 2 Expected Outcomes from the CPC Program Model .................................................................. 4 School Readiness .................................................................................................................. 4 Third-Grade Reading and Literacy ........................................................................................ 4 Reduced Special Education Use ........................................................................................... 5 Chicago PFS Project (PFS-CPC Project) .................................................................................. 6 Evaluation Design ......................................................................................................................... 7 Analysis Approach ..................................................................................................................... 9 CPC Intervention Sample Included in Analysis ..................................................................... 9 Analyzing Impact on Kindergarten Readiness ..................................................................... 13 Analyzing Impact on Special Education Placement ............................................................. 15 Selecting a Comparison Group ............................................................................................ 16 Results ........................................................................................................................................ 20 Kindergarten Readiness .......................................................................................................... 21 Cohort 4 Kindergarten Readiness ....................................................................................... 21 Special Education Placement .................................................................................................. 22 Cohort 3 Kindergarten Special Education Placement .......................................................... 22 Cohort 2 First grade Special Education Placement ............................................................. 23 Cohort 1 second grade Special Education Placement ........................................................ 23 Discussion ................................................................................................................................... 24 Kindergarten Readiness Findings ........................................................................................... 26 Special Education Placement Findings ................................................................................... 32 Additional Findings .................................................................................................................. 37 Limitations ............................................................................................................................... 38 Conclusion ............................................................................................................................... 39 References .................................................................................................................................. 41 Appendices ................................................................................................................................. 47 Appendix A: Chicago Child-Parent Center Social Impact Bond Evaluation Plan ................... A-1 Appendix B: Timing of Cohorts .............................................................................................. B-1 Appendix C: Propensity Score Approach ............................................................................... C-1 PFS-CPC: Report for 2017\u201318 May 2019 iii List of Exhibits Exhibit 1. CPC Program Model Components ................................................................................ 3 Exhibit 1. CPC Program Model Components (concluded) ............................................................ 4 Exhibit 2. Description of Participating CPC Sites, by Project Year ............................................... 6 Exhibit 3. Enrollment at PFS-funded CPC sites, by year ............................................................ 11 Exhibit 4. Children Attending PFS-funded CPC Sites, by Cohort and Exclusion Criteria ........... 12 Exhibit 5. Intervention Sample Characteristics During their Preschool Year, by Cohort ............. 13 Exhibit 6. Annual attrition, by Cohort and comparison group ...................................................... 20 Exhibit 7. Percent of Children Meeting Kindergarten Readiness Criteria, Across Domains, by Cohort ......................................................................................................................................... 22 Exhibit 8. Percent of Children Meeting Kindergarten Readiness Criteria, by Cohort and Domain .................................................................................................................................................... 22 Exhibit 9. Percent of Children in Special Education, by Cohort and Grade ................................ 24 PFS-CPC: Report for 2017\u201318 May 2019 iv Background The Child-Parent Center (CPC) model, one of the longest running early childhood intervention models in the United States, has produced some of the most robust long- term academic and social outcomes for children (; ). Beginning in January 2012, as part of a U.S. Department of Education Investing in Innovation (i3) grant to the University of Minnesota, the city of Chicago and Chicago Public Schools (CPS) received funding to (1) increase the number of children who could attend existing CPC sites and (2) increase the availability of CPC programs by adding 16 new sites. Pay for Success (PFS), previously referred to in this evaluation as a Social Impact Bond (SIB), is a funding mechanism whereby private business and philanthropic partners purchase Social Impact Bonds (SIBs) to support public programs. Government entities, such as a state\u2019s Department of Education, pay investors only when a program meets its pre-determined outcomes. The investors bear the full risk of the investment and if a program fails to meet its goals, taxpayers owe nothing. To this end, PFS initiatives typically have an independent evaluator to help determine whether the outcomes have been realized and outcome payments to the private investor need to be made. Beginning in 2014\u201315, the IFF Pay for Success project funded additional CPC preschool slots at six CPS schools. In 2015\u201316, three sites (identified by CPS and approved by the city of Chicago) were added to the PFS project. Nine sites remained in 2016-17 and 2017-18. SRI International (SRI) was contracted to conduct the evaluation of the child outcomes for this project, referred to as the \u201cPFS-CPC project.\u201d The project served four cohorts of preschool children across the nine sites over four school years\u2014Cohort 1: 2014\u201315, Cohort 2: 2015\u201316, Cohort 3: 2016\u201317, and Cohort 4: 2017\u201318. This fourth SRI project evaluation report describes second grade special education placement outcomes of Cohort 1 children, first grade special education placement outcomes of Cohort 2, and kindergarten special education outcomes for Cohort 3. Although this report was to include the kindergarten readiness outcomes for the fourth, and final cohort of preschool children, these data are not available due to a change in the administration and scoring of the early learning assessment used in the district\u2019s preschool program \u2013 Teaching Strategies (TS) GOLD\u2122. This unanticipated PFS-CPC: Report for 2017\u201318 May 2019 1 change is described in greater detail below. The report begins with a description of the CPC program and its expansion efforts using PFS funding, including evidence about the impacts of the CPC program model on children\u2019s school readiness and school achievement at the beginning of the project. Next, we describe the approach to the PFS-CPC program evaluation. The last section presents the results of the evaluation for Cohorts 1, 2, 3, and 4. We then conclude this report with a brief discussion of how the results fit in the larger context of research. CPC Program Model CPC Model Description The CPC program model is designed to promote school readiness, parent involvement, and early learning that, in turn, will translate into long-term academic achievement, higher graduation rates, and career success for CPC students. The CPC model is unique in that it is designed to (1) provide full- or part-time high-quality preschool experiences for 3- and 4-year-old children and (2) combine those educational experiences with family support services and parent engagement activities. CPC programs deliver synergized services for children and their families from preschool through third grade. Indeed, the CPCs emphasize the provision of comprehensive services and parental involvement\u2014program features that are considered to be strongly associated with program quality (; ). A typical CPC site has the components listed in Exhibit 1. The CPC program model components are explained fully at https://humancapitalrc.org/midwest-cpc/cpc-resources (). For this report, the components listed in Exhibit 1 were taken from the draft evaluation plan in the PFS-CPC expansion agreement (see Appendix A, pp. 9\u201311). Note that the CPC model as conceptualized in the current PFS expansion project focuses primarily on providing high-quality preschool education, engaging parents in their child\u2019s education through a parent resource teacher (PRT) at the child\u2019s preschool, and promoting continuity and stability from pre-K through the primary grades. Because the focus for the PFS-CPC project is on preschool programming, SRI\u2019s evaluation is designed to measure the impact of the preschool components on children\u2019s short- and long-term outcomes. PFS-CPC: Report for 2017\u201318 May 2019 2 Exhibit 1. CPC Program Model Components Effective Learning Experiences \uf0b7 Offer pre-K classes that are limited to 34 children for half-day classrooms (two sessions of 17 children each) and have a minimum of two teaching staff. Full-day classrooms, if available, will be limited to 20 children per session. \uf0b7 Provide highly qualified educational staff who will deliver the classroom instruction and parent engagement activities. For example, classroom teachers are certified with a bachelor\u2019s degree (or higher). Overall, program staff must adhere to the requirements set forth by the CPS Talent office, in accordance with collective bargaining unit agreements, and state regulations. Any changes in CPS education and certification requirements will be complied with. \uf0b7 Use data to drive instruction by effectively documenting the organization and implementation of instructional practices to monitor quality and adherence to the program, which is completed by all program staff where appropriate. \uf0b7 Program staff meet with parents over the course of each school year to review their child\u2019s progress and discuss parent program opportunities with the Parent Resource Teacher (PRT). Aligned Curriculum \uf0b7 Implement a CPS District curriculum and formative assessment that are aligned to standards, domains of learning, assessments, and learning activities. \uf0b7 Collaborate with the PRT and classroom teachers to ensure that opportunities to engage families in student learning are available, appropriate, and aligned to the program and parents\u2019 needs. \uf0b7 CPS and, most specifically, the Office of Early Childhood Education provide meaningful professional development and ongoing coaching and feedback for teachers, aides, and other staff members that facilitates high-quality instructional practices. Parent Involvement and Engagement \uf0b7 Engage a PRT and School-Community Representative to work closely with the head teacher and liaisons to maintain a consistently supportive parent program. \uf0b7 Encourage parents to sign a CPC school-home agreement at the start of the school year outlining a plan for fostering learning at home and participating in CPC activities. \uf0b7 Offer and engage families in monthly activities. PRTs create and distribute a monthly parent involvement calendar and conduct parent/teacher conferences over the year to review progress in the parent program. \uf0b7 Provide a resource room dedicated to parent and family activities through kindergarten when possible. \uf0b7 Provide culturally responsive learning opportunities for families that provide flexibility for families\u2019 needs and schedules. Collaborative Leadership Team \uf0b7 Engage a program leadership team that includes the head teacher, PRT, and school-community representative. \uf0b7 Meet regularly, under the direction of the principal, to discuss operations and best practices within the CPC. \uf0b7 Meet regularly, under the direction of the Office of Early Childhood Education (OECE) management team, with staff from across sites to share challenges, experiences, and best practices and make frequent on-site visits to monitor the quality and effectiveness of the program. \uf0b7 Establish meaningful partnerships with community providers to strengthen service delivery and enlist local universities in training opportunities. PFS-CPC: Report for 2017\u201318 May 2019 3 Exhibit 1. CPC Program Model Components (concluded) Continuity and Stability \uf0b7 CPC pre-K classrooms are collocated in the same building as kindergarten classrooms, when possible, to promote familiarity and integration for students as they transition to kindergarten. \uf0b7 Provide a structure of communication, planning, and joint activities under the direction of the principal, leadership team, and OECE management team from pre- K through the primary grades. \uf0b7 Provide a part-time kindergarten aide when funding is available to support the transition into kindergarten. Professional Development System \uf0b7 Offer ongoing professional development opportunities on current trends and needs in early childhood education classrooms, through the OECE and the CPC leadership teams, including topics such as quality curriculum and instruction, data- driven instruction, learning environment, social and emotional needs, and parent engagement. \uf0b7 Meet regularly and create professional learning communities to review ways to support instruction in the classroom and with other teachers. Source: Adapted from Chicago Child-Parent Center Social Impact Bond Evaluation Plan, dated December 2, 2014 (in Appendix A). Expected Outcomes from the CPC Program Model SCHOOL READINESS Previous research on the CPC program showed significant positive effects on children\u2019s kindergarten readiness (; ). Examination of a more recent cohort of CPC participants indicated that they had significantly higher scores on a measure of language proficiency at the end of the program than children enrolled in other publicly funded preschool programs (). More recently, Reynolds and colleagues reported that CPC participants are more likely to meet kindergarten readiness standards in four of six educational focus areas, or \u2018domains\u2019 on a teacher-rated measure (70%) compared with preschool children in the school district who did not attend CPC preschool classrooms (52%) (). THIRD-GRADE READING AND LITERACY The Chicago Longitudinal Study (CLS) followed children over time using administrative records to examine attendance, achievement, and graduation rates in CPC participants compared with children who did not attend CPC preschool. One study found a significant positive impact on third-grade reading achievement for pre-K to third-grade participants (.53 standard deviation) compared with participants who attended CPC only for pre-K and kindergarten (). Smaller studies of PFS-CPC: Report for 2017\u201318 May 2019 4 high-quality preschool interventions have found similar impacts on later school achievement compared with a no-preschool Comparison group (e.g., the Abecedarian study: ; Perry preschool project: ). REDUCED SPECIAL EDUCATION USE The long-term CLS study showed that extended CPC participation (defined as 4 to 6 years) resulted in reductions in the use of special education. Among children 6 to 18 years old, CPC participants had an average rate of special education placement of 14.4% compared with 24.6% for children in the comparison group (who did not attend CPC preschool), indicating that CPC participants had a 41% lower rate of special education placement (). This finding is consistent with another analysis using the CLS sample that compared the average rates of special education placement over time for children who had attended a CPC preschool with those of children who attended a full-day non-CPC kindergarten classroom: special education placement rates of 12.5% and 18.4%, respectively (). It is noteworthy that these estimates average special education placement rates over a wide age range extending beyond the early school years. A more recent study of North Carolina\u2019s state-funded preschool program used statewide population data from 1995 to 2010 to show that third-grade special education rates across multiple cohorts were reduced by as much as 39% for children who participated in the preschool program, even after taking into account a variety of child and family risk factors, types of special education categories, and funding levels that varied by year (). Other reviews of a variety of preschool program models also reported reductions in special education placement as one of the many cost savings results from participation in high-quality preschool programs like the CPC model (; ). In summary, positive impacts on kindergarten readiness, third-grade reading achievement, and special education placements have been cited extensively to demonstrate the short- and long-term benefits for the individual child and savings for society that come from investing in early childhood education. These studies, often including older samples of children followed extensively, were used as the basis for identifying the selected outcomes in the current evaluation and for calculating the repayments that will be made in the Chicago PFS-CPC project. PFS-CPC: Report for 2017\u201318 May 2019 5 Chicago PFS Project (PFS-CPC Project) During 2017\u201318, the PFS expansion of the CPC model involved funding for part-day or full-day CPC preschool at nine sites. Exhibit 2 indicates the year each site began receiving PFS funding and whether the site expanded an existing CPC program or began implementing the CPC program for the first time (i.e., a \u201cnew\u201d CPC site).1 In 2017\u201318, the PFS funding provided preschool to an additional 718 3- and 4-year-olds across the nine sites (see Exhibit 3). The funding paid for the expansion of classroom programming at each site as well as enhanced resources and instructional materials to implement the CPC model. The CPC program typically serves both 3- and 4-year- olds, sometimes in mixed-age classrooms. Thus, the investor funding was used to provide CPC preschool and enhanced services to both 3- and 4-year-olds. Exhibit 2. Description of Participating CPC Sites, by Project Year Site Year 1 2014\u201315 Year 2 2015\u201316 Year 3 2016\u201317 Year 4 2017\u201318 De Diego Expanded Continued Continued Continued Peck Expanded Continued Continued Continued Melody Expanded Continued Continued Continued Fiske Expanded Continued Continued Continued Thomas Expanded Continued Continued Continued Hanson Park New2 Continued Continued Continued Edwards Tonti Davis Expanded Continued Continued New New Continued Continued Continued Continued Note: \u201cExpanded\u201d indicates that a site used PFS funding in that year to expand an existing CPC program, \u201cNew\u201d indicates a program received PFS funding to begin implementing a CPC program for the first time, and \u201cContinued\u201d indicates that a site continued to receive PFS funding for an additional year. The project administrators anticipated that four cohorts of children would be served across the nine sites, identified by the school year in which children begin preschool 1 Three of the six sites in Year 1 had been providing CPC services since 2012, at the start of the i3 federal grant, and two had been providing CPC services since 2013, when the original sites from the 1970s were merged with the current site. For the three additional sites in year 2, two were new to providing CPC services and one had been providing CPC services since 2012. 2 This site only operated for half of the year due to delays in hiring. Thus, the first full year of implementing CPC was 2015\u201316. PFS-CPC: Report for 2017\u201318 May 2019 6 (Cohort 1: 2014\u201315, Cohort 2: 2015\u201316, Cohort 3: 2016\u201317, Cohort 4: 2017-18) (see Appendix B for grade levels of children in the four cohorts across years). Evaluation Design Because government pays investors only when outcomes are achieved, PFS initiatives typically have an independent evaluator to help determine whether the outcomes have been realized. SRI is conducting the independent evaluation of the outcomes of the PFS-CPC expansion project. The SRI evaluation team developed the evaluation methodology building on a draft evaluation design written by a team that included the Harvard Social Impact Bonds Technical Assistance Lab. The project also has an oversight committee of early education and research experts. The evaluation team has been charged with independently documenting the outcomes- based performance measures of the initiative. This kind of evaluation is not intended to test the impact of the CPC model against other preschool models; rather it is tracking the outcomes of the participating children against specific outcome metrics. The evaluation is addressing three performance-based outcome questions: 1. What is the rate of kindergarten readiness in children participating in the PFS- CPC sites as defined by performance on the Teaching Strategies (TS) GOLD\u2122 instrument (completed by teachers in the spring of the preschool before a child enters kindergarten)? 2. What is the rate of third-grade literacy as defined by performance in meeting or exceeding grade-level performance on the state- or district-administered third- grade assessment in reading? 3. What is the rate at which students are identified with special education needs and placed in special education services (starting in kindergarten) compared with a matched comparison group of children? Kindergarten readiness was measured in the spring of preschool for CPC participants (as described below), and third-grade literacy will be measured in the spring of third grade after the administration of required state achievement tests. SRI began measuring special education placement in kindergarten and continued through spring PFS-CPC: Report for 2017\u201318 May 2019 7 of 2018 (in spring 2018, Cohort 1 reached the second grade; Cohort 2, the first grade; Cohort 3, kindergarten; and Cohort 4, end of preschool).3 For the evaluation of the PFS-CPC project, SRI is using two designs to track the primary outcomes: a descriptive study for the kindergarten readiness and third-grade literacy outcomes4 and a quasi-experimental design for the special education outcomes from first to fourth grades (see analysis approach for further information). Specifically, for the kindergarten readiness and third-grade literacy outcomes, there will be no comparison group for evaluating the outcomes and calculating the subsequent repayment. Evaluation of these two primary outcomes will be based on the intervention group only, and payments will be calculated using outcomes relative to national standards. In the planning phase, it was determined that both the kindergarten readiness and literacy outcomes had normative information so that children\u2019s performance on these measures could be used to identify whether they were performing at or above normative trends for comparable age their peers. The decision was to use this kind of standard rather than compare performance with that of a comparison group of children. In addition, the kindergarten readiness data are not available for children with no preschool experience, given that the kindergarten readiness measure is collected during the spring of pre-K in Chicago Public Schools and only for children who attended preschool. For special education outcomes (first to fourth grades), children are identified as receiving the intervention (i.e., attending a CPC preschool classroom) in the year they are in preschool and then are matched to children with similar demographic characteristics but who did not attend any preschool (CPC or otherwise) in CPS. This no pre-K comparison group is identified when the children are in kindergarten for each of the four cohorts. That is, SRI will create a no pre-K comparison group for each cohort of intervention children using propensity score weighting processes. 3 Further evaluation will be required after 2018 to measure the impacts on 3rd grade literacy and special education outcomes beyond second grade. 4 The approach used here is sometimes referred to as the \u201crate card\u201d approach where success payments are made on a per-student basis. PFS-CPC: Report for 2017\u201318 May 2019 8 Analysis Approach CPC INTERVENTION SAMPLE INCLUDED IN ANALYSIS Children were included in the intervention cohorts if they attended one of the PFS- CPC sites that was fully implementing the CPC program during their preschool year,5 were enrolled in either a full- or half-day pre-K classroom, were not identified as having a severe disability, were income eligible (i.e., eligible to receive free or reduced-price lunch), and were at least 4 years old in September of their preschool year. Additionally, a child needed to have attended a CPC pre-K classroom for at least 66% of the days (not consecutively) in a given school year\u2014a percentage considered a sufficient amount or dose of the intervention to affect child outcomes. The project is based on the hypothesis that high-quality early childhood education will prevent or reduce a future need for special education services for children considered at-risk for developing delays or mild disabilities. As such, children diagnosed with severe disabilities were excluded from the project. Early childhood education and intervention also may reduce the need for children with mild delays or speech and language impairments in preschool from needing additional special education services in kindergarten and beyond. The project does not expect to prevent children with severe disabilities or needs from receiving special education services. Children were categorized as having no disability, a mild disability, or severe disability based on a priori decisions of the evaluation team in the planning and evaluation design phase. A severe disability could include autism, specific learning disability, deaf- blindness, deafness, hearing impairment, orthopedic impairment, other health impairment, traumatic brain injury, visual impairment, and multiple disabilities. A mild disability could include developmental delay, speech and language impairment, specific learning disability, and educational support accommodations or modifications for children with no other disability (mild or severe). Additionally, children were excluded from the intervention cohort if they were in a separate classroom for students with special education needs. Finally, children were excluded if they were identified with special needs and already had an Individualized Education Plan (IEP) prior to starting their preschool year at age 4 and were specifically assigned to one of the CPC sites because the site had blended classrooms (i.e., based on a CPS district 5 There were five sites for Cohort 1 and nine sites for Cohorts 2, 3, and 4. PFS-CPC: Report for 2017\u201318 May 2019 9 policy, some school sites had general education classrooms with additional supports to better serve children with IEPs, which are referred to as \u201cblended classrooms\u201d). Each cohort includes children from all PFS-funded sites that were providing the CPC model to 3- and 4-year-olds during that cohort\u2019s 4-year-old preschool year. Inclusion of all eligible 4-year-olds in this group increases the sample size for the study to provide a more reliable and valid assessment of kindergarten readiness at the CPC sites. All the children across all classrooms received the full CPC model. That is, the experience of all 4-year-olds enrolled in these CPCs is similar, with a common curriculum, professional development, and parent engagement aligned through monthly Collaborative Leadership Training by all CPCs, including high-quality preschool and family support services and parent engagement activities. Thus, the evaluation does not distinguish between preschool slots funded by PFS versus other CPC funding sources. Each PFS-CPC cohort was defined as meeting the eligibility criteria above and these children became the cohort to be tracked for outcomes in kindergarten and in later grades. Each cohort also was used to identify a matched comparison group of children in kindergarten for comparing special education outcomes at the end of kindergarten and in later grades. Exhibit 3 shows the enrollment information for CPC preschool slots at PFS-funded sites, by year. At the end of Year 4 (the 2017\u201318 school year), administrative enrollment data showed that 1,287 3- and 4-year-old children were attending preschool at these nine sites (480 3-year-olds; 807 4-year-olds). PFS expansion funding covered the costs of providing CPC preschool for 718 of these 1,287 children. PFS-CPC: Report for 2017\u201318 May 2019 10 Exhibit 3. Enrollment at PFS-funded CPC sites, by year Year 1 Enrollment (2014\u201315) Year 2 Enrollment (2015\u201316) Year 3 Enrollment (2016\u201317) Year 4 Enrollment (2017\u201318) Number of sites Total enrollment 3-year-olds 4-year-olds PFS-funded seats 6 653 267 386 374 9 1,378 537 841 782 9 1,309 502 807 798 9 1,287 480 807 7186 For Cohort 4 intervention group, SRI requested a data export that included all students ever enrolled as grade PK (the CPS designation for 4-year-olds in preschool) in the PFS-funded CPC sites at any time in the 2017\u201318 school year. Overall, 733 PK students were ever enrolled at one of the nine CPC sites during 2017\u201318.7 Across the total sample of 733 PK children, 592 or 77% met all the eligibility criteria. Exhibit 4 indicates the exclusions from the original sample of PK children ever enrolled in one of the sites that resulted in the final sample of children included in the analysis for each cohort. 6 The method of calculating funded slots in Year 4 may differ from previous years due to staffing changes in the district. 7 The number of children ever enrolled is different from enrollment estimates at any given point in the year. As children left a CPC site, new children were enrolled. The 773 includes all children ever enrolled during the 2017\u201318 year. Based on enrollment in May/June 2018, CPS reported that 807 4-year-old children were enrolled at the nine CPC sites at the end of the year. PFS-CPC: Report for 2017\u201318 May 2019 11 Exhibit 4. Children Attending PFS-funded CPC Sites, by Cohort and Exclusion Criteria Cohort 1 2014\u201315 (n or %) Cohort 2 2015\u201316 (n or %) Cohort 3 2016\u201317 (n or %) Cohort 4 2017\u201318 (n or %) Number of sites included 5 9 9 449 1,004 818 63710 59211 Did not attend 66% of days 21% Number of four-year old children attending these sites (grade PK) Number of four-year old children meeting eligibility criteria Reason for exclusion Severe disability and/or enrolled in separate special education classroom Had an IEP prior to PK year Not eligible for free or reduced-price lunch or insufficient documentation Under 4 years old in September of PK year 3138 % 3% 3% 2% <1% 6549 % 21% 2% 7% 1% 4% % 7% 3% 8% 4% 1% 9 773 % 7% 2% 8% 5% <1% Cohort 1 (2014\u201315) included 313 children, Cohort 2 (2015\u201316) included 654 children, Cohort 3 (2016\u201317) included 637 children, and Cohort 4 (2017\u201318) included 592 children. The demographic characteristics of all four Cohorts are described in Exhibit 5. Cohorts 1, 2, and 3 are also described in previous reports (; ). The final samples of children who were included were similar in many ways to the children who did not meet the eligibility criteria with a few exceptions. The children who were included in each intervention cohort were more likely to be Hispanic and more likely to speak Spanish at home compared with the children who were excluded from that cohort. 8 Of the 313 children selected for Cohort 1 in their PK year (2014\u201315), 289 were enrolled in CPS on the 20th day of school during their kindergarten year, for a Cohort 1 kindergarten retention rate of 92.33%. 9 Of the 654 children selected for Cohort 2 in their PK year (2015\u201316), 619 were enrolled in CPS on the 20th day of school during their kindergarten year, for a Cohort 2 kindergarten retention rate of 94.65%. 10 Of the 637 children selected for Cohort 3 in their PK year (2016\u201317), 593 were enrolled in CPS on the 20th day of school during their kindergarten year, for a Cohort 3 kindergarten retention rate of 93.09%. 11 Of the 592 children selected for Cohort 4 in their PK year (2017\u201318), 556 were enrolled in CPS on the 20th day of school during their kindergarten year, for a Cohort 4 kindergarten retention rate of 93.92%. PFS-CPC: Report for 2017\u201318 May 2019 12 Exhibit 5. Intervention Sample Characteristics During their Preschool Year, by Cohort Characteristic Cohort 1 2014\u201315 (n = 313) (percent) Cohort 2 2015\u201316 (n = 654) (percent) Cohort 3 2016\u201317 (n = 637) (percent) Cohort 4 2017\u201318 (n = 592) (percent) Male Hispanic African-American Caucasian Other ethnicity Designated as English Language Learner (ELL) Identified mild developmental delay or disability Enrolled in full-day Pre-K classrooms 50 67 30 1 1 44 4 37 48 79 17 2 <1 57 4 40 47 82 15 2 1 60 3 50 84 14 1 1 57 5 4212 3613 ANALYZING IMPACT ON KINDERGARTEN READINESS SRI examined kindergarten readiness using Teaching Strategies (TS) GOLD\u2122 scores from the spring before the child entered kindergarten.14 TS GOLD is a teacher- reported measure of young children\u2019s skills across six developmental domains: literacy, language, mathematics, cognitive development, socio-emotional well-being, and physical health. We are using this measure because it was the only available child assessment that CPS routinely collects and was therefore selected as the measure of kindergarten readiness by the PFS planning team.15 It is used routinely in the CPS preschool programs, and there was no alternative CPS-wide measure of kindergarten readiness that is completed as children are entering kindergarten in the fall of the school year at the time of the PFS implementation design. 12 Half- or full-day status was unknown for 7% of the 637 students. 13 Half- or full-day status was unknown for 9% of the 592 students. 14 The TS GOLD assessment was developed to monitor the skills of children attending a child care or preschool program so teachers can adjust their instructional strategies depending on the children\u2019s progress on a variety of skills and behaviors. TS GOLD\u2122 was not developed as a measure of kindergarten readiness. 15 The methodology involved in most SIB projects relies on use of available administrative data rather than additional data collection to evaluate outcomes. PFS-CPC: Report for 2017\u201318 May 2019 13 Calculating Impact on Kindergarten Readiness As described, we calculated the impact of CPC on kindergarten readiness by comparing children\u2019s performance on the measure with national norms. We selected this approach for two reasons. First, adequate normative data enables us to identify whether children in the sample were performing at or above a widely accepted standard. Second, creating an appropriate comparison group within CPS was not possible; kindergarten readiness data are not available for children without preschool experience (our comparison group), given that the kindergarten readiness measure is collected during the spring of pre-K in Chicago Public Schools. The metric for kindergarten readiness is the percentage of children who are performing at or above national trends across at least five of these six domains.16 A child is determined to be ready for kindergarten if he or she is rated by the teacher as demonstrating levels of skill or knowledge that are expected for a child at a particular age; the reference point for such expectations come from the observed abilities of other children from a representative sample of same-aged peers in the United States. We categorized children as kindergarten ready on each domain by the criterion of meeting or exceeding the 50% percentile on the standard score for that domain using scores from the most recently published technical manual (a). Then, we calculated the percentage of children who met this criterion on five of six domains.17 For Cohorts 1, 2, and 3, TS GOLD\u2122 observation data were administered (meaning the same items made up each domain) and scored the same way using a system for converting raw rating scores to standard scores. Between Cohort 3 and Cohort 4, the developers changed the TS GOLD\u2122 system from a Birth to Kindergarten assessment to a Birth to Third Grade assessment. This change to expand the age range of this 16 No data are available on which domains of the TS GOLD assessment to use to reliably and validly determine kindergarten readiness. The decision to define kindergarten readiness as performing at or above national trends on five of six domains (and not four of six) aligns with the National Research Council\u2019s definition of school readiness, which includes age-level skills across multiple domains (). The threshold of five of six domains also takes into account that a child may not meet a standard for all six domains, especially in the spring of preschool, as these skills are emerging during this time period. 17 Teacher-reported assessments have some unknown sources of variability, and the GOLD assessment is no different. Research on the GOLD assessment indicates that between 17% and 25% of the variance in scale scores is accounted for by unmeasured differences between classroom and teachers, including rater effects (). At this time, there is no consensus on how to calculate kindergarten readiness using GOLD assessment scores. Thus, we continue to use the a priori definition and benchmark. PFS-CPC: Report for 2017\u201318 May 2019 14 assessment tool involved adding items to some domains to represent the full-range of skills and abilities that would be observed in children from birth to 9 years of age. It also involved re-scaling the standard scores to represent the full range of raw and standard scores across the expanded age range. Unfortunately, these changes in the item pool and the scoring mean that for Cohort 4 children, we have no way to compare their TS GOLD\u2122 scores to scores derived earlier for the other cohorts. Thus, the new version of the assessment measure is still under development and does not have the same reference points to allow for reliable statements about children\u2019s kindergarten readiness skills. ANALYZING IMPACT ON SPECIAL EDUCATION PLACEMENT Special education placement was determined using data on children\u2019s disability designation at any time during the child\u2019s kindergarten year. Children were classified into three categories: children receiving special education services for mild disability, children receiving special education services for severe disability, and children not receiving special education services (no IEP). Recall that our hypothesis is that high- quality preschool via the CPC program will decrease the chances that children who are at risk will need special education services in the future. Because we are not trying to prevent children with severe disabilities from receiving the special education services they need, we restricted our definition of special education outcomes to children who needed special education for mild delays or disabilities defined as those children who had an IEP for the following: speech and language issue (S/L), developmental delay (DD), and specific learning disabilities (SLD), which is the only information available in the administrative dataset describing the type and severity of disability. This helps avoid the perverse incentive of withholding special education services from children with severe disabilities. Below we report the cumulative findings for special education placement outcomes for cohorts 1, 2, and 3 and their peers (i.e., the comparison group of children who did not attend any CPS preschool). The effect size of the impact on special education placement for Cohort 1 was calculated using the risk difference approach. The equation is the following: \ud835\udc38\ud835\udc46(cid:3036),(cid:3047) (cid:3404) \ud835\udc46\ud835\udc43\ud835\udc38\ud835\udc37(cid:3004),(cid:3036),(cid:3047) (cid:3398) \ud835\udc46\ud835\udc43\ud835\udc38\ud835\udc37(cid:3021),(cid:3036),(cid:3047) where ESi,t is the effect size for cohort i in year t, SPEDC,i,t is equal to the average of a binary indicator of special education placement among the no pre-K comparison PFS-CPC: Report for 2017\u201318 May 2019 15 group for cohort i in year t, and SPEDT,i,t is the average of a binary indicator of special education placement among the intervention group for cohort i in year t. The same calculation will be used for each cohort for each year through sixth grade as described below. Based on conversations with special education experts and reviewing existing CPS data, the consensus by the planning committee is that the vast majority of children who have a disability will be identified by the end of sixth grade (). As a result, after the sixth-grade effect size has been calculated, IFF (or the district) will average the effect size over the last 3 years (fourth, fifth, and sixth grades) and lock in that average effect size for the purposes of calculating payments in grades 7 through 12. This lock-in rate will be calculated separately for each intervention cohort. SRI may propose changes to this lock-in methodology in the event that the team determines that it produces skewed results. Any modifications must be approved by CPS, the city of Chicago, the project coordinator, and approved by the lender committee. SELECTING A COMPARISON GROUP For the special education placement outcome, we conducted propensity score analysis to identify an appropriate comparison group that had not received CPS preschool in either school- or community-based settings. Propensity score methods are quasi-experimental approaches that were developed to approximate findings obtained from randomized controlled trials (). They have been used increasingly in analysis of observational data to reduce selection bias in estimating treatment, policy, or intervention effects when randomized controlled trials are not feasible or ethical (1984, 1985). In essence, propensity score methods help to identify a comparison group that mimics what might have been obtained using random assignment. Initial selection To create the initial comparison group for each cohort, we first restricted our data set to all kindergarteners in CPS who were 5 years old or older on September 30, were eligible for free and reduced-price lunch, did not attend preschool in CPS (either in a PFS-CPC: Report for 2017\u201318 May 2019 16 CPC or other CPS preschool classroom),18 and who were not attending kindergarten at a school with a CPC program.19 For detail about the Cohort 1 and 2 comparison group selections, see the previous reports for 2015\u201316 and 2016\u201317. For the Cohort 3 comparison group, our potential sample was approximately 8,798 or about one-third of the total number of children enrolled in kindergarten in CPS in 2017\u201318 (approximately 23,000). The sample was further reduced to 7,890 who had no missing data on any baseline covariates and outcome. We then applied propensity score analysis to identify a propensity score for each of the 7,890 children eligible to be in the comparison group. The propensity score is the predicted probability of being in an intervention based on a set of potentially confounding covariates (e.g., child and neighborhood background characteristics; see below for more detail) using logistic regression. The key advantage of using a propensity score is the ability to balance intervention and comparison groups on a large number of covariates by using a linear combination of covariates for a single score. Simply, the propensity score is a measure of how similar children from the comparison group are to the children in the intervention group on a large number of covariates. We applied propensity score weighting (PSW) because this approach has the advantage of maximizing power by including all eligible children in the comparison group sample rather than only matched cases. It weights each comparison child by their propensity score, a measure of similarity between intervention and comparison on a large number of covariates; comparison children were weighted higher if they were more similar to intervention children and were weighted lower if they were to less similar to Intervention children. The way PSW works is that each child is given a weight derived from logistic regression which represents how closely the child matches the intervention group; in 18 The evaluation team only had data about whether children had received preschool in CPC or other CPS-sponsored classrooms. As such, it is possible that some children in this comparison group may have participated in a preschool program such as Head Start outside of the district in a community- based setting. 19 The initial planning team had suggested also excluding children who were enrolled in charter schools, magnet or selective enrollment schools, and schools that serve exclusively a special education population. However, there are no elementary schools that serve exclusively a special education population. The evaluation team did not think it necessary to exclude children who attended charter or magnet schools because we did not have adequate information showing these were higher-performing schools than the \u201cbusiness as usual\u201d elementary schools children could have attended. PFS-CPC: Report for 2017\u201318 May 2019 17 this case, how well-matched they were on the selected child and neighborhood characteristics. The weight is not related to the outcome (special education status). This propensity score weighting approach adjusts for confounds using inverse propensity score estimators, as recommended by , , and . From the logistic regression model, we calculated a probability that the comparison child would be in the intervention group. The weight for intervention students was 1.0, and the weight for comparison students was equal to their propensity score transformed to an odds scale (pi/1-pi) (; ). In the PSW approach, children in the comparison group who are more like the intervention group children are weighted more heavily, and comparison group children less like the intervention group children get smaller weights. Outcome data for each child is given a numerical weight based on the child\u2019s baseline demographic characteristics. For example, if the intervention group has a higher proportion of Hispanic children and a lower proportion of White children than the comparison group, the Hispanic children in the comparison group will be weighted more and the white children in the comparison group will be weighted less.20 The final comparison sample comprises all 7,890 children, weighted to closely match children in the intervention group. An important aspect of estimating the propensity score is the selection of covariates. Researchers suggest that covariates that affect both intervention participation and outcomes should be included in the estimation of the propensity score (; ; ; ). Covariates included in this study were selected based on findings from studies that have examined neighborhood effects associated with child outcomes (; ; ; ten ). Our covariates came from four data sources: school district data for the 2015-2016 school year, census tract data for 2013, community area public health data for 2009, and police district crime report data for 2010. The 20 This is an oversimplification because the approach actually uses all of the demographic data available to create the weight for each comparison child. That is, instead of matching on each of the covariates; children are given a weight that is based on the combination of all of the covariates. PFS-CPC: Report for 2017\u201318 May 2019 18 PSW did result in well-match intervention and comparison groups. Additional details about the PSW analysis for the Cohort 2 comparison group are contained in Appendix C. Adjusting for attrition The initial selection of the comparison groups for Cohorts 1 and 2 were described in the Year 1 and Year 2 reports (April 2017, March 2018). In Year 4, Cohort 1 and their comparison group moved into second grade, Cohort 2 and their comparison group moved into first grade, and our analyses of their first and second grade special education outcomes were adjusted to account for attrition21 as students left the district after their previous school year. As shown in Exhibit 6, between 2016\u201317 and 2017\u2013 18, the attrition rates were lower in both cohorts than in their comparison groups; rates between the pairs were similar, with Cohort 1 and Cohort 2 both at 6% and their comparison groups at 10% and 11%, respectively. However, we observed higher attrition from preschool to Kindergarten for Cohort 3 (20%) compared to Cohorts 1 and 2 as they moved to Kindergarten (5% and 9%, respectively). To make sure the groups were still similar after this attrition, we re-weighted the remaining children in each of the comparison groups to match the remaining children in each cohort on the selected child and neighborhood background characteristics. Additional details about the re-weighting analysis for the Cohort 1 and 2 comparison groups are contained in Appendix C in the Year 3 report. 21 Attrition here is defined as students not attending CPS in the expected grade level in a particular school year. Children are included if they are no longer enrolled in the school district or are enrolled in another grade. PFS-CPC: Report for 2017\u201318 May 2019 19 Exhibit 6. Annual attrition, by Cohort and comparison group Group School Year 2014\u201315 School Year 2015\u201316 School Year 2016\u201317 School Year 2017\u201318 Cohort 1 and their comparison group Cohort 1 Preschool n = 313 original sample Kindergarten n = 297 5% attrition Comparison n/a Kindergarten n = 9,445 original sample First Grade n = 256 14% attrition First Grade n = 7,076 25% attrition Second Grade n = 24122 6% attrition Second Grade n = 6,385 10% attrition Cohort 2 and their comparison group Cohort 2 n/a Preschool n = 654 original sample Kindergarten n = 595 9% attrition First Grade n = 56223 6% attrition Comparison n/a n/a Kindergarten n = 7,126 original sample First Grade n = 6,331 11% attrition Cohort 3 and their comparison group Cohort 3 n/a n/a n/a Preschool n = 637 original sample Kindergarten n = 506 20% attrition Kindergarten n = 7,890 original sample Comparison n/a n/a Note: Attrition rates are calculated using the number of students enrolled in that grade at the end of the designated school year as the numerator and the number of students enrolled the previous year as the denominator. Results We first present the kindergarten readiness results for Cohort 4 and then the results for kindergarten special education placement outcomes for Cohort 2 children, first grade special education placement for Cohort 2 children, and second grade special education placement for Cohort 1 children. 22 Of the 313 children selected for Cohort 1 in their PK year (2014\u201315), 241 were enrolled in CPS at the end of their second grade year, for a Cohort 1 second grade retention rate of 77.00%. 23 Of the 654 children selected for Cohort 2 in their PK year (2015\u201316), 562 were enrolled in CPS at the end of their first grade year, for a Cohort 1 first grade retention rate of 85.93%. PFS-CPC: Report for 2017\u201318 May 2019 20 Kindergarten Readiness COHORT 4 KINDERGARTEN READINESS The evaluation team was unable to calculate kindergarten readiness for Cohort 4. When the evaluation team analyzed the TS GOLD\u2122 Spring 2018 data for Cohort 4, we found that the percentage of children meeting the kindergarten readiness criterion was dramatically lower than the percentages from previous years. When investigating this difference, the team learned that the developers had changed the measure by adding items and modifying the algorithm that converts the raw scores to standard (scale) scores. These item and scoring differences mean that the evaluation team could not use an identical procedure for calculating the percentage of children meeting the kindergarten readiness criterion. That is, as described above, we categorized children as kindergarten ready on each domain by the criterion of meeting or exceeding the 50% percentile on the standard score for that domain using scores from the most recently published technical manual (a). Then, we calculated the percentage of children who met this criterion on five of six domains. The standard scores we received for Cohort 4 were not derived in the same way as the standard scores from the earlier cohorts; when we categorized children using the earlier 50% percentiles, we found much lower rates of kindergarten readiness. We also know that there were no large differences in other factors that could affect kindergarten readiness rates (e.g., no changes in this Cohort 4 on implementation of the CPC program model, other school or district characteristics, sample characteristics, teacher training on the use of the measure, etc.). Given these results, we have no data on kindergarten readiness to report for Cohort 4. PFS-CPC: Report for 2017\u201318 May 2019 21 Exhibit 7. Percent of Children Meeting Kindergarten Readiness Criteria, Across Domains, by Cohort Number of domains meeting or exceeding the 50th percentile Cohort 1 2014\u201315 (percent) Cohort 2 2015\u201316 (percent) Cohort 3 2016\u201317 (percent) Cohort 4 2017\u201318 (percent) 19% not available 0 1 2 3 4 5 6 5 or 6 Cognitive Language Literacy Math Physical Social-emotional 9% 3% 7% 12% 9% 10% 51% 61% 82% 66% 75% 81% 60% 79% Exhibit 8. Percent of Children Meeting Kindergarten Readiness Criteria, by Cohort and Domain Domain Cohort 1 2014\u201315 (percent) Cohort 2 2015\u201316 (percent) Cohort 3 2016\u201317 (percent) 14% 11% 11% 11% 11% 19% 23% 42% 65% 50% 62% 72% 30% 63% 7% 9% 7% 13% 15% 29% 44% 65% 53% 60% 68% 42% 61% not available not available not available not available not available not available not available Cohort 4 2017\u201318 (percent) not available not available not available not available not available not available Special Education Placement COHORT 3 KINDERGARTEN SPECIAL EDUCATION PLACEMENT After ensuring the two groups were equivalent on child and neighborhood characteristics and weighting appropriately, we examined the kindergarten special education placement rates for mild and moderate developmental delay or disability for PFS-CPC: Report for 2017\u201318 May 2019 22 Cohort 3 and its comparison group.24 The special education rate was lower in the intervention group than the comparison group (3.95% for Cohort 3 in kindergarten and 6.26% for children in the comparison group in kindergarten). This is a difference of 2.31 percent. COHORT 2 FIRST GRADE SPECIAL EDUCATION PLACEMENT After ensuring the two groups were equivalent on child and neighborhood characteristics and weighting appropriately, we examined the first grade special education placement rates for mild and moderate developmental delay or disability for Cohort 2 and its comparison group. The special education rate was lower in the intervention group than the comparison group (4.27% for Cohort 2 in first grade and 7.20% for children in the comparison group in first grade). This is a difference of 2.93 percent. COHORT 1 SECOND GRADE SPECIAL EDUCATION PLACEMENT After ensuring the two groups were equivalent on child and neighborhood characteristics and weighting appropriately, we examined the second grade special education placement rates for mild and moderate developmental delay or disability for Cohort 1 and its comparison group. The special education rate was lower in the intervention group than the comparison group (4.15% for Cohort 1 in second grade and 7.93% for children in the comparison group in second grade). This is a difference of 3.78 percent. 24 All students in the Cohort 1, 2, and 3 comparison groups with an IEP were identified during their kindergarten year. PFS-CPC: Report for 2017\u201318 May 2019 23 Exhibit 9. Percent of Children in Special Education, by Cohort and Grade Group Kindergarten (GK) First Grade (G1) Second Grade (G2) Cohort 1 (PK n = 313) 2015-16 n = 297 4.38% 2016-17, n = 256 3.13% 2017-18, n = 241 4.15% Comparison GK, n = 9,445 4.94% 2016-17, n = 7,076 6.17% 2017-18, n = 6,385 7.93% Cohort 2 (PK n = 654) 2016-17, n = 595 3.36% 2017-18, n = 562 4.27% Comparison 2016-17, n = 7,126 5.09% 2017-18, n = 6,331 7.20% Cohort 3 (PK n = 637) 2017-18, n = 506 3.95% Comparison 2017-18, n = 7,890 6.26% TBD TBD TBD TBD TBD TBD TBD = to be determined Discussion Sociodemographic risk factors\u2014the most extensively studied of which is poverty\u2014are highly predictive of developmental trajectories. Children from low-socioeconomic- status (SES) households are less likely to enter kindergarten with the pre-academic and social skills needed to succeed and are more likely to require later special education services later (; ; ; ). Early childhood programs potentially mitigate the risks endemic to children from disadvantaged backgrounds, with studies showing that the strongest positive short- and long-term outcomes result from intensive and comprehensive programs targeting low-income children (; Institute for Research on ; ). Indeed, prior studies have highlighted early childhood as a critical and sensitive period for the development of brain architecture and neurochemistry (e.g., ) and subsequent academic and socio-emotional well-being (). PFS-CPC: Report for 2017\u201318 May 2019 24 First implemented in Chicago in 1967, the CPC model has a long history of offering innovative, targeted approaches to school reform including a comprehensive system of educational and family support services during the preschool through third grade years for young children in low-income neighborhoods. The intervention promoted young children\u2019s school success through language enrichment and intensive, mandatory parent involvement within a system of comprehensive support services for children and their families. The CPC model, integrated into the CPS system since its inception in 1967, has been systematically evaluated for its impact on child and family outcomes. A notable by-product of the CPC program\u2019s efforts is the Chicago Longitudinal Study (CLS), which has supported researchers\u2019 efforts to develop a deeper understanding of the \u201cactive\u201d ingredients of early dual-generation interventions and early childhood interventions more generally. The following are key relevant findings from analyses conducted on the CLS samples: \uf0b7 Nearly half of children (44%) attending a CPC for one year were considered ready for kindergarten compared with 28% of children who had no preschool (unpublished data, A. Reynolds, personal communication, February 25, 2015). \uf0b7 Children having one or two years of CPC preschool experience were less likely than those having no CPC preschool experience to have received special education throughout the elementary school years (). The expectation for the PFS-funded expansion of CPC to new sites in CPS and increasing the number of available CPC preschool slots at existing sites in CPS was based on previous research showing positive impacts on kindergarten readiness and school achievement, and reductions in special education placements over time. Other new CPC data also show positive impacts on kindergarten readiness (). In a meta-analysis of 9 high-quality experimental and quasi-experimental studies conducted in the last 50 years find on average, participation in ECE leads to reductions in special education placement, about 8% fewer children need special education services when averaged across studies (). Below we discuss the findings from the year 3 evaluation outcomes, including some of the limitations in interpreting the data. PFS-CPC: Report for 2017\u201318 May 2019 25 Kindergarten Readiness Findings To put the findings for the first 3 cohorts in context, we ask four questions of the kindergarten readiness data. This information and discussion was also shared in previous reports; we include it here as this report includes all cumulative findings to date. First, is the assessment a reliable and valid measure of children\u2019s kindergarten measure and how much error might exist in measuring children\u2019s \u201ctrue\u201d kindergarten readiness? Second, to what extent are our findings similar to those of other CPC and CLS data? Third, to what extent are our findings similar to the ECLS-K data for the general population and for children from low-income families? Finally, what might explain the decrease in the percentage of children ready for kindergarten in the two cohorts of children from year 1 to year 2 and from year 1 to year 3? IS THE ASSESSMENT A RELIABLE AND VALID MEASURE OF CHILDREN\u2019S KINDERGARTEN READINESS? It is important to understand the current context of assessing young children\u2019s kindergarten readiness. Currently, there is no summative assessment tool that is considered a \u2018gold standard\u2019 for measuring kindergarten readiness. All assessments, whether they involve teacher ratings or direct assessments of young children\u2019s abilities and skills, are prone to some measurement error. Direct assessments are limited in that they only assess children at a single time point and often only assess a very small set of skills (e.g., counting, alphabet recognition) administered and scored based on performance on a highly defined set of items that do not reflect the full spectrum of foundational skills needed to be ready for kindergarten and succeed in school. Teacher ratings that are based on longer periods of observation across multiple settings can be a more accurate representation of children\u2019s skills and behaviors. The developers of the TS GOLD\u2122 recommend certain kinds of trainings to help teachers use the tool as well as procedures to ensure the accuracy of ratings (e.g., checking inter-rater reliability). Some aspects of the TS GOLD\u2122 measure show strong psychometrics. For example, the developers have published analyses showing strong internal reliability (Cronbach\u2019s alpha reliability coefficients = .94 - .97) which suggests that the items are correlated (i.e., a child who scores high on one item has a high probability of scoring high on another item (). There is limited evidence, however, for test-retest or inter-rater reliability on the TS GOLD\u2122. Understandably, high test-retest PFS-CPC: Report for 2017\u201318 May 2019 26 reliability may not be something you would expect from this measure as children develop and mature very rapidly in the first five years, especially children participating in a preschool program. However, we would want to have higher inter-rater reliability, meaning different raters (in this case, teachers) would tend to rate the children the same way given the same information and observation window for those two raters. There are limited data, however, on whether this measure has moderate to high interrater reliability. For example, correlations between the ratings of a master trainer and ratings of teachers who were current users of the system were high (between .80 and .90) suggesting that when teachers are adequately trained (in this case, received a full two days of training) they can demonstrate good reliability when making ratings of the same child (). There is some evidence that the measure has validity, meaning it measures what it is intended to measure. One way to assess the measure\u2019s validity is to examine whether children with a known delay or disability perform lower on the ratings when compared to children who do not have identified delays or disabilities. The developers have published data showing children with identified disabilities have lower TS GOLD\u2122 scores when compared with their typically developing peers and they develop at a slower rate (b). A different way to examine validity is to test whether teacher ratings are correlated to independent direct assessments of children\u2019s development. The correlations between TS GOLD\u2122 domain scores and independent direct assessment and other teacher rating measures are moderate (in the range of .3 to .5) suggesting they may be measuring different aspects of development (; ; ). In addition, to our knowledge, validation studies that examine predictive relationships have not been conducted (i.e., how well TS GOLD\u2122 assessment ratings predict later academic achievement and behavior in kindergarten and beyond). Given that our sample included many children who are ELLs, it is important to understand the validity of the use of the TS GOLD\u2122 with that population.  published data that provide some empirical evidence supporting the validity for the TS GOLD\u2122 domains and learning objectives for typically developing children, as well as English-language learners and for those PFS-CPC: Report for 2017\u201318 May 2019 27 children identified with special needs or disabilities. In other words, this observation- based teacher rating assessment tool measures the construct domains in the same way across various subgroups of children 3 to 5 years old. These studies were conducted with samples of teachers who had been trained to reliability. For the measure to be used with children who have very limited English abilities, the teacher must be bilingual in both English and the child\u2019s native language and/or be able to document children\u2019s skills and abilities using information from a bilingual teacher assistant or family members. If the teacher is not bilingual and/or has not gathered additional documentation and observation data from other staff, it is possible that language barriers could influence the accuracy of their assessment, raising the possibility that children\u2019s abilities could be either under- or over-estimated. TO WHAT EXTENT ARE THE PFS-CPC KINDERGARTEN READINESS FINDINGS SIMILAR TO THOSE OF OTHER CPC AND CLS DATA? More recently, Reynolds and colleagues (2014) published data in a peer-reviewed journal showing that 80.9% of children attending full-day CPC classrooms (n = 409) and 58.7% of children attending part-day CPC classrooms (n = 573) were considered kindergarten-ready when kindergarten-readiness was defined as meeting the national norm on four of the six TS GOLD\u2122 domains. Additionally, full-day participants demonstrated higher average levels of skill mastery in the domains of language, mathematics, socio-emotional development, and physical health (but not for literacy and cognitive development). Reynolds and colleagues (2014) report a higher proportion of children who are kindergarten ready than that reported here, but use a less stringent standard for \u201creadiness,\u201d i.e., a threshold of proficiency on four compared with five of the TS GOLD\u2122 domains; five was the standard used for the current evaluation. If we had used that less stringent standard of 4 of 6 domains, an additional 9% would meet the kindergarten readiness criteria in Cohort 1, for a total of 70%, an additional 11% in Cohort 2 for a total of 53%, and an additional 13% in Cohort 3 for a total 57% (see Exhibit 7). Kindergarten readiness rates in all three cohorts are similar or better than the previous CLS study findings for this outcome, but the percentage of children in Cohort 2 and 3 meeting kindergarten readiness benchmarks is lower than other contemporary studies of CPC and lower than the percentage found for Cohort 1. Potential explanations for these differences are discussed in more detail below. PFS-CPC: Report for 2017\u201318 May 2019 28 TO WHAT EXTENT ARE PFS-CPC FINDINGS SIMILAR TO NATIONALLY REPRESENTATIVE STUDIES OF KINDERGARTEN READINESS AND FOR CHILDREN FROM LOW-INCOME FAMILIES? Data from the contemporary, nationally representative sample of ECLS-K25 children and using a single measure of kindergarten readiness which is similar to that of this report indicate rates of school or kindergarten readiness that are typically less than 50% for children from economically disadvantaged households (). In comparison, the same report showed that 75% of children from more economically advantaged households (i.e., moderate to high income households) were considered ready for kindergarten. Other publicly available reports produced by states that are using a kindergarten readiness assessment show considerable variability given the different ways to measure kindergarten readiness. The state of Washington uses a modified version of the TS GOLD\u2122 assessment and recently published data from their kindergarten entry assessment study showing that 31% of entering kindergarteners from low-income households met the benchmarks26 on all six domains \u2013 what they refer to as \u201cfull\u201d readiness (State of Washington, n.d.). About half of Cohort 1 (51%), about one-fifth of Cohort 2 (23%) and nearly one-third of Cohort 3 children (29%) demonstrated readiness in all domains (see Exhibit 8). About 72% of children (across income levels) met the benchmarks for at least 4 domains in Washington state (State of Washington, n.d.). In this evaluation, 70% of children in Cohort 1, 53% of children in Cohort 2, and 57% of children in Cohort 3 (all low- income) met the benchmarks in at least 4 of the 6 domains. Thus, the rates of kindergarten readiness found for all three cohorts are similar to what has been found in national and state studies. WHAT EXPLAINS THE DECREASE IN KINDERGARTEN READINESS IN THE COHORTS OF CHILDREN FROM YEAR 1 TO YEAR 2 AND YEAR 3? There is much larger year-to-year variation than expected in the percentages of children identified as meeting the kindergarten readiness criterion in Cohort 1 versus in both Cohort 2 and Cohort 3. That is, one would expect the rates to be similar in the two cohorts if three factors were similar from year to year: schools were serving the same or very similar populations of children; all teachers in both cohorts received the 25 ECLS-K is a contemporary longitudinal dataset that draws from a nationally representative sample; includes direct assessments of children\u2019s skills at kindergarten entry (cf. ; ). 26 It is unclear what benchmarks on the TS GOLD\u2122 assessment the Washington study uses. PFS-CPC: Report for 2017\u201318 May 2019 29 same type and quality of training and reliability checks to reliably complete the TS GOLD\u2122 ratings (including new teachers who might need more training and practice in rating children reliably); and there were no major programmatic changes in how the CPC programs were implemented (e.g., instructional practices, curricula used, etc.) at each site from year 1 to year 2. If these were all similar from year 1 to year 2, then the only explanation for these differences would be that the assessment tool has a significant degree of unreliability. Finally, it is possible any combination of these four factors could explain the year-to-year variability, and different combinations of these factors might explain the year-to-year change at different sites.27 SRI conducted additional analyses in spring 2017 to examine if and to what degree these factors might explain the decrease in percentage of children who are deemed kindergarten ready in Cohort 2 compared with Cohort 1. The analyses also apply to differences in kindergarten readiness from Cohort 1 to Cohort 3. Are the sites serving a different population? There were some differences in the demographic characteristics served in Cohort 1 versus Cohorts 2 and 3. Most significantly, the number and percentage of children who are designated as English Language Learners has increased across cohorts (Exhibit 5), from 44% in Cohort 1 to 57% in Cohort 2 and 60% in Cohort 3. There were a larger number of ELLs served in year 2 and year 3 and it could be harder to reliably assess these children with the TS GOLD\u2122. Some children who are ELLs could be rated on their English language and literacy abilities while other children could not. The TS GOLD\u2122 developers have provided guidance on whether or not children\u2019s language and literacy skills can be rated in English. We also found that across Cohorts 1 and 2, the percentage of children meeting the Kindergarten readiness benchmark differs significantly by ELL status: 54% of all non- ELLs meet the 5 or 6 criterion compared with 42% of all ELLs (p < .001). Since Cohort 2 has more ELLs than Cohort 1, that difference might partially explain the lower rate of kindergarten readiness in Cohort 2 compared with Cohort 1 as children who are learning two languages may take longer to demonstrate proficiency in any of 27 CPS is exploring these factors related to teacher training and program implementation. PFS-CPC: Report for 2017\u201318 May 2019 30 test the differences. these domains.28 This same phenomenon applies to Cohort 3; however, we did not Did all teachers receive the same training and reliability checks? Although SRI does not collect information on teacher training and turnover, we did examine statistically the percentage of variance in children\u2019s scores that can be attributed to child, teacher, and school factors which helps us understand if the level of teacher effects or site effects is greater than what we would expect on a teacher rating. On the TS GOLD\u2122 assessment, children receive a score on each of six domains. The assumption is that these scores represents the child\u2019s ability in the area measured and that a child\u2019s ability would be measured the same no matter which teacher completed the assessment. To test if this assumption is true, we can estimate the degree to which any child\u2019s score can be predicted by the teacher who completed the TS GOLD\u2122. From other studies using TS GOLD\u2122, we expect the rater to predict about 29 to 35% of the variance in a group of children\u2019s scores (b). In the Year 2 data for the current study, the rater predicted 32 to 53% of the variance in children\u2019s scores depending on the domain. This amount of variation is more than the expected amount. In a recent study comparing TS GOLD\u2122 scores to direct assessment scores of the same domains of development, over 50% of the variance in TS GOLD\u2122 score was attributable to the rater (teacher) compared to about 15% in the direct assessments (). This measurement error reduces the reliability of the scores. As scores become less reliable, it is more difficult to estimate the impact of an intervention on the ability being measured. There should be consistency in how different teachers rate the children. You would expect children with the same abilities to be rated similarly by different teachers. These analyses might reflect teacher training and turnover factors and these are addressed in greater detail by the CPS/city of Chicago program teams in an addendum in the Year 3 report. Did CPC implementation vary from year to year? There was a surprisingly large range in the percentage of children deemed ready for kindergarten across sites and across cohorts (24% to 79%). One factor that might 28 We did not examine fall to spring gains for ELLs and non-ELLs, so we do not know whether ELLS are making good growth on the skills that are rated but just do not gain enough to meet the kindergarten readiness benchmark that we set. PFS-CPC: Report for 2017\u201318 May 2019 31 influence these site differences in kindergarten readiness could be site-level difference in implementation of the CPC model. For example, unobserved site factors may influence training in the CPC model, the ways that the CPC program is implemented, and other program components that may influence teacher ratings and/or children\u2019s kindergarten readiness (e.g., changes instructional practices). While the evaluation did not collect any data on site implementation, these factors are being explored by the implementation partners, CPS and the city of Chicago, who are conducting additional analyses about the contextual site factors that may have impacted implementation. Special Education Placement Findings Based on the extensive CLS analyses as well as reviewing existing data for CPS in the years leading up to the PFS-CPC project, the PFS project was built on the hypothesis that high-quality preschool through the CPC program would help prevent or reduce the need for special education in the intervention group. We found that the special education placement rate in kindergarten for the Cohort 2 intervention group was lower than the rate for the comparison group (3.36% versus 5.09%). This is a difference of 1.73% in the rate of special education use between the two groups, and is an 51% decrease for the intervention group relative to the comparison group. This is a much larger decrease than found in the Cohort 1 kindergarten special education outcomes from last year. That is, we found that the special education placement rate in kindergarten for the Cohort 1 intervention group was slightly lower than the rate for the comparison group (4.38% versus 4.94%). This is a difference of 0.56% in the rate of special education use between the two groups, and is an 11% decrease for the intervention group relative to the comparison group. Cohort 3\u2019s special education rate and the difference between Cohort 3 and its comparison closely matches that of Cohort 2. We observed a difference of 2.31% which represents a 58% decrease for the intervention group relative to the comparison group. For the Cohort 1 special education placement outcomes at the end of first grade, we found that the special education placement rate for the Cohort 1 intervention group was lower than the rate for the comparison group (3.31% versus 6.17%). This is a difference of 3.04% in the rate of special education use between the two groups at PFS-CPC: Report for 2017\u201318 May 2019 32 the end of first grade, and is a 92% decrease for the intervention group relative to the comparison group. Cohort 2\u2019s first grade special education rate also mirrors Cohort 1 in first grade with a similar difference of 2.93% relative to the its comparison group, representing a 69% decrease. Finally, we now have data for Cohort 1 and its comparison group at the end of second grade and we see similar trends favoring the intervention group with a difference of 3.78%, representing a 91% decrease. These results show that the difference in special education placements in favor of the intervention group is becoming larger as children age. We want to acknowledge a few data limitations. As described earlier, SRI was unable to identify with certainty children from the comparison group who may have received pre-K programming in non-CPS funded settings in order to exclude them from the comparison group sample. We did however exclude from the comparison group all children who had a CPS identification number when they entered kindergarten, which serves as an indication that they attended a CPS preschool program and/or were receiving services from the school district. In addition, with the propensity score weighting procedure, we used a large comparison sample to reduce the impact of possible preschool attendance on our estimation of comparison group outcomes. That is, there is likely some proportion of children in the comparison group samples who did attend some type of public preschool program (e.g., Head Start) or private child care program using child care subsidies and/or tuition. It is not clear how inclusion of some children with preschool experience in the comparison group is affecting the special education rate in that group. We also want to note that in the original design of this PFS project using the CPC model, the planning team decided that the targeted population was high risk children but not necessarily those with identified disabilities prior to participation in preschool. Therefore, children who were identified prior to enrollment in PreK were excluded from the sample that is tracked over time. Finally, the evaluation team used disability categories to define who had a mild versus a severe disability, based on the assumption that the intervention was only targeting prevention of the need for later special education services for children at- risk of a mild disability. Because the disability categories do not provide information on the severity of a child\u2019s disability or delay, the team used additional information about placement in special day classes and blended classrooms to identify children PFS-CPC: Report for 2017\u201318 May 2019 33 as having more \u201csevere\u201d delays or disabilities. While the information sources used are proxies for identifying those with \u201csevere\u201d delays or disabilities who were excluded from the analyses, rather than direct measurements of the severity of a child\u2019s disability, they were agreed upon with input from CPS as appropriate proxies to identify severity. We recognize that some children with developmental delay may eventually develop a more severe disorder and need services as could some of the children with speech and language delays and specific learning disabilities. To put the findings about rates of special education placement for CPC cohorts and comparison group samples into context, we searched for comparable data and organized our search around three questions. First, to what extent are the findings similar to those reported in the Chicago Longitudinal Study of the earlier CPC cohort? Second, how do kindergarten special education placement rates for the intervention and comparison groups compare with kindergarten special education placement rates in the Chicago Public Schools? Third, to what extent are the findings similar to the national data about special education placement rates for children who attend preschool versus those who do not? TO WHAT EXTENT ARE THE FINDINGS SIMILAR TO THOSE REPORTED IN THE CHICAGO LONGITUDINAL STUDY OF THE EARLIER CPC COHORT? Studies of the Chicago Longitudinal Study (CLS) cohort of children who attended CPC preschool in 1984 showed that special education placement rates were lower for CPC recipients compared with children who did not participate in CPC preschool. In one CLS analysis that looked at children 6 to 18 years old, CPC participants had an average special education placement rate of 14.4% compared with 24.6% for children in the comparison group (). This rate was calculated by averaging rates across school years, and therefore is not directly comparable to the kindergarten special education rates described in this report. In another CLS analysis that compared average special education placement rates from school entry through eighth grade for children who had attended a CPC preschool with a comparison group, special education placement rates were 12.5% versus 18.4%, respectively (). Significant differences in special education placement rates between children in the CLS who did and did not attend CPC preschool programs emerged as early as first grade (0.5% versus 3.2%) (). We see difference in special education rates also emerging by the end of first grade, a 92% PFS-CPC: Report for 2017\u201318 May 2019 34 decrease for the intervention group relative to the comparison group. These earlier CLS findings suggest that special education rates may rise over the early elementary grades and we may continue detect a positive intervention effect for reduced special education placement from attendance in CPC preschool across all the early grades.29 Other changes in how children are identified and placed in special education have occurred since the 1990s when these latter analyses were completed making these comparisons less appropriate than more contemporary data. These changes include but are not limited to improvements in early screening and programming prior to entering kindergarten as well as during the early elementary school years. For instance, with increasing attention to signs of early reading difficulties once children enter elementary school, and the growing research about the importance of skilled reading by 3rd grade for continuing school success (), many school districts may be identifying at risk children and providing extra instructional supports that prevent milder disabilities from emerging. Such improvements may mean that contemporary children who would have needed special education in the past are being identified during preschool or the early elementary grades and given more intensive or focused supports that can prevent those early difficulties from becoming more severe delays and learning problems requiring special education services. The percentage of children needing special education for developmental delay, specific learning disability, or speech/language issues across all groups ranged from 3% in first grade for Cohort 1 to close to 8% for the Cohort 1 comparison group in second grade. Interestingly, the majority of children in the intervention cohort were identified during the preschool year while enrolled in CPC preschool classrooms. Because of changes in how children are identified for services and how important assessment and early intervention are in early care and education settings, we believe as part of best practices in a high-quality preschool classroom, more children may be identified for services (and appropriately so) early in their school careers than may have occurred previously when the CLS was conducted. The hypothesized role of CPC in preventing or reducing the need for special education is still valid; however, 29 Support for this suggestion comes from earlier CPC studies that found that students with extended CPC program participation (through second or third grade) had lower rates of special education placements than CPC students having fewer years of intervention through middle () and high school (). PFS-CPC: Report for 2017\u201318 May 2019 35 outcome. in contemporary settings, there may be an initial increase in identification and placement before we see long-term reductions and/or average reductions in this HOW DO KINDERGARTEN SPECIAL EDUCATION PLACEMENT RATES FOR THE INTERVENTION AND COMPARISON GROUPS COMPARE WITH KINDERGARTEN SPECIAL EDUCATION PLACEMENT RATES IN CHICAGO PUBLIC SCHOOLS? In the previous 2015\u201316 school year, the kindergarten special education placement rate for CPS overall for what we are identifying as mild delays and disorders was 7.4%. Our findings show that both Cohort 1 and their comparison group have rates that are lower than the rate in CPS overall during the same year. We do not have a good explanation for this difference. Historical data from CPS demonstrate that special education placement rates during preschool have been relatively high for children attending CPS preschool (10\u201314% for the last 5 school years)30 and that the overall CPS rates decrease in kindergarten (7\u20138%) and steadily climb through elementary and middle school grades; by third grade, for example, overall special education rates in CPS have been 10\u201311% for the last 5 school years (). These special education rates in CPS suggest that we will see increases in special education rates as children move through the early elementary years, probably for both groups. We hypothesized that the rate for the intervention group would increase at a slower rate and be lower than the rate in the comparison group in the later elementary years if the preschool CPC experiences have helped intervention group children have better developmental trajectories. Continued follow- up of the cohorts will address this question more fully, but the 2nd grade data reported here suggest that it is being supported.31 TO WHAT EXTENT ARE THE FINDINGS SIMILAR TO THE NATIONAL DATA ABOUT SPECIAL EDUCATION PLACEMENT RATES FOR CHILDREN WHO ATTEND PRESCHOOL VERSUS THOSE WHO DO NOT? Data collected annually from every state as part of federal reporting required under the Individual with Disabilities Education Act by the Office of Special Education 30 For the previous 2015-16 school year, we found that for low-income children who had attended any CPS preschool, the overall IEP special education rate in kindergarten was 13.7% (10.7% for mild and 3% for not mild delays and disorders). 31 The special education rates in CPS preschool may be higher than rates for kindergarten because children identified with a delay or disability prior to kindergarten would be likely to be referred to CPS and when determined to be eligible for an IEP, they would be served in a CPS preschool program. PFS-CPC: Report for 2017\u201318 May 2019 36 Programs give us another perspective on the special education rates. The most recent national data from these sources indicate that 8% of children were receiving special education services at age 5, the kindergarten year for most students, 10% of 6 year olds (or equivalent to first grade students), and 11% of 7 year olds (equivalent to second grade students)32. Other data from the nationally representative Head Start Family and Child Experiences Survey (FACES) for children participating in Head Start preschool programs () and the nationally representative ECLS-B study ()33 found rates higher than those for our comparison sample (8% and 7%, respectively). However, findings from the FACES study also suggest that more children in Head Start without an Individual Education Plan (IEP) meet other criteria for disability or delay than are served (about 33% meet criteria indicative of delays such as very low assessment scores on standard measures, but only 8% had an IEP and were receiving special education services) (). These national data and other research suggest that children from low-SES families are at greater risk of developmental delay and low levels of kindergarten readiness but may be less likely than higher SES children to be receiving special education services in early childhood (). Taken together, these other data suggest that the rates we are seeing in both the intervention and comparison groups are lower than would be expected for our high risk samples. Additional Findings In addition to the agreed-upon outcome measures, we think it is important to note a few other observations in tracking four cohorts of CPC children and their peers over time. When we examine the percentage of students who are meeting the pre- determined dosage threshold for CPC exposure (i.e., 66% of the days), we observed greater attendance across the cohorts. For example, only 79% of Cohort 1 children ever enrolled in CPC sites attended 66% of the program days but 93% of Cohort 4 children met the dosage threshold. Although we do not know what caused higher attendance across the cohorts, it is possible the CPC program or other CPS policies supported better attendance. Secondly, although we observed high attrition (or 32 Data sources: : U.S. Department of Education, EDFacts Data Warehouse (EDW): \u201cIDEA Part B Child Count and Educational Environments Collection,\u201d 2017-18. Data extracted as of July 11, 2018 from file specifications 002 and 089. U.S. Bureau of the Census. \"2017 State Population Estimates by Age, Sex, Race, and Hispanic Origin\". Data accessed July 2018 from http://www.census.gov/popest 33 ECLS-B children entered kindergarten in 2006 or 2007. PFS-CPC: Report for 2017\u201318 May 2019 37 mobility) of children leaving the school district, the difference in attrition across the intervention and comparison groups was large, with CPC students having a much lower rate of attrition than comparison students, at least for Cohort 1 and Cohort 2. For Cohort 3, we observed a higher attrition from preschool to kindergarten compared to Cohorts 1 and 2. Again, we can only speculate on what caused these differences but perhaps a positive but unanticipated impact of CPC with its specific family engagement components is greater connections to the school, district, or community that resulted in less CPC families moving away. Finally, for the 3 cohorts of children who had TS GOLD data, administered and scored in the same way, we found that children who were identified as DLL (defined as home language other than English), were less likely to meet the K readiness criteria; however, full-day DLLs had much higher rates of K readiness than half-day DLLs. These data may be valuable in thinking about how to support all children served in the CPC and district preschool programs. Limitations The evaluation is limited to data already collected in the district data and as such, must use for a kindergarten readiness measure, an assessment tool that was not developed for these purposes. The TS GOLD\u2122 assessment is vulnerable to large (and maybe small) changes in training protocols and teacher turnover and both reliability and validity may suffer. In addition, the use of the TS GOLD\u2122 measure with ELL populations is problematic because some ELL children can be assessed on all six domains in English while others cannot. Furthermore, there are not scale scores for children who have the TS GOLD\u2122 language and literacy assessment domains in Spanish and therefore we did not have complete data needed for making the kindergarten readiness determination for those children. Because of the changes in items and scoring procedures with the TS GOLD\u2122 data for Cohort 4, the evaluation team could not calculate percentages for kindergarten readiness in this new cohort of entering kindergarteners. Use of a teacher-report measure as the indicator of kindergarten readiness can be seen as a limitation of this study. As described above, teacher effects or bias is also a limitation in the evaluation. The accuracy of teacher ratings of young children\u2019s behavior has been questioned by some early childhood researchers (Baker, PFS-CPC: Report for 2017\u201318 May 2019 38 ; ). Additionally, there is a need in the field for more research about the amount and types of teacher training and knowledge needed to assess young children reliably and accurately, even while it is widely acknowledged that teacher training and knowledge are critical (Institute of ; National Association Early Childhood Specialists in State Departments of Education & National Association for the Education of ; National Association for the Education of ). For the special education outcome at kindergarten, to the best of our ability we created a comparison group that was weighted to match closely the characteristics of children in the intervention cohort. However, both propensity score methods\u2013PSW and PSM\u2013have some disadvantages. One disadvantage is that these methods only account for observed (and observable) covariates. They cannot balance intervention and comparison groups on unobservable characteristics (for example, parent education levels or parent involvement in the children\u2019s early learning). Second, we can only identify those children who attended a CPS-funded preschool program prior to kindergarten. Many entering kindergarten children who meet the income and age criteria may have attended other preschool programs either public (e.g., state-funded preschool outside of the city of Chicago) or private (e.g., using child care subsidies for example). The evaluation team had no way of identifying which children attended these other settings because this information is not routinely collected at kindergarten entry in CPS. Conclusion Together, these findings show that early childhood education in the form of CPC is associated with rates of kindergarten readiness of 61% in Cohort 1, 42% in Cohort 2, and 44% in Cohort 3. The findings also show that there is a significant decrease in special education in kindergarten for the intervention group for Cohorts 2 and 3. This is a difference of 1.73% and 2.31% in the rate of special education use, representing a 51% and 58% decrease, respectively for the intervention group relative to the comparison group. This also is a much larger decrease than found in the Cohort 1 special education outcomes for kindergarten in the Year 2 report (a decrease of 11%). While the overall special education rates in both the intervention and comparison group children are very low at the end of kindergarten for all three PFS-CPC: Report for 2017\u201318 May 2019 39 cohorts, the rates are lower in the intervention group than the comparison group in all three cohorts; and the rate of the decrease is greater in Cohorts 2 and 3 (11% versus 51% versus 58% decreases). The findings also show that at the end of first grade the rate of special education placement for Cohort 1 was lower for the intervention group than for the comparison group (3.31% versus 6.17%), a 92% decrease for the intervention group relative to the comparison group. These first grade results show that the difference in special education placements in favor of the intervention group is increasing over the early school years. Finally, data for Cohort 1 and its comparison group at the end of second grade also show similar trends favoring the intervention group with a difference of 3.78%, representing a 91% decrease for the intervention group relative to the comparison group. These data suggest that perhaps over time children served in the CPC preschool classrooms in the year prior to entering kindergarten received several supports and services that led to a decreased need for special education services in the first three years of elementary school. In particular, we may see a group of children who were referred and assessed for special education supports during preschool and kindergarten then remediating by first and second grade such that they no longer need those additional supports. Additional follow-up of children through third and fourth grade and beyond would help better understand these trajectories in both the CPC students as well as their peers who did not receive district preschool. PFS-CPC: Report for 2017\u201318 May 2019 40 "}, {"target_population": "Students enrolled in low-cost private primary and secondary schools in the province of Punjab, Pakistan", "source": ["Low student learning is a common finding in much of the developing world.", "This paper uses a relatively unique dataset of five semiannual rounds of standardized test data to characterize and explain the short-term changes in student learning.", "The data are collected as part of the quality assurance system for a public-private partnership program that offers public subsidies conditional on minimum learning levels to low-cost private schools in Pakistan.", "Apart from a large positive distributional shift in learning between the first two test rounds, the learning distributions over test rounds show little progress.", "Schools are ejected from the program if they fail to achieve a minimum pass rate in the test in two consecutive attempts, making the test high stakes.", "Sharp regression discontinuity estimates show that the threat of program exit on schools that barely failed the test for the first time induces large learning gains.", "The large change in learning between the first two test rounds is likely attributable to this accountability pressure given that a large share of new program entrants failed in the first test round.", "Schools also qualify for substantial annual teacher bonuses if they achieve a minimum score in a composite measure of student test participation and mean test score.", "Sharp regression discontinuity estimates do not show that the prospect of future teacher bonus rewards induces learning gains for schools that barely did not qualify for the bonus."], "paper_id": "#7568", "title": "Short-run learning dynamics under a test-based accountability system: Evidence from Pakistan", "pdf_txt": "d e z i r o h t u A e r u s o c s D c i l i l b u P d e z i r o h t u A e r u s o c s D c i l i l b u P d e z i r o h t u A e r u s o c s D c i l i l b u P d e z i r o h t u A e r u s o c s D c i l i l b u P Policy Research Working Paper 5465 Short-run Learning Dynamics under a Test-based Accountability System Evidence from Pakistan Felipe Barrera-Osorio Dhushyanth Raju The World Bank South Asia Region Education Unit & Human Development Network Education Unit November 2010 WPS5465 Policy Research Working Paper 5465 Abstract Low student learning is a common finding in much of the developing world. This paper uses a relatively unique dataset of five semiannual rounds of standardized test data to characterize and explain the short-term changes in student learning. The data are collected as part of the quality assurance system for a public-private partnership program that offers public subsidies conditional on minimum learning levels to low-cost private schools in Pakistan. Apart from a large positive distributional shift in learning between the first two test rounds, the learning distributions over test rounds show little progress. Schools are ejected from the program if they fail to achieve a minimum pass rate in the test in two consecutive attempts, making the test high stakes. Sharp regression discontinuity estimates show that the threat of program exit on schools that barely failed the test for the first time induces large learning gains. The large change in learning between the first two test rounds is likely attributable to this accountability pressure given that a large share of new program entrants failed in the first test round. Schools also qualify for substantial annual teacher bonuses if they achieve a minimum score in a composite measure of student test participation and mean test score. Sharp regression discontinuity estimates do not show that the prospect of future teacher bonus rewards induces learning gains for schools that barely did not qualify for the bonus. This paper\u2014a product of the Education Unit, South Asia Region; and the Education Unit, Human Development Network\u2014is part of a larger effort of the departments to rigorously evaluate innovative government programs supported by World Bank lending operations. Policy Research Working Papers are also posted on the Web at http://econ.worldbank. org. The authors may be contacted at fbarrera@worldbank.org and draju2@worldbank.org. The Policy Research Working Paper Series disseminates the findings of work in progress to encourage the exchange of ideas about development issues. An objective of the series is to get the findings out quickly, even if the presentations are less than fully polished. The papers carry the names of the authors and should be cited accordingly. The findings, interpretations, and conclusions expressed in this paper are entirely those of the authors. They do not necessarily represent the views of the International Bank for Reconstruction and Development/World Bank and its affiliated organizations, or those of the Executive Directors of the World Bank or the governments they represent. Produced by the Research Support Team Short-run learning dynamics under a test-based accountability system: Evidence from Pakistan\uf02a Felipe Barrera-Osorio\u2020 Dhushyanth Raju\u2020 JEL classification codes: I21; I28 Keywords: education; Pakistan; private schools; subsidies; learning; test accountability; teacher incentives; regression-discontinuity design. \uf02a We thank the Punjab Education Foundation, in particular, Mian Kashif Ijaz and Huma Rizvi, for extensive discussions on program and test design and implementation and assistance with the program administrative data. We also thank Amit Dar, Sofia Shakil, Huma Waheed, and the Government of Punjab School Education Department/Project Management and Implementation Unit for their encouragement and support of the research project. The findings, interpretations, and conclusions expressed herein are our own and do not necessarily represent the views of the World Bank, its Board of Directors, or any of its member countries. All remaining errors are our own. \u2020 World Bank, Washington, DC. Email addresses: fbarrera@worldbank.org; draju2@worldbank.org. 1. Introduction Low student learning is an important feature in Pakistan, as it is in much of the developing world (Andrabi et al. 2007; Glewwe and Kremer 2006; Hanushek and W\u00f6\u00dfmann 2007). The shortfalls relative to national curricular standards are exacerbated by the fact that a large share of children, particularly rural, female, and poor children, obtains little or no formal schooling in the country, likely seriously impairing their long-term socioeconomic prospects. In addition, in general, the factors and processes that produce real and sustained gains in student learning are not as well understood as the factors and processes that produce real and sustained gains in school participation and attainment. Evidence also shows that the factors and processes behind learning can differ from the factors and processes behind participation (Andrabi et al. 2007). This background makes the search for effective policy solutions to improve learning outcomes pressing yet tenuous. In this study, we use five semiannual rounds of standardized test data to characterize and explain the evolution of student learning over a period which spans three academic years (2007/08-2009/10). The tests were conducted in low-cost private schools supported by public cash subsidies under an innovative test-based accountability program in the province of Punjab, Pakistan administered by the Punjab Education Foundation (PEF), called the Foundation Assisted Schools (FAS) program. The data are repeated cross-sections at the student level and longitudinal at the school level. Such data are relatively rare for a developing country. Additionally, the data are unusual for a low-income setting given that they are generated from what appears to be a well-designed and robust quality assurance testing system integrated into the administration of the program, providing a high degree of confidence that the test scores can be interpreted as sound estimates of underlying learning. Initiated in 2005, the FAS program provides conditional cash subsidies to low-cost private schools with the objective of offering private schooling opportunities for children from low-income households and raising the level of learning in low-cost private schools. The cash subsidies are provided monthly and on a per-student basis, with essentially no conditions on how the subsidy is to be used by the program school. The subsidy amount is purposely set low to ensure that only low-cost private schools self-select to participate in the program; the original amount was also purposely set at half the estimated per-student cost in the public school system.1 In return for receiving the subsidy benefit, the program school has to, among other things, waive tuition and fees for all students and ensure that the school achieves a minimum student pass rate in the Quality Assurance Test (QAT). Program schools that satisfy the above conditions are also eligible for other substantial cash benefits offered on an annual basis: group-based bonuses for teachers in schools that achieve high QAT pass rates/mean scores and competitive bonuses for schools that rank highest in the QAT in each main program district. Each of the above incentive features (the structure of the benefits as well as the benefit eligibility rules) represents key program innovations in the education field that may induce participation, equity, and learning gains.2 We are not aware of any other program in a developing country which combines these innovations into a single intervention. As of June 2010, the FAS program has proceeded through six phases of expansion and supports 798,000 students in 1,779 schools in 29 of the 36 districts in the province, making it one of the largest PPP initiatives in education in the developing world. The learning data used in the study come from the QAT. The QAT is a curriculum-based, multi-subject, written test offered biannually in program schools. It is designed by professional subject specialists in PEF, and, starting with QAT 4, the administration of the test was competitively outsourced to independent testing agencies. The testing agencies are expected to adhere to the testing protocols set by PEF, with testing agency compliance monitoring by PEF at all program schools. Importantly, the testing agencies are instructed by PEF to follow pre- established procedures to control for certain types of potential strategic responses of schools (i.e., cheating in a broad sense) that may artificially raise test scores. To date, nine rounds of the QAT (QAT 1-QAT 9) have been administered, of which data from five rounds, QAT 4-QAT 8, administered between November 2007 and November 2009, are used in this study. QAT 4 is the first round of test data used in the study due to sample size considerations: it is the first QAT administered after the first major expansion of the FAS program. 1 Setting the subsidy level in such a way was considered important by PEF for securing political buy-in for the use of public funds for the initiative. 2 The typical subsidy program is designed to finance stipulated education inputs (Gauri and Vawda 2003). 3 We examine four questions. The first three questions are descriptive in nature. First, we explore how student learning at the school level has evolved in program schools over QAT rounds by examining summary statistics of the mean QAT score distributions and stochastic dominance relations between pairs of successive mean QAT score distributions. Second, we estimate the share of student-level QAT score variation attributable to different levels (district, school, grade, and student) and how the shares and levels of QAT score variation have evolved over QAT rounds. Third, we estimate the conditional mean relationship at the school level between basic pre-program school characteristics and the evolution of mean QAT scores over QAT rounds, controlling for school-level heterogeneity using alternative panel regression methods. The fourth question is causal in nature. We estimate the causal effects at the school level of specific program benefit rules on student learning in program schools. The first subquestion we ask is whether high-powered stick incentives can induce learning gains in program schools. Program schools that fail to achieve the minimum pass rate in a given QAT are offered a second opportunity in the following QAT. If the program school fails to achieve the minimum pass rate in two consecutive attempts, the school is permanently disqualified. This creates a high-stakes situation for first-time failers to rapidly boost their learning performance in order to avoid program disqualification. Applying a sharp regression discontinuity (RD) design to the data, we examine whether accountability pressure induces gains in mean scores in the ultimatum QAT among marginal first-time failers. We also examine whether any gains found persist over post- ultimatum QAT rounds. Such persistence is at times interpreted in the literature as indicating that gaming behavior is unlikely to be an explanatory factor though it cannot be ruled out. Several studies have examined the effects of (the threat of) sanctions and assistance on low-performing schools on performance in subsequent test rounds (see, e.g., Figlio and Rouse 2006; Chiang 2009; Rockoff and Turner 2008; West and Peterson 2006; and Rouse et al. 2007). Much of this research has focused on state public education systems in the United States where schools are rated on a letter grade scale from A to F based on summarizing multiple performance measures, including student performance on standardized tests, and where F-rated schools are 4 subjected to (the threat of) sanctions.3 Typically applying a sharp regression discontinuity design to the data, these studies consistently find short-run gains in test scores among (students in) marginal F-rated schools in the test which is included in the determination of the rating, with the estimated impacts ranging between 0.05\u22120.15 standard deviations. Some of the studies additionally find that (i) test score gains persist in the medium run among (students from) marginal F-rated schools, (ii) the estimated effects are unlikely to be driven by test-taking pool selection; and (iii) \u201cteaching to the test\u201d is likely to be an important driver as inferred from the small or lack of effects in standardized tests that are not used in the determination of the rating. The second subquestion we ask is whether carrot incentives can induce learning gains in program schools. Program schools qualify for substantial group-based teacher bonuses if they de facto achieve a minimum score of 100 in a composite measure of the number of students that took the QAT and the mean percentage score in the QAT. Also applying a sharp RD design to the data, we examine whether bonus nonqualification induces gains in mean scores among marginal nonqualifiers in the QAT round following the distribution of the teacher bonuses. We also examine the persistence of the carrot effect over subsequent QAT rounds. Though the carrot incentive question posed here is not perfectly correspondent (as the focus here is on the effects on nonbeneficiaries as opposed to beneficiaries), it broadly fits into the literature on the causal effects of teacher incentive schemes which directly tie teacher compensation to student learning levels and changes (Glewwe et al. 2009). To date, the limited but growing evidence is inconclusive with, for example, some studies finding positive effects on student learning (Lavy 2002, 2009; Muralidharan and Sundararaman 2009) and others finding positive effects on student learning which disappear post-intervention, suggesting temporary artificial gains in learning (Glewwe et al. 2003). The remainder of the paper is organized as follows. Section 2 describes the education context in Pakistan at the time that the FAS program was introduced. It also describes in detail the main design and implementation features of the program. Section 3 describes in detail the design and administration features of the Quality Assurance Test as well as the data used in the study. Section 4 discusses the evolution of the school-level mean QAT scores in core subjects over QAT rounds. Section 5 discusses the student-level QAT score variance decomposition 3 Sanctions for F-rated schools include a combination of stigmatization from publicly disclosing ratings, higher scrutiny and oversight by school system administrations, permission/private school vouchers for students to shift out of F-rated schools, changing school management and staff, and school closure. 5 analysis and findings. Section 6 discusses the school-level QAT score regression analysis and findings. Section 7 discusses the regression-discontinuity analysis and findings on the threat effect on mean QAT scores arising from QAT failure on marginal first-time failers and the carrot effect on mean QAT scores and test participation arising from missing teacher bonus qualification on marginal bonus nonqualifiers. Section 8 summarizes the main findings and provides some concluding remarks. 2. Context and program features The Foundation Assisted Schools (FAS) program was introduced into an education landscape characterized by three defining features. One: equitable access to schooling and attainment and achievement are acute, persistent challenges. Estimates using household sample survey data for Punjab from 2004/05, the year prior to the launch of the FAS program, indicate that the school participation rate (grade 1+) of children ages 6\u201315 years was 65.7%\u2014this share drops to 61.2%, 60.9%, and 48.7% when the sample is restricted to girls, children from rural households, and children from the poorest (bottom expenditure quintile) households, respectively. Conditional on any schooling (grade 1+), while 91.8% of individuals ages 17\u201321 years completed primary school (grade 5), only 40.7% of them completed secondary school (grade 10), with significantly lower shares for rural children and, in particular, poor children. The National Education Assessment System (NEAS) for Pakistan finds that scaled mean scores in mathematics and language assessments for a sample of grade-4 students in public schools in Punjab in 2005 were significantly less than 500, suggesting that, on average, students, obtained less than 50% of the points in the assessments (Government of Pakistan 2006).  and  also find that the learning levels of grade-3 students in a selected sample of villages in Punjab measured in 2004 were far below curriculum standards in English, Urdu, and mathematics. Two: the public sector, which is the dominant provider of education, suffers from chronic weaknesses which impair its ability to effectively address the challenges in education access, equity, and quality. To a large extent, public sector performance is hampered by weak accountability and incentive systems (Government of Pakistan 2009; Social Policy and Development Center 2003). This state-of-affairs is exemplified by recent evidence on relative teacher performance between private and public schools in rural Punjab.  6 find that, while public school teachers tend to be better paid and have higher levels of education, training, and teaching experience than their private school counterparts, the teacher absenteeism rate in public schools is almost double that in private schools (15% vs. 8%). They also find that, while private school teacher salaries are increasing in teacher and student test scores and decreasing in teacher absenteeism, public school teacher salaries are largely unresponsive to these variables and are mainly a function of teacher credentials (education, training, and experience). The greater accountability in the private sector is likely due to market competitive forces which the public sector is not subject to, at least directly. Three: in the wake of the public sector failure to adequately address these issues, the private sector has emerged as a major alternate provider of education, growing dramatically in size and reach. In particular, the rapid growth of a private sector that offers schooling opportunities to low-income households has created a major policy opportunity. Using data from 2000,  find that there was an exponential increase in the number of private schools over the 1990s, with over 50% of existing private schools established on or after 1996. They also find that the birth rate of private schools in the recent period is higher in rural areas. These changes in the patterns of growth in private schools are also reflected in changes in the patterns of participation growth among students. Data from 2004/05 show that 18.7% of children ages 6\u201315 years were enrolled in private schools in Punjab, a 36% increase from 1998/99, with this increase largely attributable to private school participation increases among children from rural and poor households. The demand for private schooling is likely driven by the fact that fees in private schools tend to be low, accounting for a small percentage of mean annual household expenditure (Andrabi et al. 2008). It is also likely driven by the perceived higher quality of private schooling\u2014evidence from rural Punjab shows that the learning levels in private schools are significantly higher than in public schools, even after controlling for a range of village, household, and school characteristics (Andrabi et al. 2007). The FAS program and PEF are direct outcomes of the government\u2019s recognition of the importance of leveraging the potential of the growing low-cost private sector in addressing access, equity, and quality issues in primary and secondary education. PEF is a publicly-funded semi-autonomous statutory organization established in 1991 by the government. It serves as the main institutional conduit for PPP programs in education in Punjab. The organization\u2019s primary aims are to provide affordable private school opportunities to socioeconomically-disadvantaged 7 households and raise the quality of education in low-cost private schools. To these ends, it employs a variety of instruments such as providing vouchers to poor households in disadvantaged urban neighborhoods to attend selected low-cost private schools and supporting low-cost private schools with monthly per-student subsidies conditional on school quality standards, teacher training courses on subject content and pedagogical and classroom management techniques, and the insertion of competitively-hired subject specialist trainers in secondary schools for fixed terms.4 The FAS program is PEF\u2019s largest program. In the fiscal year 2009\u221210, PEF spent roughly 2.4 billion rupees (US$28.7 million, in current dollars) on the program\u2014this amount accounts for 93% of total expenditures by the organization in that year. It was initiated in November 2005 on a pilot basis in 54 schools in seven districts in Punjab. Since then, PEF has rapidly expanded program coverage in phases in terms of additional districts as well as more schools within districts. The program has proceeded through six phases (the pilot phase is considered by PEF to be phase 1). Phase-6 program schools entered the program in April 2010. As of June 2010, the program covers 798 thousand students in 1,779 private schools in 29 out of the 36 districts in Punjab. As a result of explicitly targeting the program at high illiteracy districts over phases 3\u22125, the majority of program students and schools (70% and 68%, respectively) are in seven districts located in the southern part of the province (see Figure 1). Table 1 provides summary statistics based on current administrative data on program schools separately by phase of entry. The sample consists of 1,776 primary (classes 1\u20135), middle (classes 1\u20138), and secondary schools (classes 1\u201310, 6\u201310).5 Looking at the aggregate sample (pooled across phases), the mean program school size is 455 students; in schools with both girls and boys enrollment, the mean ratio is 1 (gender parity). Program schools have on average 17 teachers and 16 classrooms. The mean student-teacher and student classroom ratios are 27:1 and 29:1, respectively. The majority of program schools is middle level (64%), coeducational (97%), rural (59%), and registered (100%). The phase-wise statistics indicate that mean enrollment is positively associated with length of program participation, this relationship also holds for mean boys and girls enrollment. The number of teachers and classrooms are also positively associated 4 The organization is continuing to expand its set of instruments: for example, it is now considering supporting private organizations/individuals that adopt and manage non-functional public schools handed over by the government for this initiative. 5 The three higher secondary schools in the program are excluded. 8 with length of program participation, increasing commensurately with enrollment increases as inferred from the stable student-teacher and student-classroom ratios across phases. The FAS program offers three types of cash benefits to schools. These benefits were introduced at different points in time. First, the program offers a per-student subsidy, which was introduced at program inception. The monthly per-student subsidy amount was fixed at Rs. 300 (US$3.5) for all students, which was roughly half of the estimated per-student cost in the public primary and secondary education system at the time the program was initiated. Starting in September 2008, the monthly per-student subsidy was raised to Rs. 350 (US$4.1) for students in grades 1\u20138 and Rs. 400 (US$4.7) for students in grades 9\u201312. The subsidy benefit is provided to schools on a monthly basis for all twelve months in the year. To facilitate timely and regular payments, starting in August 2007, the subsidy benefit amounts are electronically transferred to the bank accounts of program schools. Second, first announced in December 2006, every academic year, the program offers cash bonuses to teachers in high-performing schools. Details on the eligibility criteria for the bonuses are provided in Section 7 but a maximum of five teachers in program schools that achieve (in part) a minimum student pass rate of 90% (i.e., at least 90% of tested students obtain a minimum percentage of 40%) in the QAT receive a bonus award of Rs. 10,000 (US$118) each. This is a substantial bonus amount for teachers in program schools: using available data on maximum and minimum monthly teacher salaries from applications to the program by phase-3 and phase-4 program schools, we estimate that the bonus amount represents 29% and 59% of pre-program mean annualized maximum and minimum salaries. This bonus size is approximately an order of magnitude larger than the range of sizes observed in most teacher incentive programs (see Glewwe et al. 2003). In practice, the bonuses are offered to teachers who taught the classes and/or subjects that were tested in the QAT. Similar to the subsidy benefits, the bonuses are transferred electronically to the personal bank accounts of the teacher awardees. To date, four rounds of teacher bonuses have been awarded. Third, first announced in February 2007, every academic year, the program offers a competitive school bonus to the top-performing school in each major program district (there are seven major program districts). The program school with the highest student pass rate in the QAT is awarded Rs. 50,000 (US$588).6 This bonus size is relatively modest: given a pre- 6 Ties between schools in pass rates are broken by looking at mean percentage scores in the QAT. 9 program mean school size of 252 students in phase-3 and phase-4 schools based on data from program applications and a per-student subsidy of Rs. 300, the bonus amount represents 6% of the expected mean annual subsidy payment to program schools. Again, the bonuses are transferred electronically to the bank accounts of the school awardees. To date, three rounds of school bonuses have been awarded. Once schools qualify and join the FAS program, the partnership contract stipulates several conditions for maintaining benefit eligibility. The conditions that are stringently applied by PEF are (1) schooling is offered to students without charging them any tuition or fees (and displaying this status prominently on a PEF-issued signboard outside the school gate) and (2) participation of the program school in the QAT and that at least 66.67% of the tested students score 40% or higher on the QAT. A one-time violation of these conditions typically results in a warning and the capping of enrollment figures for the subsidy payment until the next QAT round. A second violation results in the permanent disqualification of the school with immediate effect. With the QAT-related condition, the school is permanently disqualified if it fails to achieve the minimum pass rate in the QAT in two consecutive attempts. Since the start of the program, there have been 51 schools that have been disqualified from the program due to double failure on the QAT. There are also other conditions for maintaining benefit eligibility. These include (1) registering the school with the District Registration Authority within one year of joining the program; (2) conducting only one class in a classroom in any period; (3) maintaining or upgrading the quality of the school\u2019s physical infrastructure (e.g., adequate classroom space, properly-constructed rooms and buildings, sufficient ventilation, and sufficient artificial and natural light); (4) adequate furniture and teaching tools (e.g., benches, desks, and blackboards); (5) monthly reporting on enrollment figures; (6) maximum student-teacher and student- classroom ratios of 35:1; (7) a minimum enrollment of 100 students; and (8) no after-hours classes or tutoring services at the school. These additional conditions are applied more leniently; typically, when PEF detects a violation among this subset of conditions, schools are provided with a warning and a grace period within which to comply. To date, no program schools have been disqualified for repeated violations of these conditions. 10 3. The Quality Assurance Test The Quality Assurance Test (QAT) is the backbone of the FAS program, as eligibility for program benefits are directly tied to the performance of the school in this test. The test has several design and administration strengths. In terms of salient design features, the QAT is designed by professional subject specialists at the Academic Development Unit (ADU) in PEF. It is a criterion-referenced test based on learning standards in the national curriculum.7 It tests five levels of cognitive learning under Bloom\u2019s (1956) classification: knowledge, comprehension, application, analysis, and synthesis. The test duration varies between 45\u201365 minutes, with shorter test durations for lower grades. The QATs designed for students in primary and elementary grades have sections in English, Urdu (the vernacular language in Punjab), mathematics, and general science; those designed for students in secondary grades have sections in English, Urdu, mathematics, and a combination of three of the following five subjects: biology, chemistry, and physics, electrical application, and computer science (the combination of the physical science subjects is the norm).8 Except in the English and Urdu sections, where the questions are matching, short-answer, or essay type (Urdu section only), questions in the rest of the subjects follow a four-option multiple-choice format. Instructions for the QAT are provided in Urdu; the questions and multiple answer choices in the non-language sections are in both Urdu and English. The QAT is offered twice every academic year, first in November and second in March. The tests are structured identically and are of equal difficulty but more material is covered in the March test, in line with the syllabi in the program schools.9 To help schools familiarize themselves with the test content and format, PEF periodically shares sample test papers with program schools. PEF has also developed and periodically shares content lists which delineate expected content knowledge, separately by grade and subject.10 7 The majority of program schools use textbooks from the Punjab Textbook Board as they are provided free of charge through the program\u2014these textbooks are based on the national curriculum. 8 Each program school is categorized into a subject group based on information provided prior to the QAT. The subject group determines the subjects tested in classes 9 and 10. The groups are Biology (physics, chemistry, biology, math, English, and Urdu), Electrical Application (physics, chemistry, electrical application, math, English, Urdu), and Computer Science (physics, chemistry, computer science, math, English, Urdu). 9 The November QAT tests material from the first six months of the academic year. The March QAT tests material from the full academic year. 10 Sample QAT papers and content lists are available on PEF\u2019s website at http://www.pef.edu.pk/downloads-model- papers.html and http://www.pef.edu.pk/downloads-content-list.html, respectively (Last accessed: June 15, 2010). Content lists are also shared with program schools in booklet form. The first time the contents lists were shared was in June 2007, prior to QAT 4. 11 In terms of salient administration features, the testing is school-based, with students tested in their school during normal school hours. The test papers are written, formatted, sorted, counted, and sealed in envelopes by ADU. PEF also administered the tests at program schools in QAT 1\u2212QAT 3. Starting from QAT 4, the administration of the test was competitively outsourced to independent testing agencies, namely the Board of Intermediate and Secondary Education (BISE), Bahawalpur and the Punjab University Education Testing Service, Lahore.11 The testing agencies are expected to strictly follow the test administration guidelines prepared by PEF and are responsible for the administration steps starting from securely transporting the test materials to the schools and ending with hand-scoring the test following the provided scoring guides and the delivery of the student- and subject-wise test score database and filled-in and unused question papers, as well as brief test administration reports and test administration checklists for each school, to ADU. PEF is not completely divorced from test administration however\u2014it sends a PEF staff member to be present at each test to monitor test agency compliance with the guidelines; if any problems arise, the staff member is authorized to take corrective steps. The staff member is expected to fill in and submit a monitoring report (accompanied by photographs and video footage [see Figure 2 for examples]) for each program school covered. Although the QAT is a pre-announced test, it attempts to control for test pool selection by the school at the grade level. Prior to administering the QAT, PEF sends an intimation letter to the school some two-three weeks in advance of the planned test date, with key test planning information. The testing agency also communicates the same information to the school a few days before the planned test date, either by letter or personal visit. Importantly, schools are notified that 100% attendance is required on the test date, with attendance numbers checked against the grade-wise enrollment statement submitted to PEF for the latest subsidy benefit payment. Consistent with the test administration guidelines, in practice, the QAT is administered at the program school if the student attendance rate is at least 80% (PEF reports that test cancellation due to lower-than-required student attendance is a rare event). The number of test papers in each grade-specific packet is determined by ADU based on the latest submitted monthly enrollment statement. If the number of students in the grade selected for the QAT 11 PEF reportedly made the decision to outsource the testing in order to (i) increase program school confidence in the integrity of the testing process and the test results as well as (ii) release the organization from the administrative burden of performing these critical activities during a period of significant program scale-up. 12 exceeds the number of enclosed test papers, the testing agency is directed to select the longer- tenure students by examining the school enrollment records for the last three months (again, ADU reports that this is a rare event, as changes in enrollment usually occur at the start of the academic year and the QATs are administered well into the academic year). The testing agency also checks the enrollment and attendance records over the last three months for fictitious students and impersonation cases. QAT procedures have been developed to discourage schools from strategically concentrating on some grades for test preparation and to limit the risk of test leakage and its consequences. In primary schools, the QAT tests two grades; in middle and secondary schools, it tests three grades. Which specific grades are selected to be tested in a given school are kept strictly confidential by the ADU team\u2014both the testing agency and the program school learn which grades will be tested only when the sealed test packets are opened by the testing agency at the school in the presence of the school administrator(s) just before testing time. The testing agency also only brings in the sealed test packets to be used at that school on the day of the test. In addition, for each grade, eight different question papers are prepared by the ADU. These questions papers are randomized for each grade. Table 2 shows the practical results of implementing these procedures: it presents the top-four combinations of tested grades and the associated shares of program schools by QAT round. A number of additional, more standard procedures are applied to prevent cheating. Teachers and school administers are not permitted to enter the testing area during the test. Test invigilation is typically carried out by a team of at least three persons. Children are not allowed to bring any materials or stationery (other than pens) into the testing area. The grades selected for the QAT are tested simultaneously in the same testing area and the seating for the students is mixed. All test materials provided to the test takers are collected back. All unused test materials are retained by the testing agency. ADU also reports that test item recycling across QAT rounds is presently rare given the size of its test item bank. The QAT serves as the main source of data for the analysis of learning dynamics in program schools. While PEF has conducted nine QATs since the inception of the FAS program (QAT 9, the latest QAT, was administered in March 2010), this study uses data from QAT 4\u2212QAT 8 which spans November 2007\u2013November 2009, a two-year period, covering, in whole or in part, three academic years. QAT 4 is the first QAT round in the analysis as it represents the 13 first QAT after the first major expansion of the program: phase-3, which increased the number of program schools from 194 to 676 schools or by 248%. The sample for the learning dynamics analysis is restricted to phase-3 and phase-4 program schools. This is for two reasons. First, large numbers of schools entered into the program in these phases, and these schools have been in the program for a sufficiently long period to examine short-run dynamics (phase-3 schools have been subjected to five QATs and phase-4 schools four). Second, by phase-3, PEF had formalized the program entry qualification process, introducing standardized application forms, unannounced school inspections by PEF staff with standardized inspection forms, and an entry test, called the Short-Listing Quality Assurance Test (SLQAT), which is a pared-down version of the QAT. As a result, pre-program information on schools from the entry qualification stages is available for phase-3 and phase-4 schools, allowing the examination of the correlations between pre-program characteristics and the learning levels and changes, as well as their use as a form of specification testing in the causal analysis of the effects on learning from program design features that introduce stick and carrot incentives. The data were provided by PEF in QAT-specific databases. Each QAT database is at the student level, with the number of points scored and/or the percent score in each relevant subject. Information on the school and grade of the tested student is also provided. Schools in the databases for QAT 5\u2212QAT 8 were identified by both their names and unique identification numbers provided by PEF. School-level summary statistics on QAT performance\u2014such as the number of test takers, test score means, test score standard deviations, and test pass rates\u2014 derived from the student-level data were linked across QAT rounds using the unique school identifiers. There were no issues in the linking process: when a school in a given QAT was expected to be also found in another QAT, it was. Program schools in the QAT 4 database were however only identified by school name (at times augmented by location markers inserted into the school name field). Thus, schools in QAT 4 were linked to the schools in QAT 5 by visually matching on school names. There were 674 program schools that took QAT 4; 658 of them were expected to be found in QAT 5. Matching on school names yielded 625 linked schools (a success rate of 95%). Table 3 presents the number of phase-3 and phase-4 program schools that took each of the QATs. It also presents the number of phase-3 and phase-4 schools that qualified for entry and 14 joined the program. The first QAT that phase-3 program schools took was QAT 4 in November 2007. The first QAT that phase-4 program schools took was QAT 5 in March 2008. It appears that until QAT 8, there was virtually no school attrition out of the program. Even in QAT 8, the attrition was minor: only 3% of phase-3 and phase-4 program schools exited the program. The majority of schools that exited did so due to disqualification for consecutive failures on the QAT. This finding of low attrition from the program indicates that sample selection of this form is unlikely to be a source of bias in the learning dynamics analysis. Table 4 presents the number of students tested in the various QAT rounds, separately by grade. The sample comprises of all program schools. We discern two patterns that signal test design and administration procedures at work. First, the number of grades that are potential targets for testing has expanded over QAT rounds: in QAT 4, the tested grades were drawn from a universe of four grades. By QAT 8, it was nine. Second, the changing shape of the frequency distribution of test takers by grade between QAT rounds is consistent with the procedure of changing the combination of grades tested in a given program school over QAT rounds. 4. Evolution in learning In this section, we examine how learning has evolved over QAT rounds among phase-3 and phase-4 program schools, where learning is measured in terms of mean QAT scores in the core subjects of English, mathematics, and Urdu. Table 5 presents means and standard deviations for school-level mean QAT scores by QAT round. These statistics are presented for total mean QAT scores as well as the subject-specific mean QAT scores. Figures 3 and 4 depict kernel estimates of the probability density functions (PDFs) for total mean scores by QAT round for phase-3 and phase-4 program schools, respectively. Mean QAT scores for both phase-3 and phase-4 programs are normalized using the mean QAT 4 score distribution for phase-3 program schools as the base. Looking first at phase-3 program schools, we find that mean scores jumped 2.90 standard deviations between QAT 4 and QAT 5. Figure 3 clearly displays this distributional shift. This is a massive change that occurred over a short period of four months. In Section 7, we examine whether this substantial change in learning is attributable to some extent to accountability pressure on a large number of phase-3 program schools that failed to achieve the minimum pass rate for program benefit maintenance in QAT 4. Changes in learning after QAT 5 are relatively 15 more modest, with mean scores backtracking somewhat in QAT 7 and QAT 8 relative to those of QAT 6 by 0.42 and 0.36 standard deviations, respectively. Decomposing the mean total score into its constituent subjects, we find that the mean scores in all subjects depict the same major increase in learning between QAT 4 and QAT 5 as the mean total score. Mean English and mathematics scores continue to show similar trends over QAT rounds as the mean total scores; mean Urdu scores however appear to follow a counter-trend to the mean total scores in later QAT rounds. Similar to the trend for the level of mean scores, the variation in mean scores as measured by standard deviations shows a pattern of increase (peaking in QAT 6) and then decline over QAT rounds. Variations in mean English and mathematics scores depict similar trends to the variation in mean total scores, while variation in mean Urdu scores follows a counter-trend to the variation in mean total scores. Phase-4 program schools entered in the program prior to QAT 5. Mean scores in QAT 5 were 2.51 standard deviations higher than the mean scores for phase-3 program schools in their first QAT, QAT 4. However, the mean scores were 0.39 standard deviations lower than how phase-3 program schools performed in QAT 5. Over QAT 5\u22128, mean scores for phase-4 program schools do not show any discernible trend, with mean scores fluctuating between 2.5 and 2.9 standard deviations. Similarly, the subject-specific mean scores show no discernible trend, displaying stronger fluctuations over QAT rounds. The effects of these fluctuations on mean total scores are however dampened by the counter-fluctuation of mean Urdu scores vis-\u00e0-vis mean English and mathematics scores. Variation as measured by standard deviations in mean total scores shows an increase from QAT 5 to QAT 6 and then a decline over subsequent QAT rounds; similar trends are exhibited by the subject-specific mean scores. In addition to examining summary statistics of the mean QAT score distributions, we test for stochastic dominance relations between successive pairs of mean QAT score distributions for phase-3 and phase-4 program schools separately. Suppose we have two distributions A and B, characterized by their cumulative distribution functions (CDFs) AF and BF , respectively. The distribution B stochastically dominates distribution A at first order, if for any argument z, \uf028 \uf029 F z A \uf0b3 \uf028 \uf029 F z B . If Z denotes learning and the observations are schools, this implies that the incidence of schools with learning values equal to or less than a \u2018low\u2019 learning level z is higher under distribution A than under distribution B. Higher orders of stochastic dominance can be 16 defined analogously. Denote kD to be dominance function of order s for distribution K A B \uf03d , , s defined recursively by the relations \uf028 \uf029 1 D z k \uf03d \uf028 \uf029 s F z D k , 1 \uf02b \uf028 \uf029 z \uf03d \uf028 \uf029 D x dx s k s , \uf03d 1, 2,3,... z \uf0f2 z Distribution B stochastically dominates distribution A at order s if \uf028 \uf029 s D z A s D\uf03e B for all values of z in the joint support of the two distributions. Stochastic dominance of the second order implies that the low learning gap is higher under distribution A than under distribution B. Stochastic dominance of the third order implies that the squared low learning gap is higher under distribution A than under distribution B. We test for stochastic dominance based on an empirical likelihood ratio statistic proposed by  and extended by .12 This test tests for the rejection of the null hypothesis of nondominance between distributions A and B. The test tests first order as well as higher order stochastic dominance relations and permits the distributions under examination to be correlated, which is likely given serial correlation in the mean QAT score distributions. The test is restricted to the mean QAT score values between the 5th and 95th percentiles of the joint support of the two distributions. Figures 5 and 6 present CDFs of the mean QAT scores by QAT round for phase-3 and phase-4 program schools, respectively. For phase-3 program schools, pair-wise tests suggest that the distribution of mean QAT scores for QAT 5 and subsequent ones first-order dominate the corresponding distribution for QAT 4. There is no evidence of stochastic dominance up to the third order between successive mean score distributions among QAT 5\u2212QAT 8. Pair-wise tests of the successive mean score distributions among QAT 5\u2212QAT 8 for phase-4 program schools also suggest that the null hypothesis of nondominance up to the third order cannot be rejected under standard significance levels. Thus the evidence collectively points to two main findings. First, there was a major jump in learning as measured by mean scores between QAT 4 and QAT 5 for phase-3 program schools. Second, between QAT 5\u2212QAT 8 learning appears to be in an oscillating steady state over QAT rounds for both phase-3 and phase-4 program schools. This finding remains valid when mean total scores are decomposed into mean scores for English, mathematics, and Urdu. 12 The test is automated in Stata by . 17 5. Learning variance decomposition In this section, we examine how much of the total variability in QAT scores is attributable to the variability in QAT scores between program schools (i.e., due to school heterogeneity) versus the variability in QAT scores between students within program schools (i.e., due to student heterogeneity). Decomposing further, we examine how much of the total variability in QAT scores is attributable to the variability in QAT scores (1) between program districts, (2) between schools within district, (3) between grades within school, and (4) between students within grade. These are important questions as education policymakers and practitioners may have at their disposal the means to effectively reduce the extent of heterogeneity at the level of the school and grade (if they are found to be major contributing factors), thereby reducing total variability in student achievement. To answer the above questions, we fit two-level and four-level variance-components models (nested random effects models) to the student-level QAT score data. This exercise is performed separately for each round of QAT score data.13 It is also performed separately for phase-3 and phase-4 program schools. The two-level variance-components model is specified as y is \uf03d x \uf062 \uf061 \uf065 g s is \uf02b \uf02b i , \uf03d 1,..., I s , \uf03d 1,..., S , (1) where i indexes the student and s the school, and isy denotes the mean QAT score in the core subjects of English, mathematics, and Urdu for student i in school s. Students are nested within schools\u2014thus student QAT scores within schools are likely to be correlated. The QAT sometimes tested students in the same grades across schools. As a result, the grade g is viewed as a cross factor with the school s and is treated in the model as a fixed vector of grade dummies with a vector of fixed parameters \uf062 to be estimated. The error components s\uf061 and is\uf065 are assumed to be independently normally distributed with means zero and standard deviations gx s\uf061\uf073 and \uf065\uf073 , respectively, and are estimated correcting for potential correlation among students within schools and heteroskedasticity of arbitrary form. Since the error components ( s\uf061 and is\uf065 ) 13 We are unable to pool the student-level QAT score data over QAT rounds in order to examine how much the variation in student QAT scores is explained by inter-round variation, as a panel only exists at the school level; at the student level, we have repeated cross-sections. 18 are assumed to be independently distributed, the total variance in QAT scores \uf028 Var y \uf029is is equal to the sum of the between-school variance \uf028 \uf0292 s\uf061\uf073 and the within school, between-student variance \uf028 \uf0292 \uf065\uf073 . The four-level variance components model is specified as y igsd \uf0a2\uf03d x \uf062 \uf061 \uf061 \uf061 \uf065 g sd \uf02b \uf02b \uf02b \uf02b gsd d igsd , (2) where i indexes the student, g the grade, s the school, and d the district, and igsdy denotes the mean QAT score in core subjects for student i in grade g in school s in district d. There are four factors in this model: district, school, grade, and students. Students are nested within grades, grades within schools, and, in turn, schools within districts. These factors are treated as additive random effects in the model, where d\uf061 , sd\uf061 , and gsd\uf061 denote the random effects varying over district d, school s, and grade g, respectively. These random effects are assumed to be independently and normally distributed with means zero and standard deviations d\uf061\uf073 , sd\uf061\uf073 , and gsd\uf061\uf073 , respectively, and are estimated correcting for potential correlation among students within schools and heteroskedasticity of arbitrary form. As in (1), the grade g is additionally treated in the model as a fixed vector of grade dummies gx with a vector of fixed parameters \uf062 to be estimated. Given that the error components are assumed independent, total QAT score variation is equal to the sum of the variances of the error components. Both variance-components models are estimated via maximum likelihood. The results of the QAT score variance decomposition are presented in Table 6. Panel 1 presents the estimated shares of total variation at the selected levels for phase-3 FAS program schools, separately by QAT round. Panel 2 presents analogous results for phase-4 FAS program schools. We highlight four main results. First, the results in general suggest that most of the variation in QAT scores is at the level of the student\u2014for example, the two-level variance components estimation suggests that roughly 60\u201370% of total QAT score variation is between students within schools, while the remaining 30\u201340% is between schools. This finding does not change qualitatively when we look at the results from the four-level variance-components estimation: though the share falls to 50\u201360%, the variation in QAT scores between students remains the majority contributor to total QAT score variation. 19 Second, the four-level variance-components estimation suggests that the variation in QAT scores between program districts explains a small share of the total variation in QAT scores: between roughly 1\u20135%. This finding implies that the QAT score distributions are essentially identically centered across districts. Third, the estimation also suggests that within schools, the variation in QAT scores between tested grades explains a nontrivial share of total QAT score variation (around 15\u201318%). In addition, the share of total variation due to between- grade variation appears to be drawn from the shares due to between-school variation and between-student variation\u2014this absorption from both directions likely arises from the fact that tested grades are not only nested within schools but are also crossed with schools, given that sometimes students in the same grades are tested across schools. Fourth, the estimated total variation in student scores shows substantive movements over QAT rounds. Figure 7 depicts the evolution of the levels of total, between-school, and within- school variation in QAT scores, separately for students in phase-3 and phase-4 schools. In phase- 3 program schools, the level of total student score variation declines from QAT 4 to QAT 5 before rising sharply with QAT 6, and then declines monotonically over QAT 7 and QAT 8. The level of total student score variation for phase-4 program schools shows an identical trend, with a sharp increase between QAT 5 and QAT 6 before declining over the subsequent two rounds. It appears that the evolution in the level of total student score variation between QAT 4\u2013QAT 6 in phase 3 schools is largely explained by the evolution in the level of within-school student score variation; between-school student score variation shows little movement over these QAT rounds. Notwithstanding, what explains the uptick in total score variation between QAT 5 and QAT 6? There were no major changes in program design or implementation between those two rounds. The one change that did occur was the reduction in the number of QAT questions and points in the English, mathematics, and science sections from 15 to 10, while the points for the single question in the Urdu section remained fixed at 10. This test structure has been maintained through the subsequent QAT rounds. This change implies that the Urdu section now receives a higher weight in the QAT\u2014if the student only answered the Urdu question correctly in QAT 5, she would receive 18.2% on the test; if the same event occurred in QAT 6, she would receive 25% on the test. Given the reweighting of the QAT across subjects, the increase in total QAT score variation between QAT 5 and QAT 6 suggests that the variation in Urdu scores is higher than in 20 the other core subjects of English and mathematics. Figure 8 depicts the evolution of the level of QAT score variation by subject. While the level of QAT score variation in Urdu is not always higher than those for the other subjects, there was a major spike in the level of its variation between QAT 5 and QAT 6: Urdu score variation increased by 61% and 57% for phase-3 and phase-4 program schools, respectively. Thus, it appears that the score reweighting amplified the effect of the spike in Urdu score variation on total QAT score variation. We however cannot provide an explanation for the observed spike in Urdu score variation. How do these test score variance decomposition estimates compare to estimates from other recent studies from the South Asia region? Our estimates of inter-school differences appear to lie on the lower end of the range of available estimates. For example, similar to our findings, on the lower end, , using 2007 data from a nationally-representative sample of grade-2 and grade-4 students from Bhutan, find that 26\u201341% of the total variation in test scores across tested grades and subjects is explained by variation between schools.  find that, in a sample of grade-3 students in private and public schools in rural Punjab, Pakistan, roughly 50% of total variation is explained by variation between schools. On the higher end, although the statistic is not reported,  finds that, in a sample of public schools from rural Sindh, Pakistan, the majority of the variation in test scores for grade-3 and grade-5 students is explained by variation between schools. 6. Pre-program correlates of learning dynamics In this section, we examine what factors are associated with learning levels and changes in program schools by essentially estimating school effectiveness regressions. The factors that we examine are basic school-level characteristics captured at the program application stage (i.e., pre- program) for phase-3 and phase-4 program schools such as school size, number of teachers, maximum and minimum teacher salaries, number of classrooms, level, gender type, location, registration status, and mean SLQAT score. Learning is measured in terms of the school-level mean QAT score in the core subjects of mathematics, English, and Urdu. The conditional relationships between these factors and learning (changes) are investigated via simple pooled ordinary least squares (OLS) regression as well as via fixed-effects (FE) and random-effects (RE) regressions which take advantage of the panel structure of the data (multiple test rounds over schools) to control for heterogeneity at the school level. 21 The pooled OLS regression model is formulated as y sq \uf03d \uf02b \uf061 QAT \uf06c q \uf02b QAT q \uf0b4 x x \uf067 \uf062 \uf065 s s sq \uf02b \uf02b s , \uf03d 1,..., S q , \uf03d 1,..., Q , (3) where s indexes the school and q the QAT round, and sqy is the normalized mean QAT score in the core subjects for school s in QAT q, qQAT and sx are vectors of the QAT rounds and the time-invariant pre-program covariates, respectively; the associated parameter vectors \uf06c and\uf062 to be estimated capture the main effects of the covariates on mean QAT scores. The vector QAT q s x\uf0b4 captures interactions between the pre-program covariates and the QAT rounds; the associated parameter vector \uf067 to be estimated captures the differential effects of the pre- program covariates over QAT rounds. The stochastic error term sq\uf065 is assumed to be uncorrelated with the covariates and distributed normally. The classical assumption of identically and independently distributed errors is however relaxed. The error term is likely to be correlated over QAT rounds for a given school; hence, we estimate standard errors corrected for potential serial correlation as well as cross-sectional heteroskadasticity of arbitrary form. If the model is correctly specified and the error term assumptions are valid, the pooled OLS estimator is consistent. The pooled OLS estimator is inconsistent if the true model is the fixed effects model. The fixed-effects (FE) regression model is formulated as y sq \uf03d \uf061 s \uf02b QAT \uf06c q \uf02b QAT q \uf0b4 x \uf02b \uf067 \uf065 s sq s , \uf03d 1,..., S q , \uf03d 1,..., Q , (4) where s\uf061 is a vector of random school-specific variables treated as unknown parameters to be estimated that are potentially correlated with the other regressors qQAT and sx . The stochastic error term sq\uf065 is assumed to be uncorrelated with the covariates. The estimates of the parameter vectors \uf067 and \uf06c reflect within-school effects of the QAT rounds and the pre-program covariates over QAT rounds on mean QAT scores (relative to the base QAT, QAT 4), respectively. As with the OLS standard errors, the FE standard errors are adjusted for serial correlation and cross- sectional heteroskedasticity of arbitrary form. If the true model is a random effects model, the pooled OLS estimator and the FE estimator are consistent but inefficient. The random-effects (RE) regression model is formulated as 22 y sq \uf03d QAT \uf06c q \uf02b QAT q \uf0b4 x \uf02b \uf067 \uf062 \uf061 \uf065 s sq \uf02b \uf02b x s s s , \uf03d 1,..., S q , \uf03d 1,... Q , (5) where s\uf061 are assumed to be random intercepts that are distributed independently of the covariates. The random intercepts s\uf061 and the stochastic error term sq\uf065 are assumed to be distributed normally; they are however not assumed to be independently and identically distributed. The FE estimator is likely to be less biased than the pooled OLS estimator as the school fixed effects control for time-invariant unobserved factors that vary at the school level or higher. The model also allows for the school fixed effects to be correlated with the other covariates. However, as the estimator ignores the significant between-school variation present, the parameter estimates are likely to be imprecise. In addition, the independent effects of the time- invariant pre-program covariates cannot be estimated and are excluded from the model as they are perfectly collinear with the school fixed effects. The RE estimator allows the independent effects of the time-invariant pre-program covariates to be estimated. However, the RE model assumes that the school random effects are uncorrelated with the covariates, which is usually unrealistic in most applications. We use the artificial regression approach to test the null hypothesis that the more efficient RE estimator yields similar parameter estimates to the consistent FE estimator (Wooldridge 2002; Baltagi 2005). This test is robust version of the standard Hausman test, accounting for cross-sectional conditional heteroskedasticity and serial correlation of arbitrary form.14 As discussed in Section 4, given that significant changes in learning were only observed with phase-3 program schools, we only present results from estimating school-level learning growth-curve regressions for this sample over QAT 4\u20138. Table 7 presents the learning growth- curve regression results. The dependent variable in the models is the mean QAT score in the core subjects normalized using the QAT 4 score distribution. All regressions include district dummies although their parameter estimates are not reported. We find that the parameter estimates for pre- program characteristics appear to be of comparable sizes across the three estimation models. Estimates of the standard errors also appear to be similar across models; this implies that 14 The test is automated into Stata by . 23 statistical inference is largely identical across models. Hence, we discuss the estimation results without differentiating by model. Learning in QAT 5\u2013QAT 8 was higher than in QAT 4. The effects largely vary between 4\u20135 standard deviations at the conditional mean. This evidence is consistent with the unconditional evidence on changes in learning presented in Section 4. While the main effect lacks significance, middle schools have lower learning levels than primary schools in QAT 7 and QAT 8 relative to QAT 4. Similarly, while the main effect lacks significance, secondary schools have lower learning levels than primary schools in all rounds relative to QAT 4. The main and interactions effects for both middle and secondary schools are jointly significant. Registration status of the school has a positive effect on learning but this effect disappears in QAT 6 and QAT 8. While the main effect lacks significance, program school size appears to have a small positive effect on learning in QAT 5. The number of teachers also has a small positive effect on learning. Given that we control for school size, this effect can be interpreted as the effect of lower student- teacher ratios on learning. However, the effect disappears in QAT 5\u20138. Neither the location of the program school in terms of rural versus urban nor the gender status of the school in terms of coeducational versus single-sex appear to matter for learning levels or changes. Pass rates in the program entry test is positively associated with learning; the effect however does not vary with QAT round. Finally, maximum and minimum teacher salaries, which taken together may be interpreted as reflecting the level of teacher quality in the program school, are not associated with learning levels or changes. Explaining changes in learning is effectively tantamount to explaining the jump in learning between QAT 4 and QAT 5, as post-QAT 5, the learning distributions of phase-3 program schools appear to show some relatively small oscillating movement. The same situation applies to phase-4 program schools: mean scores appear to show only slight oscillating movement over QAT rounds. Tables A1 and A2 present learning growth-curve regression results over QAT 5\u2013QAT 8 for phase-3 and phase-4 program schools, respectively. The explanatory power of the models estimated over these samples drops precipitously. All the estimations presented above do not attempt to correct for potential measurement error in the regression covariates. Measurement error in covariates such as location, level, gender type, and registration status is unlikely but schools may overreport such characteristics as enrollment, teachers, and classrooms in the program application forms if they feel that it may 24 increase the likelihood of program entry. However, the fact that PEF visits all applicants and checks all reported figures is likely to help arrest this tendency. Notwithstanding, if present, the extent of overreporting is likely decreasing with true enrollment, teachers, and classrooms. For example, given that only private schools with at least 100 students can apply to the program, small schools may inflate the enrollment to exceed and distance themselves from this floor. If the observed values of a single covariate are inflated with measurement error negatively correlated with true values, the associated parameter estimate is upwardly biased. In a multiple regression framework, systematic measurement error of this form among multiple covariates is likely to bias regression parameters in unknown ways. 7. Causal effects of stick and carrot incentives on learning Exploiting the design feature that program assignment was ultimately strictly determined on the basis of SLQAT pass rates relative to a distinct, known cutoff and applying a sharp regression- discontinuity design to the data for phase-4 program schools,  find that the FAS program produced sizeable, positive effects on school size, school inputs such as teachers, classrooms, and blackboards, and student achievement in program schools with SLQAT pass rates near the cutoff. The documented learning gains induced by the program are theoretically attributable to several drivers. For example, a first potential mechanism is the QAT pass rate floor for continued program eligibility which is likely to create a strong push from below for the program school to invest resources, organize itself, and set and activate its own internal incentives to ensure that the majority of students learn enough to regularly pass the QAT. The effort exerted may also be dynamically continuous: more risk-averse program schools are likely to continue to exert an effort to raise the QAT performance of their students in order to extend the distance between their pass rate positions and the QAT pass rate floor, creating further \u201cbreathing room\u201d. A second potential mechanism is competition-driven pressure exerted by parents and other local stakeholders on the program school to raise student learning created by the FAS program requirement initiated with QAT 6 in November 2008 that the program school prominently publicly display the QAT pass rate performance rankings of all the program schools in the school\u2019s district. The first and second mechanisms are likely to produce learning gains by compressing the QAT distribution from the left. 25 A third potential mechanism is the offer of annual cash bonuses to teachers in program schools that (first) achieve a QAT pass rate of at least 90% (and, second, pass another threshold based on a simple addition of the number of testtakers and mean QAT score), as well as the competitive annual cash bonus to the program school with the highest QAT pass rate15 in the major program districts. Both of these bonuses\u2014which are substantial in both absolute terms and relative to pre-program school revenue and teacher salary estimates\u2014are likely to create a pull from above for schools to make an effort to continue to raise their QAT performance. This mechanism is likely to produce learning gains by shifting as well as stretching the QAT score distribution to the right. A fourth potential mechanism is the per-student subsidy benefit itself, which may provide higher revenues to the program school if pre-program tuition rates were lower than the subsidy benefit and/or school size has expanded. The regular, full receipt of the per-student subsidy benefit (rather than reliance on tuition payments from parents with low and/or unstable paying capacity) also raises the program school\u2019s confidence in the predictability of future cash flow. Both these factors may facilitate larger and longer-term investments in resources to improve teaching and learning at the school, and, hence, produce learning gains which are realized across the QAT score distribution. A fifth potential mechanism is the tuition-free schooling condition for program benefit eligibility. Household expenditures previously allocated for tuition and fees are freed up for other household consumption and investment priorities. One potential outcome is the reduction in the opportunity cost of child time, allowing the student to attend school more regularly, stay for the full school hours, and spend after-school hours on homework assignments. Another potential outcome is households redirect (a portion of) the freed-up resources to investments and expenditures that may directly or indirectly improve student learning such as better nutrition, uniforms, books and stationery, transportation to school, and tutoring services. The above potential mechanisms can generate real gains in student learning. However, the observed gains could also be the product of gaming behavior by schools, resulting in artificial gains in QAT scores. For example, program schools may respond to the QAT-related requirement for program continuation and additional benefits by systematically dropping low- performing students and/or screening in and admitting high potential or high-performing 15 With ties broken by using mean QAT scores. 26 students, cheating on the QAT, manipulating which students are present for the QAT (which is announced in advance) and testing conditions, and devoting resources and directing staff and student effort to QAT-taking strategies as well as reorienting teaching and learning towards the subject and content matter covered in the QAT, at the possible expense of a more extensive and richer teaching and learning agenda (see, e.g., Jacob 2005 and Jacob 2007 for reviews). These mechanisms likely work simultaneously to produce the observed learning gains under the program. Decomposing their individual contributions is likely to be difficult without structural modeling; and, even then, the data may not be sufficiently rich to permit the identification of the (full set) of structural parameters. However, it is still possible to partially unpack the black box of learning-gains production under the program via reduced-form estimation. This opportunity emerges from the combination of peculiar circumstance and program construction which allow the credible independent identification and estimation of the average causal effects of two mechanisms on defined subsets of program schools: (1) the threat of program exit for program schools that just failed the QAT a first time and (2) the prospect of receiving teacher bonuses in the next award round for program schools that just missed acquiring bonus eligibility in the preceding award round. A. Threat effect on learning As mentioned, design and circumstance combine to yield an opportunity and empirical strategy to investigate whether accountability pressure under the FAS program induces student learning gains. First, in terms of the enabling design, FAS program schools have to maintain a minimum QAT pass rate of 67% for continued program eligibility. Schools that fail to pass a given QAT are offered a second chance to pass the QAT the next time it is administered. In the intervening period, PEF may impose additional rules and regulations on first-time failers such as freezing their enrollment counts for benefit amount calculations. The school is permanently disqualified from the program if it fails the QAT two consecutive times. This appears to be a serious turn of event: Observations reported by PEF suggest that a disqualified school is significantly worse off relative to a low-cost private school that had remained continuously outside the program, with disqualified schools experiencing student and staff flight and closure. Thus, the high-stakes nature of the QAT introduces powerful incentives for first-time failers to boost learning in order to avoid the threat of program exit. 27 In terms of circumstance, in phase 3 of the program\u2019s expansion (the first major expansion of the program in terms of the number of schools enrolled), 514 low-cost private schools who applied to the program attained the minimum pass rate in the SLQAT, the final qualification step for program entry. Out of these schools, 482 schools (93%) signed their program participation agreements with PEF in July-August 2007 and began receiving the monthly subsidy benefit. In November 2007, three to four months after phase-3 program schools entered the program, QAT 4 (the first QAT for phase-3 program schools) was administered by PEF in all program schools. Out of 479 phase-3 program schools that took QAT 4, only 234 (49%) passed it. The high failure rate was unanticipated by PEF\u2014such a rate had not been observed in preceding QAT rounds nor has it been repeated to date in subsequent QAT rounds. For example, in phase 4, the next major program expansion, of the 425 phase-4 program schools that took QAT 5 (which represented the first QAT for phase-4 program schools), 412 (97%) passed it. The precise QAT pass rate cutoff for determining program eligibility combined with the unusually high failure rate among phase-3 program schools in QAT 4 provides a data design with adequate sample size to investigate whether the threat of program exit precipitated by failing QAT 4 has a causal effect on mean scores in QAT 5 (the ultimatum or threat QAT) as well as later QAT rounds (indicating effect persistence) for first-time failers near the cutoff among phase-3 program schools. Specifically, we fit a sharp RD design to the data to essentially compare mean scores in subsequent QAT rounds of phase-3 program schools that just failed QAT 4 (referred to as marginal failers), and, hence become subject to the threat, to those of corresponding schools that just passed QAT 4 (referred to as marginal passers). To briefly delineate the identification strategy, let sy denote the mean QAT score in the core subjects of Urdu, English, and mathematics in phase-3 program school s , and let the indicator variable sd denote treatment (threat) assignment, where one denotes that the school failed QAT 4, and zero otherwise. In addition, let 0 sy and 1sy denote the potential outcomes of school s in the untreated and treated states, respectively. Treatment status is assigned based on the decision rule \uf028 d z s s \uf029 \uf03d \uf07b 1 z s \uf03c \uf07d c , (6) 28 where sz denotes school s \u2019s QAT 4 pass rate which is perfectly observed ( z is more generally referred to as the assignment variable), c the known, distinct pass rate cutoff of 67% (more precisely, 66.67%), and 1 an indicator function. Thus, the conditional probability of treatment as a function of the assignment variable z, Pr d \uf0e9 \uf0eb s \uf03d 1 z s \uf03d c \uf0fb , dives discontinuously from one to \uf0f9 zero at the cutoff, yielding a sharp RD design (Trochim 1984). Let e denote an arbitrarily small number. Under the assumption that (i) the zero-limit of the conditional expectation of the counterfactual untreated outcome for treated schools is well defined, (ii) the conditional expectation of the outcome variable exhibits local smoothness at the cutoff in the absence of the treatment, (iii) and the density of the assignment variable z is positive in the neighborhood of the cutoff, the difference in mean outcomes between marginal passers and marginal failers identifies \uf061 y \uf0ba E \uf061 \uf0e9 \uf0eb s z s \uf03d c \uf0f9 \uf0fb \uf03d lim e 0 \uf0af E y \uf0e9 \uf0eb 1 s z s c \uf03d \uf02d e \uf02d \uf0f9 \uf0fb lim e 0 \uf0af E y \uf0e9 \uf0eb 0 s z s c \uf03d \uf02b e \uf0fb \uf0f9 (7) which represents the average treatment effect of the treated (ATT) or threat effect at the cutoff for phase-3 program schools (Hahn et al. 2001, Todd 2006). A consistent estimate of the threat effect at the cutoff is given by \uf02b \uf061 \uf061 \uf061\uf02d \u02c6 \u02c6 , \u02c6 y y \uf02d \uf03d y (8) where \u02c6 y\uf061\uf02d and \u02c6 y\uf061\uf02b denote the conditional expectations of the outcome variable y at the cutoff from below and above, respectively. Given that we are interested in flexibly estimating the treatment effect at a single point using observations in its neighborhood, an attractive method is local smoothing using nonparametric regression. We use local linear regression (a local polynomial of order one) to individually estimate the two conditional expectations at the cutoff in (5); the selection of this estimator is motivated by its faster convergence rates at boundaries relative to standard kernel regression (Fan and Gijbels 1996; Porter 2002). The practical implementation of local linear regression requires the specification of the kernel hK \uf0d7 , the weighting function, and the \uf028 \uf029 bandwidth h , the window width in which the kernel function is applied. We select the triangular kernel given that it is boundary optimal and thus well suited to regression-discontinuity designs (Cheng et al. 1997). We select the optimal bandwidth h by applying the plug-in method developed by Imbens and Kalyanaraman (henceforth, I-K) (2009) specifically for use in 29 regression-discontinuity settings, with h determined by minimizing the mean squared error (MSE) using observations only around the cutoff.16 Following the guidance in , we also examine the sensitivity of our inference results to setting the bandwidth to half and twice the optimal bandwidth generated from the I-K method for each of our estimations. The local estimation via RD aids in controlling for phenomena/events that may have biased our results if we had opted for a more global estimation method. We note three potential sources. First, it is conceivable that some program schools may place in the bottom of the score distribution in a given QAT round due to a transitory bad draw but can expect to make gains towards the mean in subsequent QAT rounds (Kane and Staiger 2002). Thus, the initial mean QAT score of a low-performing school may be a misleading measure of its true QAT performance. This implies that, in our case, the learning gains experienced by first-time failers may be attributable in part to both accountability pressure and regression to the mean. However, any potential mean reversion tendency is expected to be locally smooth at the pass rate cutoff (Chay et al. 2005). Second, the estimated RD effects are net of any natural student learning depreciation that may affect gains in mean scores (Andrabi et al. 2009), with the conditional mean level (and the rate) of learning depreciation expected to be locally smooth at the pass rate cutoff. Third, PEF responded to the high QAT 4 failure rate by organizing training in January 2008 on QAT content and format and targeting it at QAT 4 failers as well as marginal passers. Given this, while the training may have shifted the levels of the learning regression functions, the effect of the training on mean learning is expected to be locally smooth at the cutoff. Thus, the estimated RD effects at the pass rate cutoff net out any bias due to these sources and continue to identify the threat effect on marginal first-time failers. We first discuss the findings from some basic model specification tests. First, we check if there is a positive mass of school observations in the neighborhood of the QAT 4 pass rate cutoff, given that this is a necessary condition for the identification strategy. This condition is verified by a visual inspection of the frequency distribution of phase-3 program schools by QAT 4 pass rate (see Figure 9). Second, although the following check does not necessarily pose a threat to identification, using Figure 9, we also visually inspect whether there is an unusual discontinuity in the density function of the QAT 4 pass rates at the cutoff, as it may indicate 16 The I-K bandwidth selection algorithm is automated in Stata by . 30 strategic one-way manipulation of pass rates at the cutoff (McCrary 2008). The inspection suggests that the QAT 4 pass rate density function appears to be generally naturally characterized by a jagged structure; furthermore, this structure does not appear to be unique to the QAT 4 pass rate density for phase-3 program schools as other QAT rounds exhibit a similar pattern. Third, the RD analysis is performed on schools for which data could be linked across QAT rounds. As discussed in Section 3, the success rate in linking schools was not perfect, particularly between QAT 4 and QAT 5, and the loss of the unlinked schools may serve as a source of potential sample selection bias in the RD analysis. However, a comparison between the frequency distribution of all phase-3 program schools by QAT 4 pass rate with that of only linked phase-3 program schools (Figures 9 and 10), provides no telltale signs of dissimilarities, suggesting that the problem is negligible. Fourth, we test for local smoothness in the conditional expectation of pre-program covariates at the QAT 4 pass rate cutoff using data from submitted program application forms. Although consistent evidence of discontinuities in the conditional means at the cutoff for these covariates does not necessarily undermine the identification strategy, it does cast doubt on its plausibility. Table 8 presents summary statistics on the pre-program number of students, number of teachers, maximum monthly teacher salaries, number of classrooms, gender, location, level, registration status, and mean SLQAT scores, as well as the RD estimates of the effects at the cutoff using local linear regressions. The findings strongly suggest that the null hypothesis of local regression smoothness in conditional expectations at the cutoff cannot be rejected at standard significance levels for the full set of pre-program covariates examined. Fifth, we test if the conditional mean pre-program outcome (mean QAT 4 scores) exhibits local smoothness at the cutoff. This directly tests a necessary condition for identification under RD. Table 9 shows that the RD estimate of the threat effect on normalized mean QAT 4 scores at the cutoff are is \u22120.003 standard deviations, with a standard error of 0.775 standard deviations. The local linear regressions are depicted in Panel 1 in Figure 11. Thus, the finding suggests that the null hypothesis of local smoothness in mean QAT 4 scores at the pass rate cutoff cannot be rejected at standard significance levels. Column 1 in Table 9 presents the RD estimates of the threat or \u201cstick\u201d effect on mean QAT scores for marginal failers among phase-3 program schools. Optimal bandwidth sizes for the local linear regressions, obtained using the I-K method, range between 20\u201337 percentage 31 points depending on the QAT round. To limit the influence of outliers in outcome values, school observations with QAT 4 pass rates within 15 percentage points of the cutoff with mean QAT score values smaller or larger than the 1st and 99th percentile values respectively were discarded from the analysis. Figure 11 depicts the local linear regressions of conditional mean QAT scores. The estimated stick effect on mean scores at the cutoff in QAT 5, the threat QAT, is 0.664 standard deviations and statistically significant. We also find a RD stick effect on mean QAT 6 scores: the estimated effect is 0.561 standard deviations and significant. The inference findings for these QAT rounds are robust to setting the bandwidth to half and twice the optimal bandwidths for the estimations. The estimated RD effect on mean QAT 7 scores, two QATs removed from the threat QAT, drops in magnitude to 0.349 standard deviations and loses significance. The estimated RD effect on mean QAT 8 scores, three QATs removed from the threat QAT, is 0.089 standard deviations; this effect is also not statistically different from zero. The inference results are however not robust to setting the bandwidth to twice the optimal bandwidths for the estimations\u2014when the bandwidths are doubled, the RD effects grow in size and gain significance. However, the observed degressive pattern in the RD effects over QAT rounds remains. Thus, the RD estimates collectively suggest the presence of a strong stick effect on learning for marginal failers. We also find weaker evidence of persistence in the stick effect but this effect appears to dissipate over time once the threat of program exit is no longer immediately present. The detected RD stick effects on mean QAT scores may be due to QAT 4 failers manipulating the composition of student test takers to increase their chances of attaining the minimum pass rate in QAT 5. We see two opportunities for test-taking pool selection. First, the program school can take advantage of the minimum attendance requirement of 80% for testing to (temporarily) systematically rid itself of its poorest learners before the QAT is administered. Second, the program school can screen in and admit better (potential) learners in anticipation of their stronger performance in the QAT. QAT 4 failers may have more pursued both strategies more intensively than QAT 4 passers. While we cannot directly examine whether the composition of QAT takers have systematically changed over QAT rounds in a way that suggests positive test-taking pool selection, we can indirectly examine this question by studying whether we find any local discontinuities in the conditional expectation of the number of QAT takers at the pass rate cutoff. 32 Column 2 in Table 9 presents the RD estimates of the stick effect on the mean number of QAT takers. Optimal bandwidth sizes for the local linear regressions range between 12\u201331 percentage points depending on the QAT round. School observations with QAT 4 pass rates within 15 percentage points of the cutoff with test-taker values smaller or larger than the 1st and 99th percentile values respectively were discarded from the analysis. Figure 12 depicts the local linear regressions of conditional mean QAT takers. The estimated RD effect on QAT 4 takers is \u20136.1 students; this effect is not statistically different from zero. Likewise, we do not find evidence of a RD effect on QAT 5 takers: the estimated RD effect is \u20134.2 students. The inference findings for QATs 4 and 5 are robust to setting the bandwidth to half and twice the optimal bandwidths for the estimations. In QAT 6-8, at the optimal bandwidths for the respective estimations, we also fail to reject the null hypothesis of local smoothness in the mean number of test takers at the cutoff. The inference findings are however not robust to setting the bandwidth to twice the optimal bandwidths for the estimations: the magnitude of the RD effects increases to roughly \u201315 students and the effects are significant at standard significance levels. Given that there is consistent evidence of local smoothness in mean test takers at the cutoff in QAT 5 (the threat QAT), we discount the sensitivity of the results in the post-threat QAT rounds and read the collective results as suggesting that test-taking pool selection is unlikely to be an important gaming strategy pursued by failers in order to raise mean QAT scores. B. Carrot effect on learning The FAS program also awards annual individual cash bonuses to a fixed number of teachers in qualifying program schools. With each annual round of bonuses, PEF has revised the qualifying criteria, largely motivated by the need to limit the number of bonus recipients. The first round of teacher bonuses was offered in January 2007, some 10 months into the academic year for program schools. The program schools that qualified for the bonus were those that achieved a minimum student pass rate of 90% on QAT 2, administered in November 2006. There were a total of 23 schools that qualified for teacher bonuses, which represented 43% of the program schools that took QAT 2. The second round of teacher bonuses was offered in January 2008. The qualifying schools were those that achieved consecutive minimum pass rates of 90% on QAT 3 and QAT 4, administered in March 2007 and November 2007, respectively. There were a total of 33 24 schools that qualified for teacher bonuses in the second round, which represented 12% of the program schools that took QAT 3. The third round of teacher bonuses was offered in January 2009. The qualifying schools were those that achieved the minimum pass rate of 90% in QAT 5, administered in February 2008, as well as obtained a minimum value of 100 in a simple average of the number of students tested in the QAT and the percent mean QAT score across all tested subjects. There were a total of 42 schools that qualified for teacher bonuses, which represented 4% of the program schools that took QAT 5. Given the small number of schools that qualify for teacher bonuses, the sample for the analysis is expanded to include all program schools that took QAT 5. There were 1,083 schools that took QAT 5. If bonus qualification was solely based on obtaining a pass rate of 90%, 870 schools (80.3%) would have qualified. In contrast, if bonus qualification was solely based on obtaining a minimum score of 100 in the composite measure, 49 schools (4.5%) would have qualified. Applying the two criteria together yields 42 qualifying schools. Consequently, facilitating the application of a RD design to the data, it turns out that the general binding constraint for determining bonus qualification is the minimum score on the composite measure. Figure 13 depicts the independent effects of the two thresholds as well as their combined effect. Thus, the analysis of the carrot effect on learning is conducted on program schools which obtained the minimum pass rate of 90% in QAT 5 and are in the neighborhood of the minimum QAT 5 composite score. Discussions with PEF and a review of program documents indicate that the same thresholds are not used to determine eligibility for any other benefits (or penalties). Analogous to the threat effect investigation, a sharp RD design is applied to examine the carrot effect for marginal bonus nonqualifiers among program schools who obtained the minimum QAT 5 pass rate of 90%. Given that the composite score is constructed from both learning and test participation measures, the carrot effect may manifest itself in mean QAT scores and/or the number of students that take the QAT (QAT takers). Thus, let sy denote either the mean QAT score in the core subjects of Urdu, English, and mathematics or the number of QAT takers in program school s . Let the indicator variable sd denote treatment assignment, where one denotes that the school failed to attain the minimum QAT 5 composite score, and zero otherwise. Finally, let 0 sy and 1sy denote the potential outcomes of school s in the untreated and treated states, respectively. Treatment status is assigned based on the decision rule 34 \uf028 d z s s \uf029 \uf03d \uf07b 1 z s \uf03c \uf07d c , where sz denotes school s \u2019s QAT 5 composite score which is perfectly observed, c the known, distinct pass rate cutoff of 100 points, and 1 an indicator function. The conditional probability of treatment as a function of the assignment variable z, Pr d \uf0e9 \uf0eb s \uf03d 1 z s \uf03d c \uf0fb , \uf0f9 dives discontinuously from one to zero at the cutoff. Under the assumptions for sharp RD identification stated before, the carrot effect of the teacher bonus at the cutoff for program schools, y\uf061 , is identified by the difference in post-bonus mean outcomes between marginal nonqualifiers and marginal qualifiers. A consistent estimate of the carrot effect at the cutoff is given by \u02c6 which we estimate via local linear \uf02b \uf061 \uf061 \uf061\uf02d \u02c6 , \u02c6 y y \uf03d \uf02d y regressions on either side of the cutoff with kernel hK and bandwidth h fixed following the same procedures as in the threat effect investigation. In all estimations, sensitivity of the inference results is checked by setting the bandwidth to half and twice the optimal bandwidth. The carrot effect on learning remains identified in the potential presence of mean reversion from the top of the distribution as well as natural learning depreciation as the conditional expectations of these phenomena are assumed to be locally smooth at the composite score cutoff. We begin by discussing some basic model specification tests. Figure 14 depicts the frequency distribution of program schools over QAT 5 composite scores. Each bin is two points wide and the vertical line represents the bonus qualification cutoff of 100 points. A visual inspection of the frequency distribution shows a nontrivial mass of observations in the neighborhood of the cutoff. The inspection also shows that there is no unusual discontinuity in the number of schools at the cutoff. Table 10 presents summary statistics on the pre-program number of students, number of teachers, maximum and minimum monthly teacher salaries, number of classrooms, gender, location, level, registration status and mean SLQAT score, as well as the sharp RD estimates of local discontinuities in the conditional expectations of these covariates at the cutoff using local linear regressions. Given that program application data are only available for phase-3 and phase-4 program schools, the total sample size for the local smoothness checks for pre-program covariate means decreases from 870 to 658 schools; importantly, only 30 schools qualify for bonuses in the sample. In contrast to the threat effect analysis, we do not find uniform evidence of local smoothness in the conditional means of pre- program covariates at the composite score cutoff: the RD effects for the means of number of teachers, share of schools that is rural, and the share of schools that is coeducational are 35 statistically significant. However, these findings are not robust to setting the bandwidths to half and twice the I-K derived optimal bandwidths for the estimations. We test if the conditional expectations of mean scores and test participation in QAT 5 (the bonus assignment QAT) exhibit local smoothness at the composite score cutoff. This directly tests a necessary condition for identification under RD. Table 11 shows that the RD estimate of the carrot effect on mean QAT 5 scores at the cutoff is \u22120.60 standard deviations, with an estimated standard error of 0.60 standard deviations. The local linear regressions are depicted in Panel 1 in Figure 13. Similarly, the RD estimate of the carrot effect on QAT takers at the cutoff is \u20132.56 students, with an estimated standard error of 3.81 students. The local linear regressions are depicted in Panel 1 in Figure 15. The findings suggest that the null hypothesis of local smoothness in mean learning and test participation levels at the QAT 5 composite score cutoff cannot be rejected at standard significance levels. Turning now to the results, Table 11 presents the RD estimates of the carrot effect for marginal bonus nonqualifiers among program schools that satisfy the QAT 5 minimum pass rate of 90%. Columns 1 and 2 present RD estimates for the carrot effect on mean QAT scores and QAT takers, respectively. RD effects controlling for pre-program covariates are not estimated given the limited degrees of freedom for the estimations in the cutoff neighborhood. Optimal bandwidth sizes for the local linear regressions, obtained using the I-K method, were roughly 5 points for mean QAT scores and 17 points for QAT takers. Figure 15 depicts the local linear regressions of the conditional mean QAT scores, separately by QAT round. Similarly, Figure 16 depicts the local linear regressions of the conditional mean QAT takers, separately by QAT round. A priori, we expect no carrot effect in QAT 6, the QAT round just preceding the bonus award, and a carrot effect in QAT 7, the QAT round just following the bonus award, with possible persistence in the effect in QAT 8, the next QAT round. In terms of QAT performance, the estimated effect on mean scores at the cutoff in QAT 6 is \u22120.87 standard deviations. Although large in size, this estimate is not statistically different from zero. The estimated RD effect on mean scores in QAT 7, the immediate post-bonus QAT, is 0.21 standard deviations and not statistically different from zero. The estimated RD effect on mean scores in QAT 8, the post- bonus QAT once-removed, is 0.49 standard deviations and also not statistically different from zero. In terms of QAT participation, the estimated RD effect on QAT 6 takers is \u20132.6 students; 36 this effect is not statistically different from zero. Likewise, we find no evidence of a RD effect on QAT takers in QAT 7. In QAT 8, we find a significant, negative RD effect on the number of QAT takers\u2014the finding is however not robust to setting the bandwidth to twice the optimal bandwidth for the estimation.17 The evidence collectively suggests that, despite their size, group-based teacher bonuses do not provide sufficiently strong incentives for marginal nonqualifiers to raise either QAT performance or participation in order to increase their chances for qualifying for bonuses in the next award round. It is plausible that given that PEF has revised the bonus eligibility criteria for every award round (without communicating the revisions well in advance), it may have generated uncertainty on the applicable criteria for the next award round, discouraging the effort of marginal disqualifiers to raise learning and test participation. Independent of this conjecture, it is plausible that gains in learning and test participation by marginal qualifiers may have been masked by gains in the corresponding measures among marginal nonqualifiers. Estimation issues may also be relevant: the inability to detect any effects at the composite score cutoff could be due to inadequate statistical power. 8. Conclusion Low student learning is a consistent finding in much of the developing world and the search for solutions is an active research and public policy agenda. This paper uses a relatively unique dataset of five semiannual rounds of standardized test data to characterize and explain the short- term evolution of student learning in primary and secondary schools. The data are collected as part of the quality assurance system for a public-private partnership program which offers public subsidies conditional on minimum learning levels to low-cost private schools in Pakistan. Apart from a large positive distributional shift in learning between the first two test rounds, the learning distributions over test rounds show little progressive movement. School-level panel regressions essentially show that pre-program learning levels and the level of the school are associated with the level and evolution of conditional mean learning. Variance component decomposition shows that between 60\u201370% of the cross-sectional student-level test score variation is attributable to between-student variation, with no discernible trend in either the level or component shares of 17 The effect remains statistically significant when the selected bandwidth is set at half the optimal bandwidth. 37 variation over test rounds. The share of test score variation attributable to between-grade variation is only somewhat smaller than the share attributable to between-school variation. Schools are ejected from the program if they fail to achieve a minimum pass rate in the test in two consecutive attempts, making the test high stakes. Sharp regression discontinuity (RD) estimates show that the threat of program exit on marginal first-time failers induces large learning gains. The large change in learning between the first two test rounds is likely importantly attributable to this accountability pressure given that a large share of new program entrants failed in the first test round. Schools also qualify for substantial annual teacher bonuses if they de facto achieve a minimum score in a composite measure of student test participation and mean test score. Sharp RD estimates however do not show that the prospect of future teacher bonus rewards induces learning gains for marginal bonus nonqualifiers. Thus, the evidence collectively suggests that, apart from the pressure from below to maintain a minimum level of learning for program participation, program schools do not face any effective incentives to continuously raise learning. 38 "}, {"target_population": "Young people aged 18 to 30 who: \u00e2\u20ac\u00a2Are not in education, training or employment \u00e2\u20ac\u00a2Are homeless as defined in the homelessness legislation but not in priority need under that legislation \u00e2\u20ac\u00a2Have previous difficulties in, or eviction from, supported accommodation \u00e2\u20ac\u00a2 And have needs deemed too high/complex to manage within a supported housing scheme because of issues such as substance misuse, significant mental health issues, low/medium learning disability or personality disorders below the threshold for Adult Social Care services.", "source": ["The Be the Change Social Impact Bond (SIB) is delivered by the Mayday Trust(Mayday) \u2013 a charity that provides personalised and strength based support toyoung people experiencing homelessness and those going through tough lifetransitions.It was originally conceived as a Fair Chance Fund (FCF) SIB1and Mayday started development work in 2014when it made some of its services outcomes-based.", "At that stage three County Councils (CCs) were involved ascommissioners \u2013 Northamptonshire, Oxfordshire and Warwickshire.", "Though the FCF application was unsuccessful(because other applicants were bidding to achieve greater impact) Mayday managed to retain Northamptonshireas commissioner for its application to the Commissioning Better Outcomes (CBO) Fund.Northamptonshire CC underwent a significant restructuring during the SIB\u2019s development and Be the Changewas commissioned by First for Wellbeing CIC, established by the Council in April 20162The SIB uses the same outcome measures and metrics as the FCF; is delivered by Mayday; and is based onMayday\u2019s Personal Transitions Services (PTS).", "The PTS a highly flexible \u2018assets-based\u2019 approach that focuses onidentifying people\u2019s strengths and then providing the personalised support they need to achieve their aspirations.Unlike many high support homelessness programmes, this primarily uses general housing in the social or privaterental sectors rather than hostels or supported accommodation.", "Mayday firmly believes that this helps the youngpeople to live more independently, build new support networks and break the cycle of dependency, therebyavoiding the institutionalisation of service users.Although Mayday had developed a good working relationship with Bridges Fund Management (BFM) during theFCF development and application process it ran a further competition to select an investor in its Be the ChangeSIB.", "BFM was successful and is thus the investor in this SIB.", "The SIB went live in June 2017 What are the successes?Ability to provide personalised services that respondto individual needThe SIB allows Mayday to work with individuals freefrom the constraints imposed by the detailed servicespecifications that feature in the contracts more routinely letby commissioners.", "Use of a SIB approach allows Maydayto deliver its asset-based PTS service and continue to gatherevidence for its effectiveness with a view to further roll-out.Better scrutiny of service deliveryMeasuring the impact of the Be the Change SIB is an integralpart of the service, not an add on.", "This is a particularlyimportant feature of the SIB for the commissioner as First forWellbeing is keen to learn from Be the Change and test itsapplicability in other areas.The use of an existing SIB frameworkin this case that used in the FCF - meant that many ofthe challenges faced in developing other SIBs did notmaterialise here.", "The availability of pre-defined outcomes,metrics and payment tariff meant that very little developmentwork was needed for the SIB (on top of that done for theFCF application).", "Effectively, Mayday was able to offeran \u201coff the shelf\u201d solution that had central government\u201cendorsement\u201d.", "In addition, Mayday had already run aservice in Northamptonshire in 2014/15 using FCF criteriaand metrics and this successful track record providedthe confidence that Mayday would deliver the outcomespromised.Potential to replicate and scaleMayday and BFM have developed a comprehensive\u201cpackage\u201d (comprising an evidence-based intervention, anexperienced provider and social investment) that they hopeto sell to other local commissioners keen to address theissues of homelessness in their areas.Transfer of riskto the investor thorough the \u201cconventional\u201d SIB structureshields Mayday from financial risk and allows it to focus onthe delivery of its PTS.", "It utilises a Special Purpose Vehicle(SPV) to enable this and does so in a cost effective andefficient manner.", "In this case, the SPV did not incur the usualongoing performance management costs because Maydayhad \u201cpracticed\u201d using payment by results (PbR) and alreadyhad in place the data collection processes needed toevidence performance.What are the challenges?Commissioner engagement and ongoing involvementCommissioner commitment was hard to sustain especiallyduring and after the major re-structuring of NorthamptonshireCC in 2015/16 and the creation of First for Wellbeing.Maintaining momentum and interest in the SIB took a lot ofeffort from Mayday in the 12 months until the new organisationfelt able to take the SIB forward.", "This experience mirrorsthat in other SIBs in terms of the challenges of initiating andmaintaining commissioner buy-in in the face of changinglocal circumstances.The size of the contractFirst for Wellbeing was already commissioning services fromMayday and wanted to continue to do so.", "To do this meant a)keeping the contract value below the EU threshold requiringcompetition and b) satisfying internal procurement rules.The result is a small contract, for services commissionedon an outcomes basis.", "While keeping the SIB small madeprocurement relatively straightforward (and low cost) forFirst for Wellbeing, its small scale made it challenging forBFM to get it through its Investment Panel.Use of the Centre for SIBs template contractFirst for Wellbeing anticipated that the template contractprovided would be capable of being used withoutamendment.", "Instead there was a lot of interaction betweenit, BFM and the Centre for SIBs, that First for Wellbeing didnot expect, to ensure that the contract reflected the specificoperational obligations and requirements of the service forwhich it was contracting.", "This reflects the fact (as we havefound in other reviews) that the template contract helpsparties to a SIB ensure that the contract reflects the particularrequirements of an outcomes-based approach, but it is notand cannot be a complete \u2018off-the-shelf\u2019-solution, and stillneeds tailoring to service requirements.Sourcing general housingIn the social or private rental sectors rather than hostelsor supported accommodation.", "Such accommodation isscarce and difficult to obtain, and its availability is key to thesuccess of the project.", "However this is a challenge of thespecific intervention and approach adopted by Mayday, andwould have been equally challenging if the project had beenconventionally funded and structured, rather than being aSIB and outcomes-based.", "What are the lessons learnt?1 Leadership is key.", "Mayday had to expend a lot of effort to keep the momentum behind theSIB going and to obtain and maintain commitment in the face of changing circumstances.Even without root and branch re-organisation among the commissioning body, ashappened in this case, commissioning post holders move regularly and providers have tobe prepared to \u201csell\u201d the SIB repeatedly to a range of audiences.2 The use of existing outcomes lent credibility to the proposition, particularly with a newset of stakeholders.", "It also speeded up development \u2013 notwithstanding the difficultiesin maintaining commissioner commitment in the light of an organisational re-structure.3 The ability to build on previous experience.", "Mayday\u2019s experience of running the pilotin Northamptonshire was also useful for informing the development of the financialmodel for the Be the Change SIB.", "Specifically analysis of performance data informedthe decision to remove volunteering (one of the FCF payment metrics) from thepayment metrics for the SIB because it proved unrealistic to achieve.", "In addition, asa result of further research undertaken during that period, Mayday extended the agerange of the cohort from 25 to 30.4 Having a shared understanding of the \u201cproblem\u201d is important.", "All parties involved inthe SIB (Mayday, First for Wellbeing and Bridges) had a common understanding of thepolicy \u201cproblem\u201d to be addressed (in this case homelessness among young people).In addition they were all agreed that the SIB represented an innovative solution for Firstfor Wellbeing who had not commissioned for outcomes before, with potential for scaleand replication that was worth pursuing, despite the challenges that arose during itsdevelopment.5 Availability of local data.", "specifically from the pilots Mayday had run (using the FCFrate card and collecting outcomes data), strengthened the case for the SIB andbolstered the credibility of the proposition for both the commissioner and the investorbecause Mayday was able to provide evidence that it was capable of delivering theoutcomes sought.", "Building a business case, and persuading stakeholders to take arisk, is harder if there is only national or international data on which to rely.6 Availability of the CBO contribution to outcomes payments.", "First for Wellbeing wasa brand new organisation when it made the decision to commission the SIB.", "Theproposition would have been harder to sell if the 24% CBO contribution had not beenon the table."], "paper_id": "#17757", "title": "In depth review - 'Be the change' Social Impact Bond", "pdf_txt": "An indepth review Produced as part of the Commissioning Better Outcomes Fund Evaluation \u201cBe the change\u201d Social Impact Bond 1 Summary The Be the Change Social Impact Bond (SIB) is delivered by the Mayday Trust (Mayday) \u2013 a charity that provides personalised and strength based support to young people experiencing homelessness and those going through tough life transitions. It was originally conceived as a Fair Chance Fund (FCF) SIB1 and Mayday started development work in 2014 when it made some of its services outcomes-based. At that stage three County Councils (CCs) were involved as commissioners \u2013 Northamptonshire, Oxfordshire and Warwickshire. Though the FCF application was unsuccessful (because other applicants were bidding to achieve greater impact) Mayday managed to retain Northamptonshire as commissioner for its application to the Commissioning Better Outcomes (CBO) Fund. Northamptonshire CC underwent a significant restructuring during the SIB\u2019s development and Be the Change was commissioned by First for Wellbeing CIC, established by the Council in April 20162 The SIB uses the same outcome measures and metrics as the FCF; is delivered by Mayday; and is based on Mayday\u2019s Personal Transitions Services (PTS). The PTS a highly flexible \u2018assets-based\u2019 approach that focuses on identifying people\u2019s strengths and then providing the personalised support they need to achieve their aspirations. Unlike many high support homelessness programmes, this primarily uses general housing in the social or private rental sectors rather than hostels or supported accommodation. Mayday firmly believes that this helps the young people to live more independently, build new support networks and break the cycle of dependency, thereby avoiding the institutionalisation of service users. Although Mayday had developed a good working relationship with Bridges Fund Management (BFM) during the FCF development and application process it ran a further competition to select an investor in its Be the Change SIB. BFM was successful and is thus the investor in this SIB. The SIB went live in June 2017. 1 The Fair Chance Fund was established in 2014 to pay for sustained housing, employment and educational support for homeless 18 to 24 year olds with investors putting in money now on a long-term payment by results basis. More detail is provided in section 2.2 below. 2 First for Wellbeing CIC was a partnership between Northamptonshire County Council, Northamptonshire Healthcare NHS Foundation Trust and the University of Northampton. In April 2018 First for Wellbeing CIC was taken back in-house by Northamptonshire CC as part of a wider re-organisation initiated in response to the County Council\u2019s financial difficulties. 2 \u201cBe the change\u201d Social Impact Bond \u201cBe the change\u201d Social Impact Bond Figure 1. below summarises the key organisations involved in the SIB, and the SIB structure Partners in First for Wellbeing Co-Commissioners Commissioner Grant agreement Outcomes Contract SPV Investment & Support Delivery Contract 3 \u201cBe the change\u201d Social Impact Bond What are the successes? What are the challenges? Ability to provide personalised services that respond to individual need Commissioner engagement and ongoing involvement Commissioner commitment was hard to sustain especially during and after the major re-structuring of Northamptonshire CC in 2015/16 and the creation of First for Wellbeing. Maintaining momentum and interest in the SIB took a lot of effort from Mayday in the 12 months until the new organisation felt able to take the SIB forward. This experience mirrors that in other SIBs in terms of the challenges of initiating and maintaining commissioner buy-in in the face of changing local circumstances. The size of the contract First for Wellbeing was already commissioning services from Mayday and wanted to continue to do so. To do this meant a) keeping the contract value below the EU threshold requiring competition and b) satisfying internal procurement rules. The result is a small contract, for services commissioned on an outcomes basis. While keeping the SIB small made procurement relatively straightforward (and low cost) for First for Wellbeing, its small scale made it challenging for BFM to get it through its Investment Panel. Use of the Centre for SIBs template contract First for Wellbeing anticipated that the template contract provided would be capable of being used without amendment. Instead there was a lot of interaction between it, BFM and the Centre for SIBs, that First for Wellbeing did not expect, to ensure that the contract reflected the specific operational obligations and requirements of the service for which it was contracting. This reflects the fact (as we have found in other reviews) that the template contract helps parties to a SIB ensure that the contract reflects the particular requirements of an outcomes-based approach, but it is not and cannot be a complete \u2018off-the-shelf\u2019-solution, and still needs tailoring to service requirements. Sourcing general housing In the social or private rental sectors rather than hostels or supported accommodation. Such accommodation is scarce and difficult to obtain, and its availability is key to the success of the project. However this is a challenge of the specific intervention and approach adopted by Mayday, and would have been equally challenging if the project had been conventionally funded and structured, rather than being a SIB and outcomes-based. The SIB allows Mayday to work with individuals free from the constraints imposed by the detailed service specifications that feature in the contracts more routinely let by commissioners. Use of a SIB approach allows Mayday to deliver its asset-based PTS service and continue to gather evidence for its effectiveness with a view to further roll-out. Better scrutiny of service delivery Measuring the impact of the Be the Change SIB is an integral part of the service, not an add on. This is a particularly important feature of the SIB for the commissioner as First for Wellbeing is keen to learn from Be the Change and test its applicability in other areas. The use of an existing SIB framework in this case that used in the FCF - meant that many of the challenges faced in developing other SIBs did not materialise here. The availability of pre-defined outcomes, metrics and payment tariff meant that very little development work was needed for the SIB (on top of that done for the FCF application). Effectively, Mayday was able to offer an \u201coff the shelf\u201d solution that had central government \u201cendorsement\u201d. In addition, Mayday had already run a service in Northamptonshire in 2014/15 using FCF criteria and metrics and this successful track record provided the confidence that Mayday would deliver the outcomes promised. Potential to replicate and scale Mayday and BFM have developed a comprehensive \u201cpackage\u201d (comprising an evidence-based intervention, an experienced provider and social investment) that they hope to sell to other local commissioners keen to address the issues of homelessness in their areas. Transfer of risk to the investor thorough the \u201cconventional\u201d SIB structure shields Mayday from financial risk and allows it to focus on the delivery of its PTS. It utilises a Special Purpose Vehicle (SPV) to enable this and does so in a cost effective and efficient manner. In this case, the SPV did not incur the usual ongoing performance management costs because Mayday had \u201cpracticed\u201d using payment by results (PbR) and already had in place the data collection processes needed to evidence performance. 4 \u201cBe the change\u201d Social Impact Bond What are the lessons learnt? 1 2 3 4 5 6 Leadership is key. Mayday had to expend a lot of effort to keep the momentum behind the SIB going and to obtain and maintain commitment in the face of changing circumstances. Even without root and branch re-organisation among the commissioning body, as happened in this case, commissioning post holders move regularly and providers have to be prepared to \u201csell\u201d the SIB repeatedly to a range of audiences. The use of existing outcomes lent credibility to the proposition, particularly with a new set of stakeholders. It also speeded up development \u2013 notwithstanding the difficulties in maintaining commissioner commitment in the light of an organisational re-structure. The ability to build on previous experience. Mayday\u2019s experience of running the pilot in Northamptonshire was also useful for informing the development of the financial model for the Be the Change SIB. Specifically analysis of performance data informed the decision to remove volunteering (one of the FCF payment metrics) from the payment metrics for the SIB because it proved unrealistic to achieve. In addition, as a result of further research undertaken during that period, Mayday extended the age range of the cohort from 25 to 30. Having a shared understanding of the \u201cproblem\u201d is important. All parties involved in the SIB (Mayday, First for Wellbeing and Bridges) had a common understanding of the policy \u201cproblem\u201d to be addressed (in this case homelessness among young people). In addition they were all agreed that the SIB represented an innovative solution for First for Wellbeing who had not commissioned for outcomes before, with potential for scale and replication that was worth pursuing, despite the challenges that arose during its development. Availability of local data. specifically from the pilots Mayday had run (using the FCF rate card and collecting outcomes data), strengthened the case for the SIB and bolstered the credibility of the proposition for both the commissioner and the investor because Mayday was able to provide evidence that it was capable of delivering the outcomes sought. Building a business case, and persuading stakeholders to take a risk, is harder if there is only national or international data on which to rely. Availability of the CBO contribution to outcomes payments. First for Wellbeing was a brand new organisation when it made the decision to commission the SIB. The proposition would have been harder to sell if the 24% CBO contribution had not been on the table. 5 2 What is the SIB model? 2.1 The intervention Be the Change is a new intervention designed to help homeless and unemployed young people who are going through particularly difficult times in their lives. It is based on Mayday\u2019s PTS, a highly flexible \u2018assets-based\u2019 approach that focuses on identifying people\u2019s strengths and then providing the personalised support they need to achieve their aspirations. Unlike many homelessness programmes, it primarily uses general housing in the social or private rental housing sectors rather than hostels or supported accommodation, in the belief that this helps the young people supported to live more independently, build new support networks and break the cycle of dependency. 2.1.1 Rationale behind the approach In 2011 Mayday undertook a qualitative review of over 100 people with the objective of finding out what people thought of the services designed to support their move out of homelessness and towards independence3. This identified that the \u2018traditional\u2019 focus on needs kept people in their area of weakness and left them unable to create sustained, positive change for themselves. Arguably, therefore, it thus fostered the institutionalisation of people accessing homelessness services. Armed with this insight, Mayday set about identifying a new method that would flip the way services are traditionally delivered and put control into the hands of those using the services. As a result, in 2012 it developed PTS - an asset-based model built on a solid evidence base from the US. PTS is based on a significant body of research undertaken by the Search Institute4 into the positive support and strengths that young people need to thrive. The Developmental Assets framework was the result and it was first introduced in 1990. Since then evaluations of Developmental Assets have been conducted with about six million young people across the United States and around the world, and the link between developing individual assets and the reduction in negative behaviours has been evidenced. Mayday has taken the learning from the Search Institute and used it to develop an approach for delivery adapted to the UK context. 2.1.2 Groups targeted by the intervention Be the Change works with young people aged 18 to 30 who: are not in education, training or employment; \u2022 \u2022 \u2022 \u2022 are homeless as defined in the homelessness legislation but not in priority need under that legislation; have previous difficulties in, or eviction from, supported accommodation; and have needs deemed too high/complex to manage within a supported housing scheme because of issues such as substance misuse, significant mental health issues, low/medium learning disability or personality disorders below the threshold for Adult Social Care services. 3 Published as \u201cWisdom from the Street\u201d (https://maydaytrust.org.uk/download-publications/#toggle-id-9) 4 http://www.search-institute.org 6 \u201cBe the change\u201d Social Impact Bond 1 Role of the Asset Coach Each young person referred to the programme is assigned an Asset Coach who works with them through a number of linked core interventions: \u2022 Coaching - a young person makes a decision to work with an Asset Coach. The coach builds a relationship with the individual and uses evidence-based tools to support the young person to articulate their aspirations, build a strong personal identity and work to their strengths to take control of their life and future aspirations. \u2022 Brokering - the coach brokers bespoke existing opportunities, activities or support for each individual to allow them to either build their sense of who they are or gain evidence that they can achieve and can contribute to their community. \u2022 Building positive networks - volunteers assist young people to find and build positive networks, friendships, and people who value them and affirm them as individuals with a sense of purpose. These networks are built in the wider community, rather than the homeless sector, so that young people experiencing homelessness can reintegrate, feel a sense of purpose and contribute to their local community. 2.1.3 Outcomes measurement Mayday uses an online tool to measure personal asset developments and link them to hard outcomes. This provides the robust evidence that outcomes and impact are being achieved. Mayday ran a two-year proof of concept pilot of its model in Oxford in 2013/2014. Evaluation of this identified a number of aspects that were key to the success of the programme and these have been taken forward in the ongoing development of PTS. They include: \u2022 the importance of voluntary engagement. The evaluation identified that when coaching became a mandatory part of the accommodation service, the active engagement dropped significantly \u2013 turning accepted wisdom (if support is mandatory, people will have to and therefore will engage) on its head. When individuals have control over their engagement with their coaches they are more likely to trust them and participate meaningfully. When it is made mandatory, coaching is seen as a \u2018box to tick\u2019 to move out of homelessness and people engage less enthusiastically or not at all; and \u2022 the persistent and positive approach of the coaches was key to getting young people to engage. In particular, positive conversations about what people are interested in were important in getting young people to re-engage. 2 The balance between voluntary engagement and outreach There is a balance to strike between voluntary engagement and outreach to keep people engaged. The Mayday approach lets people have a say if and when they want to engage, but coaches persistently reach out to let people know that they should get in touch when they are ready. This has proved effective and successful engagement and participation in the programme (evidenced by signing of a jointly developed Asset Plan) is one of the payment metrics for the SIB (see section 2.4). 7 \u201cBe the change\u201d Social Impact Bond 2.2 The SIB business case In 2014 then Department of Communities and Local Government (DCLG) (now Ministry of Housing, Communities and Local Government (MHCLG)) and the Cabinet Office launched the Fair Chance Fund (FCF). The FCF was a payment by results (PbR) scheme that aimed to improve accommodation and work outcomes for a group of young, homeless people whose support needs are, and continue to be, poorly met by existing service because of the complexity of their circumstances. It was designed to \u201cstimulate innovate approaches which can be built on and replicated in the future and address problems that would otherwise lead to long term benefit dependency, health problems and increased crime\u201d5. 3 Why use a PbR approach? The decision to use a PbR approach was taken because the complexity of the problems faced by the group. This, along with the lack of quality data meant that it was very difficult to specify how services should be run in advance. DCLG therefore decided to pay for the outcomes achieved (up to a maximum tariff for each young person) and allow voluntary sector providers to innovate and achieve the best results possible. The up-front service costs were wholly or partially funded by social investors, and therefore FCF contracts are a form of social impact bond. The Be the Change SIB was originally conceived as a FCF SIB and has adopted the majority of the FCF\u2019s key characteristics. It aims to demonstrate the effectiveness of its approach to tackling the complex issues faced by homeless young people and effect a system change in the way services for this group are commissioned and paid for. The FCF recognised that a significant proportion of the benefits arising from achieving positive outcomes for homeless young people accrue to central government. The Be the Change SIB is one of the first SIBs for people experiencing homelessness in England where the local commissioners pay the majority of the outcomes payments. Be the Change will work with around 360 young people over three years and will aim to achieve positive outcomes for all of them. 2.3 Contracting model 2.3.1 Contracting model The contracting model for the Be the Change SIB is relatively straightforward. There is a: \u2022 single commissioner - First for Wellbeing CIC6; \u2022 single provider \u2013 Mayday; and \u2022 single investor - BFM, who will provide finance through its Social Impact Bond Fund. BFM has established a Special Purpose Vehicle (SPV) that holds the contract with First for Wellbeing. Mayday is contracted to deliver the Be the Change service by the SPV. 5 Fair Chance Fund Full bid specification documentation,  6 First for Wellbeing CIC was a partnership between Northamptonshire County Council, Northamptonshire Healthcare NHS Foundation Trust and the University of Northampton. In April 2018 First for Wellbeing CIC was taken back in-house by Northamptonshire CC as part of a wider re-organisation initiated in response to the County Council\u2019s financial difficulties. 8 \u201cBe the change\u201d Social Impact Bond 2.3.2 Operational structure and financial flows The operational structure for the SIB is summarised in the infographic at the front of this report. The flow of funding and payments is as follows: \u2022 BFM provides financing from its Social Impact Bond Fund to the SPV which then makes the fee for service payments that allow Mayday to deliver Be the Change; outcomes payments from First for Wellbeing are claimed via the SPV; First for Wellbeing pays the SPV for the outcomes achieved; the SPV requests co-payments from the CBO Fund on the basis of the outcomes achieved; The National Lottery Community Fund makes co-payments to the commissioner and if Be the Change is sufficiently successful, BFM\u2019s investment is repaid. \u2022 \u2022 \u2022 \u2022 \u2022 BFM has made an investment of \u00a3150,000 and outcomes payments are capped at \u00a3360,000 over three years. 2.4 Outcomes payments Be the Change SIB has a single outcome measure \u201cYoung people (18-30 years old) not in education, employment or training are supported to live independently (in line with the Fair Chance Fund).\u201d Like the FCF it uses a series of proxy measures (engagement, accommodation, education and employment) against which payments are made as shown in table 1 below. Table 1. Outcomes measures and indicators Metric Indicator Timing Young homeless people who are NEET participate in the scheme, measured by their input into goal-setting (development asset planning) The person has successfully engaged with the intervention by participating on the assessment (measure through electronic signed copy of Asset Plan). Three payments paid for: successful engagement and two subsequent assessments within nine months of registering an individual on the scheme Young homeless people who are NEET secure and sustain accommodation The person has successfully secured and sustained accommodation An initial payment on entry to accommodation then four payments at 3, 6, 12 and 18 months Young homeless people who are NEET engage with education and training, leading to accredited qualifications and resulting in improved employment prospects through participation in accredited and non-accredited learning opportunities Young homeless people who are NEET secure full or part time employment and that this is sustained The person has engaged with education and training (First level entry, Level 1 and Level 2) Payment made when the individual achieves the relevant qualification The person has secured and sustained part time or full time employment Sustained part time or full time employment for 13 or 26 weeks Initial assessment - \u00a3500 Second assessment - \u00a3500 Third assessment - \u00a3200 Move into accommodation - \u00a3500 Accommodation sustained for 3 months - \u00a31,500 Accommodation sustained for 6 months - \u00a31,500 Accommodation sustained for 12 months - \u00a31,500 Accommodation sustained for 18 months - \u00a31,500 First Entry Level Qualification - \u00a32,000 Level 1 Qualification (e.g. NVQ) - \u00a33,000 Level 2 Qualification - \u00a34,300 Entry into Employment - \u00a3500 13 weeks part-time employment - \u00a33.000 26 weeks part-time employment - \u00a32,000 13 weeks full-time employment - \u00a34,500 26 weeks full-time employment \u00a33,500 9 \u201cBe the change\u201d Social Impact Bond The outcome structure is designed to reward Mayday for achieving the main metric (accommodation) and sustaining it over a period of time. It is anticipated that most young people will be engaged and accommodated in Years 1 and 2 (of a three year contract) and that the focus in Year 3 will be on education and employment outcomes. Though there is no payment for soft outcomes (largely because the SIB follows the FCF outcome and payment structure, which has no such payments), personal asset scores are measured and monitored as an integral part of the intervention. First for Wellbeing partners also intend to measure other outcomes over and above those specified in the contract, to try and quantify the programme\u2019s broader social impact. This includes the impact on offending, local healthcare and the benefits system. 2.5 SIB Development process and costs Mayday has been exploring new ways of working that fit better with the actual (rather than perceived) needs of homeless people since 2011. It believes that contracting for outcomes provides the means to deliver a \u201creal world\u201d solution that allows providers to provide personalised services that respond to individual need. In 2015 Mayday made a strategic decision to align all its services to the delivery of PTS and only deliver services on an outcomes basis. \u201cTraditional contracts constrain providers (because of their specificity), outcomes-based contracts allow them the freedom to deliver differently, test new approaches and deliver better outcomes.\u201d Pat McArdle, CEO Mayday Trust Mayday found that delivering outcomes-based contracts also meant taking a different approach to identifying opportunities and winning contracts. In 2014 it worked with an intermediary, Numbers for Good, using a \u00a330,000 grant from the Investment and Contract Readiness Fund programme, in a contract readiness (or \u201cSIB preparation\u201d) project to support its application to the FCF. This involved getting an evidence base together, aligned with the FCF outcomes, design of a delivery model and data management systems, investor engagement and help with the application. As part of the transformation work undertaken under the ICRF, Mayday also employed a Social Impact Manager and started to collect, collate and interrogate real outcomes data in ways that were meaningful to the organisation as well as its funders. The Social Impact Manager is still in post and continues to provide the information that allows the Be the Change SIB to be managed on a light touch basis thereby keeping SPV management costs down. Mayday\u2019s FCF proposition had three co-commissioners \u2013 Northamptonshire CC, Oxfordshire CC and Warwickshire CC \u2013 but the bid was unsuccessful. Despite the disappointment the FCF experience proved useful in that it allowed Mayday to develop an effective relationship with BFM (who had been selected as investor for the FCF SIB). This meant that when Mayday sought investment for its CBO Fund proposition it was a \u201cknown entity\u201d (Matt Black, Numbers for Good). Mayday was determined to carry on \u2013 and had a solid base on which to build \u2013so in 2014/15 it developed and ran a six months pilot service for people experiencing homelessness in Northamptonshire CC. This used the PTS approach and FCF outcomes with the objective of gathering evidence of its ability to deliver and get a measure of the impact it had on the cohort. In this pilot Mayday measured and reported outcomes against the FCF outcomes framework though the commissioner made payment in advance. In January 2015, Mayday submitted an expression of interest and in February 2015 it was awarded a \u00a330,000 development grant. Mayday engaged Numbers for Good to take forward their previous work and help develop the CBO Fund application. Mayday had found keeping three commissioners interested in, and committed to, the FCF application very difficult and time consuming as each raised different issues about the SIB development and FCF application processes that needed to be resolved at different times. Of the three commissioners involved in the FCF application, Northamptonshire CC was particularly supportive. When the opportunity to develop a SIB with the CBO Fund presented itself, Mayday decided that, given its previous experience, it was better to work with a single commissioner and that commissioner should be Northamptonshire CC. Northamptonshire CC agreed to support the CBO full application. It was already commissioning Mayday to deliver traditional services for homeless people and was attracted by the PTS that had some track record in achieving good outcomes. It was also helpful that there was a readily available set of pre-defined outcomes against which success could be measured and rewarded. The potential for CBO to make a contribution to outcome payments also encouraged the Council to make a positive decision. 10 \u201cBe the change\u201d Social Impact Bond In 2015/16, at the same time the CBO application was being developed, there was a major re-structuring of Northamptonshire CC, which externalised public health services \u2013 including the Council\u2019s responsibilities for homelessness \u2013 into a new organisation, First for Wellbeing. First for Wellbeing CIC was established in April 2016 and had three partners - Northamptonshire County Council, Northamptonshire Healthcare NHS Foundation Trust and the University of Northampton. First for Wellbeing was a new company with a new Managing Director - who had not had any involvement in the development of either the FCF or the CBO applications. She was wary of taking on something new and was sceptical about the SIB proposition which, though it had been signed off by Northamptonshire CC, had lost all its key supporters as part of the re- organisation. Mayday (in the person of Pat McArdle) worked very hard to keep the momentum going. She sent reports, provided information and data and communicated well and clearly with all the key stakeholders in First for Wellbeing and those in the wider public sector (District and Borough Councils, youth offending teams, the PCC, CCG and others) on which the service would rely for referrals. It was, according to Lorraine Meads (First for Wellbeing\u2019s Service Planning and Commissioning Manager) entirely because of her significant efforts that First for Wellbeing decided to commission the SIB. 4 Competitive procurement process \u2022 First for Wellbeing was already commissioning Mayday and wanted to continue to do so. It decided that the best way to do this was to keep the contract value below the EU threshold at which an open competition must be conducted. The result was a small contract (value \u00a3360,000), being run as a pilot to assess the feasibility of commissioning for outcomes across a wider range of services. \u2022 Although Mayday had already run a competition to find an investor for its FCF bid, it ran a further competition to procure a suitable social investor for this SIB. Three candidates were evaluated: Big Issue Invest (BII), CAF Venturesome and BFM. BFM was selected because of its capacity to be a so-called \u2018active\u2019 investor \u2013 i.e. be actively involved in the monitoring, evaluation and performance management of the contract - and because of the relationships it had already built with Mayday during the FCF process. Neither BII nor CAF Venturesome were considered to have the same capacity to be actively involved in these aspects that Mayday felt would be key to the success of the SIB. The Be the Change SIB aims to address what some people perceive as a potential drawback in the FCF SIBs. This is that they allowed providers of supported accommodation who were also FCF providers effectively to get paid twice for the same outcome \u2013 by DWP for the rent on the accommodation, through housing benefit, and by DCLG for the individual being in accommodation through the FCF outcome payments. This also led to a potential disincentive to move service users from supported accommodation into independent living because the provider would lose its DWP payment. In addition, service users in supported accommodation were reluctant to find employment (without the promise of alternative accommodation) because they would lose DWP support and be unable to afford the rent. The Be the Change SIB is therefore taking a \u201cpurist approach\u201d to accommodation in the SIB in that supported accommodation is, as far as possible, to be used only when the service user\u2019s circumstances demands it \u2013 otherwise general housing in the social or private rental sectors is used. This will be challenging for both Mayday as provider - it is difficult to source affordable accommodation in Northamptonshire - and for BFM as the approach makes the investment high risk. However, both consider it worthwhile in order to avoid the \u201cimpact risk\u201d, in terms of the institutionalisation of service users, inherent in an unintended bias towards the supported accommodation approach. 11 \u201cBe the change\u201d Social Impact Bond 5 \u2022 \u2022 \u2022 \u2022 Reasons why DFM backed the contract The small scale of the SIB (an investment of \u00a3150,000) was a challenge for BFM given that it normally aims to make larger investments in SIBs. However, BFM\u2019s Investment Committee was prepared to back the contract because: it allowed BFM to \u201cinvest in what we know\u201d in terms of both the social policy area and the provider it was happy with the FCF rate card the service is replicable it provided the opportunity to test a new intervention (PTS) and build a for it with a view to making the model available for homeless service groups nationwide; the SIB was initiated by a local commissioner (as opposed to other Homeless SIBs that have been developed in response to central government funding programmes). BFM hopes to be able to use the precedent set here to persuade others to buy the BFM backed, Mayday delivered PTS service \u2022 only a small amount of resource is needed for performance management because BFM is largely able to rely on, and trust, the information provided by Mayday\u2019s Social Impact Manager. The SIB went live in June 2017 and is receiving a 24% contribution to outcome payment from the CBO Fund. 3. Advantages of the SIB approach The main advantages of the SIB approach for the Be the Change service include: \u2022 Ability to provide personalised services that respond to individual need. The outcomes contract allows Mayday to work with individuals free from the constraints imposed by the type of contracts more routinely let by commissioners. Outcomes-based contracts are characterised by their lack of specificity in terms of inputs, activities to be undertaken, etc. and, in the context of this contract, the type of accommodation to be provided. They provide the opportunity to support service users, in this case homeless young people, with what they actually want and need to develop solutions to their problems. Use of a SIB approach allows Mayday to deliver its asset-based PTS service and continue to develop the evidence base for its effectiveness with a view to further roll-out. \u2022 Potential to replicate and scale. Mayday and BFM hope to replicate and scale the SIB by offering an off the shelf SIB package to more local commissioners. To that end measures around healthcare, benefits payments and offending are being captured, alongside accommodation and employment, to demonstrate the broader social impact, and value for money, of the PTS. \u2022 Better scrutiny of service delivery. Measuring the impact of the Be the Change SIB is an integral part of the service, not an add on. This is a particularly important feature of the SIB for the commissioner as First for Wellbeing is keen to learn from the SIB and test its applicability in other policy areas. Other potential future advantages identified by the commissioner include the rigour that the SIB structure enforces, and \u201cthe demonstrable VFM and better quality services that flow from it\u201d Lorraine Meads (First for Wellbeing\u2019s Service Planning and Commissioning Manager). \u2022 Transfer of risk to the investor. This is a \u201cconventional\u201d SIB. That is one in which the investor is taking the financial risk and paying the provider, Mayday, on a fee for service basis. 12 \u201cBe the change\u201d Social Impact Bond 4. Challenges and disadvantages in developing the SIB The challenges encountered in developing the SIB included: \u2022 Initial commissioner engagement and ongoing involvement. As already discussed, this SIB was a long time in development \u2013 31 months from initial application to the CBO Fund to contract start. A significant amount of effort went into engaging and involving both commissioners and the wider group of stakeholders (District and Borough Councils, youth offending teams, the PCC, CCG, etc.) who would make referrals to the service. The major restructuring of Northamptonshire CC in 2015/16 meant that the SIB lost most of its key supporters and Mayday had to undertake the not insignificant task of engaging a differen t group of people in a newly formed organisation \u2013 something it was able to do successfully. This experience mirrors that in other SIBs of initiating and maintaining commissioner buy-in in the face of changing local circumstances. \u2022 Change of commissioner. The challenges of commissioner engagement were exacerbated by the fact that the original commissioner was First for Wellbeing but the commissioner effectively became Northamptonshire CC when First for Wellbeing was taken in-house in April 2018. This meant that the contracts had to be novated and, possibly more importantly, it took time for the new commissioner to become familiar with the aims and objectives of the SIB. \u2022 Size of the contract. First for Wellbeing was already commissioning services from Mayday and wanted to continue to do so. To do this meant a) keeping the contract value below the EU threshold requiring competition and b) satisfying internal procurement rules. The result is a small contract, being run as a pilot, for services commissioned on an outcomes basis. While keeping the SIB small made procurement relatively straightforward (and low cost) for First for Wellbeing, its small scale made it challenging for BFM to get it through its Investment Panel. \u2022 Use of the Centre for SIBs template contract. While BFM was comfortable with the use of the template contract, First for Wellbeing, perhaps understandably because this was the first time it had used it, was less so. It felt that though the template contract provided a good starting point, it did not take account of the specific operational obligations and requirements of service it was buying. This meant there was a lot of interaction between it, BFM and the Centre for SIBs \u2013 some of it time consuming \u2013 that First for Wellbeing did not expect. This criticism may be due, in part, to First for Wellbeing\u2019s over-optimistic expectation that the template contract would be capable of being used without amendment. It is interesting to note that in our wider research for the CBO evaluation the contract template has, on the whole, been well received; commissioners responding to our survey rated it on average as 4.6 out of 5 in terms of usefulness. However, some commissioners did find they were unable to use it due to internal insistence on a standard form of contract, or found it unduly detailed and onerous.7 7 . Commissioning Better Outcomes Fund Evaluation: 2nd Update Report: Full Report, pg. 52: https://www.tnlcommunityfund.org.uk/ media/CBO-2nd-Update-Report_FINAL_FINAL.pdf?mtime=20191018112839 13 \u201cBe the change\u201d Social Impact Bond 6 SIB costs and time \u2022 Taken in isolation, the cost of developing the Be the Change SIB (a \u00a330,000 ICRF grant plus a \u00a330,000 CBO development grant) was high in terms of both money spent and staff time in relation to the size of the contract. However, Mayday used the 2014 ICRF grant to help it become SIB ready and develop the FCF SIB that evolved into the Be the Change SIB. The cost quoted here is therefore attributable to a wider range of activity than that involved in the development of this SIB. 5. Other observations The following observations about the SIB and its development are also worth recording: \u2022 Fit with organisational culture. Mayday is committed to delivering its services on an outcomes basis \u2013 with or without PbR. Its CEO believes that this is a \u201creal world\u201d solution that allows providers to provide personalised services that respond to individual need. Indeed, in 2016 Mayday took the strategic decision to withdraw services in areas where it could not negotiate to deliver the PTS. This clarity of focus meant that Mayday (in the person of its CEO) was determined to make the SIB work despite the disappointment with its FCF bid and the significant challenge posed by the wholesale re-structuring of Northamptonshire CC during the SIB development phase. \u2022 The use of an existing framework. In this case the SIB design used in the FCF - meant that many of the challenges faced in developing other SIBs did not materialise here. The framework\u2019s DCLG \u201cbacking\u201d made it easier for Mayday to sell the proposition and for the commissioner to commit to it. The commissioner was familiar with how the FCF worked having been involved in the development of the original application. The availability of pre-defined outcomes, metrics and payment tariff meant that very little development work was needed for the SIB (on top of that done for the FCF application) and these have been used to develop an \u201coff the shelf\u201d SIB-backed PbR service that Mayday and BFM hope to roll-out to more local commissioners. \u2022 Availability of the CBO contribution to outcomes payments. First for Wellbeing was a brand new organisation when it made the decision to commission the SIB. The proposition would have been harder to sell if the 24% CBO contribution had not been on the table. \u2022 Availability of data to build the case. Mayday had invested internal resources in advance of making its CBO application. It had, for example, run pilots in Oxford and Northamptonshire, employed an Impact Manager to collect and collate evidence relating to its services and developed a thorough understanding of the local context. This meant it was possible to build the case for the SIB using \u201creal\u201d data and impact actually achieved. This added credibility to the proposition to both the commissioner and the investor. 14 \u201cBe the change\u201d Social Impact Bond 6. Conclusions and lessons learnt 6.1 Conclusions This SIB is in part the result of Mayday changing its entire approach to contracting. Mayday believes that traditional contracts, because of their specificity, constrain providers while outcomes-based contracts allow them the freedom to deliver differently, test new approaches and deliver better outcomes. In 2015, it took the strategic decision to align all of its activities to the delivery of PTS \u2013 its outcomes focussed service. This necessitated a move away from tendering for, and delivering, \u201ctraditional\u201d contracts and finding new sources of revenue that would allow Mayday to deliver differently \u2013 these included social investment. What is less clear is exactly how Mayday are using the capital that has been provided, notably as a flexible source of finance and cashflow that enables it to test its outcomes-based approach and change its intervention model where necessary. This is something that we will aim to explore in the second visit. Both the FCF and the CBO Fund provided an opportunity to take advantage of an alternative source of funding that would allow Mayday to deliver services in the way it wanted. The FCF also provided a readily available set of outcomes and a payment structure that could be adopted for the Be the Change SIB. This had advantages in making it quicker and easier to develop the SIB, and indeed has proven to be a \u2018test case\u2019 for one route to successfully replicating SIB models that brings down the transaction costs of developing the SIB, which are frequently cited as being a major barrier to the future sustainability of SIBs.8 However, this also meant that there was a reluctance to change the structure in ways that might arguably have been desirable \u2013 for example to include soft outcome measures that are not part of the FCF structure. Therefore, replicating previously-developed SIB models is an effective approach to developing SIBs, but requires compromise. Mayday had done a lot of work to build its presence and credibility with Northamptonshire CC before applying to the CBO Fund. It had run a pilot, using its PTS approach and FCF measures and metrics, and had worked closely with Northamptonshire CC, as a commissioner, to develop the FCF bid. The pilot provided both local performance data and a track record of successful local delivery on which to build when developing the CBO Fund application and, was key to demonstrating Mayday\u2019s ability to deliver. While Mayday\u2019s track record went some way to persuading commissioners to support its CBO Fund application, it was the potential of a contribution towards outcomes payments from the CBO Fund that was instrumental in persuading both Northamptonshire CC and then First for Wellbeing to support the CBO application. 8 . A study into the challenges and benefits of commissioning Social Impact Bonds in the UK, and the potential for replication and scaling: final report: https://www.gov.uk/government/publications/research-social-impact-bond-commissioning-and-replication 15 \u201cBe the change\u201d Social Impact Bond 6.2 Lessons learned There are four key lessons to be taken from the development of this SIB, which confirm the findings of our wider research for the CBO Fund contained in our LOUD SIB model. 1 2 3 4 Leadership is key. Mayday had to expend a lot of effort to keep the momentum behind the SIB going and obtain and maintain commitment in the face of changing circumstances. Even without root and branch re-organisation of the commissioning body, as happened in this case, commissioning post holders move regularly and providers have to be prepared to \u201csell\u201d the SIB repeatedly to a range of audiences. The Be the Change SIB was provider-led but commissioner-led SIBs face the same issues and challenges. Use of existing outcomes. Rather than starting from scratch, Mayday decided to use the existing FCF outcomes and rate card. This lent credibility to the proposition and made the development work for the SIB relatively straightforward \u2013 notwithstanding the difficulties in maintaining commissioner commitment in the light of an organisational re-structure. The framework\u2019s provenance also helped to establish the credibility of the approach with a new set of stakeholders. In both other findings from this evaluation9 and other recent SIB research 10 there is evidence that the-re-use of outcomes and rate cards is becoming a feature of SIB development and is also facilitating the replication of SIBs in some circumstances. Shared understanding of the \u201cproblem\u201d is important All parties involved in the SIB (Mayday, First for Wellbeing and BFM) had a common understanding of the policy \u201cproblem\u201d to be addressed, in this case homelessness among young people) and agreed that the SIB represented an innovative solution, for First for Wellbeing who had not commissioned for outcomes before, with potential for scale and replication that was worth pursuing, despite the challenges that arose during its development. Availability of local data. The SIB benefitted from the availability of robust local data, specifically from the pilots Mayday had run, which strengthened the case for the SIB and bolstered the credibility of the proposition for both the commissioner and the investor. Building a business case, and persuading stakeholders to take a risk, is harder if there is only national or international data on which to rely. 9 See for example the latest Update report from this evaluation, downloadable at https://www.tnlcommunityfund.org.uk/media/CBO-2nd-Update-Report_ FINAL_FINAL.pdf?mtime=20191018112839 10 See for example A Study into the challenges and benefits of commissioning Social Impact Bonds in the UK, and the potential for replication and scaling, downloadable at https://assets.publishing.service.gov.uk/government/upload s/system/uploads/attachment_data/file/844190/A_study_into_the_challenges_ and_benefits_of_the_SIB_commissioning_process._Final_Report.pdf 16 \u201cBe the change\u201d Social Impact Bond 6.3 Areas for future investigation Assessing scalability A key motivation for both Mayday and BFM in developing the Be the Change SIB is to scale and expand it to other areas. In our next visit we will explore how successful they have been in this given that contributions to outcome payments will no longer be available. Exploring the relationship between funder & provider We will also explore how the working relationship between Mayday and BFM has developed over the life of the SIB with a particular focus on the impact, if any, of BFM\u2019s performance management approach. We will also investigate how the capital provided by BFM has enabled Mayday to take a more flexible approach to delivery, as has been the case for other SIBs and outcomes contracts supported by BFM. Gauging the value of the purist approach One of the key principles of Be the Change is to find and use accommodation in the wider social and private housing market and avoid the use of supported accommodation except where strictly necessary to meet individual needs \u2013 thereby avoiding the potential perverse incentives present in the FCF. We will identify the extent to which this purist approach worked in practice at the next review. Investigating learning outcomes First for Wellbeing is attracted to outcomes-based commissioning because it means that \u201c...the commissioner is not too tied up with writing service specifications and can get away from being instructive\u201d. (Lorraine Meads, (First for Wellbeing\u2019s Service Planning and Commissioning Manager). It views the SIB as a test of the applicability of commissioning for outcomes in other areas. We will also explore whether, and in what areas, First for Wellbeing has used outcomes based commissioning in its business at our next visit and how far the learning and experience from the development and delivery of the Be the Change SIB has been embedded in the commissioning body and wider stakeholders. Mayday expects to gain a lot of learning and experience from the delivery of the Be the Change SIB. It also has extensive plans, set out in its final application to the CBO Fund, for sharing of learning and good practice, with the intention that this model will be made available for homeless service groups nationwide. As part of the next review It will be interesting to discover what learning and experience it has been able to use, and what impact it has had, in the delivery of its own projects; and whether and to what extent it has been able to successfully transfer learning to other projects. 17 \u201cBe the change\u201d Social Impact Bond About this report This in-depth review report is the sixth in a series being produced as part of the CBO Fund Evaluation, commissioned by The National Lottery Community Fund and undertaken by Ecorys UK and ATQ Consultants. The CBO Fund aims to encourage the development of SIBs and similar financial mechanisms. The report is based on a review of documents provided by stakeholders and consultations with key stakeholders involved in the SIB, including representatives from the commissioner intermediary, provider and investor. Consultations took place between November 2017 and January 2018. The report will be updated in subsequent years to provide an account of the SIB\u2019s progress. The report was written by Eileen Robinson, Director at ATQ Consultants (eileen@atqconsultants. co.uk). In total, the evaluation will produce in-depth reviews of nine SIBs part-funded through the CBO Fund. More information about the CBO Fund evaluation, including other in-depth reviews, can be found at https://www.tnlcommunityfund.org.uk/insights/ social-investment-publications. "}]