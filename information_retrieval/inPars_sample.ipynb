{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from extract import extract_relevant_content\n",
    "# import torch\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "import gzip\n",
    "import os\n",
    "import torch\n",
    "from pygaggle.rerank.base import Query, Text\n",
    "from pygaggle.rerank.transformer import MonoT5\n",
    "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Warning: No GPU found. Please add GPU to your notebook\")\n",
    "\n",
    "device=\"cuda:2\"\n",
    "cross_encoder = MonoT5('castorini/monot5-base-msmarco', use_amp=True)\n",
    "cross_encoder.tokenizer = MonoT5.get_tokenizer('t5-base', batch_size=32)\n",
    "cross_encoder.model = T5ForConditionalGeneration.from_pretrained(\"../inPars/data/jff/20230210-021357\").to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also compare the results to lexical search (keyword search). Here, we use \n",
    "# the BM25 algorithm which is implemented in the rank_bm25 package.\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string\n",
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We lower case our text and remove stop-words from indexing\n",
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split():\n",
    "        token = token.strip(string.punctuation)\n",
    "\n",
    "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['what is the study design?',\n",
    " 'what is the research method?',\n",
    " 'how was data collected and analysed? ',\n",
    " 'study design; method; methodology; data collection; research design',\n",
    " 'study design', 'method', 'methodology', 'data collection', 'research design',\n",
    " 'what is the target population?',\n",
    " 'who are the intended beneficiaries of the service?',\n",
    " 'who does the service try to help?',\n",
    " 'who was eligible for inclusion in the intervention?',\n",
    " 'target population; beneficiaries; service users; participants; eligible population; eligibility criteria; cohort; clients',\n",
    " 'target population',\n",
    " 'beneficiaries',\n",
    " 'service users',\n",
    " 'participants',\n",
    " 'eligible population',\n",
    " 'eligibility criteria',\n",
    " 'cohort',\n",
    " 'clients',\n",
    " 'what are the costs of the contract?',\n",
    " 'how much is paid for outcomes?',\n",
    " 'what are the outcomes payments?',\n",
    " 'what is the total contract value?',\n",
    " 'what is the price per outcome?',\n",
    " 'outcomes payment; price; contract value; contract cap; rate card; incentive payment; costs; savings',\n",
    " 'outcomes payment',\n",
    " 'price',\n",
    " 'contract value',\n",
    " 'contract cap',\n",
    " 'rate card',\n",
    " 'incentive payment',\n",
    " 'costs',\n",
    " 'savings',\n",
    " 'what outcomes were achieved?',\n",
    " 'what impact was achieved;?',\n",
    " 'what were the results of the intervention?',\n",
    " 'what was the impact of the intervention?',\n",
    " 'were the contracted outcomes achieved?',\n",
    " 'results; outcomes achieved; impact',\n",
    " 'results', 'outcomes achieved', 'impact']\n",
    "# questions = ['research; consultation; rating; document; level',\n",
    "#             'vulnerable; patient; household; unemployed; living',\n",
    "#             'usd; million; fund; outcome; payment',\n",
    "#             'school; girl; student;']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/samples\"\n",
    "articles = []\n",
    "for f in os.listdir(path):\n",
    "    print(os.path.join(path, f))\n",
    "    passages = extract_relevant_content(os.path.join(path,f))\n",
    "    passages = [re.sub(\"\\s+\", \" \", passage) for passage in passages if len(passage.split()) <= 100000 and len(passage.split()) > 0]\n",
    "    # for finicial target\n",
    "    # passages = [re.sub(\"\\s+\", \" \", passage) for passage in passages if len(passage.split()) <= 300 and len(passage.split()) > 0 and (re.search(\"[Â£$]\\d+\", passage) or re.search(\"\\d,\\d\\d\\d\", passage) or re.search(\"\\d+(k|mil|%)\", passage))]\n",
    "    articles.append(passages)\n",
    "\n",
    "qa = {}\n",
    "for query in questions:\n",
    "    qa[query] = []\n",
    "    \n",
    "for passages in articles:\n",
    "    tokenized_corpus = []\n",
    "    for passage in tqdm(passages):\n",
    "        tokenized_corpus.append(bm25_tokenizer(passage))\n",
    "\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    # This function will search all wikipedia articles for passages that\n",
    "    # answer the query\n",
    "\n",
    "    def search(query):\n",
    "        print(\"Input question:\", query)\n",
    "\n",
    "        ##### BM25 search (lexical search) #####\n",
    "        bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "        top_n = np.argpartition(bm25_scores, -5)[-500:]\n",
    "        bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "        bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        ##### Re-Ranking #####\n",
    "        # Now, score all retrieved passages with the cross_encoder\n",
    "        ans = []\n",
    "        count = 0\n",
    "        question = Query(query)\n",
    "        texts = [Text(passages[hit['corpus_id']],{'docid': hit['corpus_id']},  0) for hit in bm25_hits[:1000]]\n",
    "        reranked = cross_encoder.rerank(question, texts)\n",
    "        for i in range(len(reranked[:30])):\n",
    "            if count == 30:\n",
    "                break\n",
    "            docid = reranked[i].metadata['docid']\n",
    "            score = reranked[i].score\n",
    "            result = reranked[i].text.replace(\"\\n\", \" \")\n",
    "            if  result not in ans:\n",
    "                ans.append(\"Top \"+ str(count+1) + \": \" + result)\n",
    "                count += 1\n",
    "                print(\"\\t{:.3f}\\t{}\".format(score, reranked[i].text.replace(\"\\n\", \" \")))\n",
    "        qa[query].append(\"\\n\".join(ans))\n",
    "\n",
    "    for question in questions:\n",
    "        search(query = question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=qa, index=[\"#17247 - Brookings 2017.pdf\", \"#2598 - Lee 2020.pdf\", \"#17755 - Ecorys 2019.pdf\", \"#17284 - Warner 2018.pdf\",  \"#17725 - IDinsight 2018.pdf\", \"#17192 - Education 2016 (1).pdf\"])\n",
    "df = (df.T)\n",
    "print (df)\n",
    "df.to_excel('qa_top30_inPars.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search(query = \"what is the scale of intervention?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for passages in articles:\n",
    "#     for passage in passages:\n",
    "#         if len(passage.split())>512:\n",
    "#             print(len(passage.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa['what is the study design?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
